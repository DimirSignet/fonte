{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import wilcoxon\n",
    "from lib.experiment_utils import *\n",
    "\n",
    "# plt.rcParams.update({\n",
    "#     \"text.usetex\": True,\n",
    "#     # \"font.family\": \"sans-serif\",\n",
    "#     # \"font.sans-serif\": [\"Helvetica\"]\n",
    "# })\n",
    "\n",
    "# input data\n",
    "CORE_DATA_DIR     = \"./data/Defects4J/core\"\n",
    "BIC_GT_DIR        = \"./data/Defects4J/BIC_dataset\"\n",
    "BASELINE_DATA_DIR = \"./data/Defects4J/baseline\"\n",
    "INDUSTRY_DATA_DIR = \"./data/industry\"\n",
    "\n",
    "# output data\n",
    "RESULTS_DIR = \"./experiment_results/\"\n",
    "\n",
    "# load core data\n",
    "fault_dirs = {}\n",
    "for fault in os.listdir(CORE_DATA_DIR):\n",
    "    fault_dir = os.path.join(CORE_DATA_DIR, fault)\n",
    "    if not os.path.isdir(fault_dir):\n",
    "        continue\n",
    "    pid, vid = fault.split('-')\n",
    "    fault_dirs[(pid, vid[:-1])] = fault_dir\n",
    "print(f\"The core data for {len(fault_dirs)} faults are loaded.\")\n",
    "\n",
    "# load BIC ground-truth data\n",
    "GT = load_BIC_GT(BIC_GT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_functions = {\n",
    "    'max-1': (lambda r: r.score/r.max_rank),\n",
    "    'max-0': (lambda r: 1/r.max_rank),\n",
    "    'dense-1': (lambda r: r.score/r.dense_rank),\n",
    "    'dense-0': (lambda r: 1/r.dense_rank),\n",
    "    'score': (lambda r: r.score), # baseline\n",
    "    'equal': (lambda r: 1),       # baseline\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Demo :p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(vote_for_commits(fault_dirs[(\"Lang\", \"46\")], \"git\", \"Ochiai\",\n",
    "    voting_func=(lambda r: r.score/r.max_rank), decay=0.1,\n",
    "    use_method_level_score=False, excluded=[\"5814f50\"], adjust_depth=True))\n",
    "# bic: 868f697"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Weighted Bisection Example (Math-87b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = {\n",
    "    \"tool\": \"git\",\n",
    "    \"formula\": \"Ochiai\",\n",
    "    \"voting\": \"max-0\",\n",
    "    \"decay\": 0.1,\n",
    "    \"score_level\": \"line\",\n",
    "    \"stage2\": True,\n",
    "}\n",
    "\n",
    "def draw_score_distributions(pid, vid):\n",
    "    fault = (pid, vid)\n",
    "    BIC = GT.set_index([\"pid\", \"vid\"]).loc[fault, \"commit\"]\n",
    "    fault_dir = fault_dirs[fault]\n",
    "\n",
    "    # get commit_ranking\n",
    "    style_change_commits = get_style_change_commits(\n",
    "        fault_dir, hp[\"tool\"], with_Rewrite=True) if hp[\"stage2\"] else []\n",
    "\n",
    "    vote_df = vote_for_commits(fault_dir, hp[\"tool\"], hp[\"formula\"],\n",
    "        hp[\"decay\"], voting_functions[hp[\"voting\"]],\n",
    "        use_method_level_score=(hp[\"score_level\"] == \"method\"),\n",
    "        excluded=style_change_commits)\n",
    "    rank_of_BIC = vote_df.vote.rank(ascending=False, method=\"max\")[BIC]\n",
    "\n",
    "    # C\n",
    "    all_commits = get_all_commits(fault_dir)\n",
    "\n",
    "    # C_susp\n",
    "    C_susp = [\n",
    "        c for c in all_commits if c in vote_df.index\n",
    "    ]\n",
    "\n",
    "    # C_BIC\n",
    "    C_BIC = [\n",
    "        c for c in all_commits\n",
    "        if c in vote_df.index and c not in style_change_commits\n",
    "    ]\n",
    "    scores = [float(vote_df.loc[c, \"vote\"]) for c in C_BIC]\n",
    "    BIC_index = C_BIC.index(BIC)\n",
    "    plt.figure(figsize=(6, 2.5))\n",
    "    plt.title(fault)\n",
    "    plt.bar(range(len(scores)), scores, color=[\n",
    "        \"red\" if i == BIC_index else \"green\" for i in range(len(scores))])\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xlabel(\"Commit Index (in Desending Order of Time)\")\n",
    "    # plt.yscale(\"log\")\n",
    "\n",
    "    return (\n",
    "        BIC_index,\n",
    "        standard_bisection(C_BIC, BIC, return_pivots=True)[1],\n",
    "        weighted_bisection(C_BIC, scores, BIC, return_pivots=True)[1]\n",
    "    )\n",
    "\n",
    "BIC_index, standard_pivots, weighted_pivots = draw_score_distributions(\n",
    "    \"Math\", \"87\")\n",
    "standard_pivots = '$\\\\rightarrow$'.join(map(str, standard_pivots))\n",
    "weighted_pivots = '$\\\\rightarrow$'.join(map(str, weighted_pivots))\n",
    "plt.text(7, 2, f\"Pivot (Standard Bisection): {standard_pivots}\")\n",
    "plt.text(7, 1.5, f\"Pivot (Weighted Bisection): {weighted_pivots}\")\n",
    "plt.title(f\"Math-87b (BIC index: {BIC_index})\")\n",
    "plt.savefig(os.path.join(RESULTS_DIR, \"Math-87b.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Research Question 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ1-1: Search Space Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = \"git\"\n",
    "ss_rows = []\n",
    "for _, row in GT.iterrows():\n",
    "    fault = (row.pid, row.vid)\n",
    "    if fault not in fault_dirs:\n",
    "        continue\n",
    "\n",
    "    fault_dir = fault_dirs[fault]\n",
    "    C = get_all_commits(fault_dir)\n",
    "\n",
    "    commit_df = load_commit_history(fault_dir, tool)\n",
    "    C_susp = commit_df.commit_hash.unique()\n",
    "    C_sc = get_style_change_commits(fault_dir, tool, with_Rewrite=True)\n",
    "\n",
    "    ss_rows.append([row.pid, row.vid,\n",
    "        len(C), len(C_susp), len(C_susp) - len(C_sc)])\n",
    "ss_df = pd.DataFrame(data=ss_rows,\n",
    "    columns=[\"pid\", \"vid\", \"C\", \"C_susp\", \"C_BIC\"])\n",
    "\n",
    "# reduction ratio\n",
    "print(\"Reduction (C -> C_susp):\",\n",
    "    (ss_df[\"C_susp\"]/ss_df[\"C\"]).mean().round(3))\n",
    "print(\"Reduction (C -> C_BIC):\",\n",
    "    (ss_df[\"C_BIC\"]/ss_df[\"C\"]).mean().round(3))\n",
    "\n",
    "# draw figure\n",
    "savepath = os.path.join(RESULTS_DIR, \"RQ1_SS.pdf\")\n",
    "\n",
    "plt.figure(figsize=(5,1.5))\n",
    "mean_size = ss_df[[\"C\", \"C_susp\", \"C_BIC\"]].mean().values.round(1)\n",
    "plt_df = ss_df.melt([\"pid\", \"vid\"], var_name=\"Search Space\", value_name=\"Size\")\n",
    "sns.boxplot(data=plt_df, y=\"Search Space\", x=\"Size\", orient=\"h\")\n",
    "loc, labels = plt.yticks()\n",
    "plt.yticks(loc, [\n",
    "    f\"{l}\\n(mean:{m})\" for l, m in zip([\"$C$\", \"$C_{susp}$\", \"$C_{BIC}$\"],\n",
    "    mean_size)])\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Size (log scale)\")\n",
    "plt.savefig(savepath, bbox_inches=\"tight\")\n",
    "print(f\"Saved to {savepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_cols(l, width):\n",
    "    return \" & \".join(map(lambda i: f\"{i:>{width}}\", l))\n",
    "\n",
    "table = \"\"\n",
    "size_of_C_BIC = [1, 2, 3, 5, 10, 20, 30, 50, 100, 200, 300, 500, 600, 700]\n",
    "n_rows = 2\n",
    "row_len = math.ceil(len(size_of_C_BIC)/n_rows)\n",
    "table += \"\\\\toprule\\n\"\n",
    "for row_idx in range(n_rows):\n",
    "    sizes = size_of_C_BIC[row_idx*row_len:(row_idx+1)*row_len]\n",
    "    table += \"$|C_{BIC}|$ & \" + join_cols([f\"$\\\\leq {n}$\" for n in sizes], width=10) + \"\\\\\\\\\\\\midrule\\n\"\n",
    "    table += \"\\# Subjects & \" + join_cols(\n",
    "        [(ss_df[\"C_BIC\"] <= n).sum() for n in sizes], width=10) + \"\\\\\\\\\"\n",
    "    table += \"\\\\bottomrule\\n\" if row_idx + 1 == n_rows else \"\\\\midrule\\n\"\n",
    "savepath = os.path.join(RESULTS_DIR, \"RQ1_C_BIC_size.tex\")\n",
    "tabular = \"\\\\begin{tabular}{\" + f\"l|{'r'*row_len}\" + \"}\\n\" + table + \"\\\\end{tabular}\"\n",
    "with open(savepath, \"w\") as f:\n",
    "    f.write(tabular)\n",
    "print(tabular)\n",
    "print(f\"Saved to {savepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ1-2: Ranking Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our scoring model + max aggregation (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANKING_DIR = os.path.join(RESULTS_DIR, \"ranking\")\n",
    "\n",
    "def hyperparams_to_path(hp):\n",
    "    model_path = os.path.join(RANKING_DIR, \n",
    "        f\"{hp['tool']}_{hp['score_level']}_{hp['formula']}_{hp['model']}{'_C_BIC' if hp['stage2'] else '_C_susp'}\")\n",
    "    if hp['model'] == 'voting':\n",
    "        if not os.path.exists(model_path):\n",
    "            os.mkdir(model_path)\n",
    "        filename = f\"{hp['voting']}-{hp['decay']}.csv\"\n",
    "        return os.path.join(model_path, filename)\n",
    "    elif hp['model'] == 'maxAggr':\n",
    "        return model_path + \".csv\"\n",
    "\n",
    "hyperparams = [\n",
    "    {\n",
    "        \"model\": [\"voting\"], # scoring model\n",
    "        \"formula\": [\"Ochiai\"], # SBFL formula\n",
    "        \"score_level\": [\"line\"], # granularity of code elements [line|method]\n",
    "        \"tool\": [\"git\"], # commit history retrieval tool [git|shovel]\n",
    "        \"voting\": voting_functions,\n",
    "        \"decay\": [0.0, 0.1, 0.2, 0.3], # lamdas for decay\n",
    "        \"stage2\": [True, False], # style change filtering\n",
    "    },\n",
    "    {\n",
    "        \"model\": [\"maxAggr\"],\n",
    "        \"formula\": [\"Ochiai\"],\n",
    "        \"score_level\": [\"line\"],\n",
    "        \"tool\": [\"git\"],\n",
    "        \"voting\": [None],\n",
    "        \"decay\": [None],\n",
    "        \"stage2\": [True, False],\n",
    "    },\n",
    "]\n",
    "\n",
    "hp_names = list(hyperparams[0].keys())\n",
    "hp_prod = []\n",
    "\n",
    "for hyperparams in hyperparams:\n",
    "    hp_prod += list(\n",
    "        itertools.product(*[hyperparams[n] for n in hp_names])\n",
    "    )\n",
    "\n",
    "print(\"Evaluating each hyperparam configuration..\", flush=True)\n",
    "errors = set()\n",
    "for hp_values in tqdm(hp_prod, colour=\"blue\"):\n",
    "    hp = dict(zip(hp_names, hp_values))\n",
    "    savepath = hyperparams_to_path(hp)\n",
    "    if os.path.exists(savepath):\n",
    "        old_rank_df = pd.read_csv(savepath)\n",
    "        old_rank_df = old_rank_df.drop_duplicates()\n",
    "        old_rank_df[\"vid\"] = old_rank_df[\"vid\"].astype(str)\n",
    "        old_rank_df.set_index([\"pid\", \"vid\"], inplace=True)\n",
    "    else:\n",
    "        old_rank_df = None\n",
    "    rank_rows = []\n",
    "\n",
    "    for _, row in GT.iterrows():\n",
    "        fault = (row.pid, row.vid)\n",
    "        if fault not in fault_dirs:\n",
    "            continue\n",
    "\n",
    "        if old_rank_df is not None \\\n",
    "            and fault in old_rank_df.index \\\n",
    "            and row.commit == old_rank_df.at[fault, \"BIC\"]:\n",
    "            continue\n",
    "\n",
    "        fault_dir = fault_dirs[fault]\n",
    "        try:\n",
    "            num_commits = get_the_number_of_total_commits(fault_dir)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "\n",
    "        if hp[\"stage2\"]:\n",
    "            style_change_commits = get_style_change_commits(\n",
    "                fault_dir, hp[\"tool\"], with_Rewrite=True)\n",
    "        else:\n",
    "            style_change_commits = []\n",
    "\n",
    "        if hp[\"model\"] == \"voting\":\n",
    "            vote_df = vote_for_commits(fault_dir, hp[\"tool\"], hp[\"formula\"],\n",
    "                hp[\"decay\"], voting_functions[hp[\"voting\"]],\n",
    "                use_method_level_score=(hp[\"score_level\"] == \"method\"),\n",
    "                excluded=style_change_commits, adjust_depth=True)\n",
    "        elif hp[\"model\"] == \"maxAggr\":\n",
    "            vote_df = max_aggr_for_commits(fault_dir, hp[\"tool\"], hp[\"formula\"],\n",
    "                use_method_level_score=(hp[\"score_level\"] == \"method\"),\n",
    "                excluded=style_change_commits)       \n",
    "        num_candidates = vote_df.shape[0] - len(style_change_commits)\n",
    "\n",
    "        vote_df[\"rank\"] = (-vote_df[\"vote\"]).rank(method=\"max\")\n",
    "\n",
    "        try:\n",
    "            rank_of_BIC = vote_df.loc[row.commit, \"rank\"]\n",
    "        except KeyError as e:\n",
    "            errors.add((row.pid, row.vid, \"KeyError\", str(e)))\n",
    "            continue\n",
    "        # print(row.pid, row.vid, flush=True)\n",
    "        result = [\n",
    "            row.pid, row.vid, row.commit,\n",
    "            rank_of_BIC, num_candidates, num_commits\n",
    "        ]\n",
    "        rank_rows.append(result)\n",
    "\n",
    "    rank_df = pd.DataFrame(data=rank_rows,\n",
    "        columns=[\"pid\", \"vid\", \"BIC\", \"rank\", \"num_candidates\",\n",
    "            \"num_total_commits\"])\n",
    "    rank_df[\"rank\"] = rank_df[\"rank\"].astype(int)\n",
    "    # display(rank_df)\n",
    "    if old_rank_df is not None:\n",
    "        old_rank_df = old_rank_df[old_rank_df.index.isin(\n",
    "            list(GT[[\"pid\", \"vid\"]].to_records(index=False)))]\n",
    "        old_rank_df = old_rank_df[~old_rank_df.index.isin(\n",
    "            list(rank_df[[\"pid\", \"vid\"]].to_records(index=False)))]\n",
    "        rank_df = pd.concat([old_rank_df.reset_index(), rank_df])\n",
    "    rank_df.sort_values(by=[\"pid\", \"vid\"], inplace=True)\n",
    "    rank_df.to_csv(savepath, index=False)\n",
    "print(f\"Saved to {os.path.join(RESULTS_DIR, 'ranking')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random (baseline) + Worst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_cols = {\n",
    "    # postfix: column\n",
    "    \"_C_BIC\": \"C_BIC\",\n",
    "    \"_C_susp\": \"C_susp\",\n",
    "    \"\": \"C\",\n",
    "}\n",
    "\n",
    "for postfix in ss_cols:    \n",
    "    space_size = ss_df[ss_cols[postfix]]\n",
    "    methods = {\n",
    "        'Worst': space_size,\n",
    "        'Random': (space_size + 1)/2\n",
    "    }\n",
    "    for method in methods:\n",
    "        tmp_df = ss_df[[\"pid\", \"vid\"]].copy()\n",
    "        tmp_df = tmp_df.join(GT.set_index([\"pid\", \"vid\"])[[\"commit\"]],\n",
    "            on=[\"pid\", \"vid\"])\n",
    "        tmp_df.rename(columns={\"commit\": \"BIC\"}, inplace=True)\n",
    "        tmp_df[\"rank\"] = methods[method]\n",
    "        tmp_df[\"num_candidates\"] = space_size\n",
    "        tmp_df[\"num_total_commits\"] = ss_df[\"C\"]\n",
    "        savepath = os.path.join(RANKING_DIR, method + postfix + \".csv\")\n",
    "        tmp_df.to_csv(savepath, index=False)\n",
    "        print(f\"Saved to {savepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FBL-BERT (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANKING_FILE_NAME = \"ranking_INDEX_FBLBERT_RN_bertoverflow_QARC_q256_d230_dim128_cosine_q256_d230_dim128_commits_token.tsv\"\n",
    "\n",
    "tool = \"git\"\n",
    "\n",
    "fbl_rows = []\n",
    "for dirname in os.listdir(BASELINE_DATA_DIR):\n",
    "    result_path = os.path.join(BASELINE_DATA_DIR, dirname, RANKING_FILE_NAME)\n",
    "    if not os.path.exists(result_path):\n",
    "        continue\n",
    "    m = re.match(\"(\\w+)-(\\d+)b\", dirname)\n",
    "    pid, vid = m.group(1), m.group(2)\n",
    "    fault_dir = fault_dirs[(pid, vid)]\n",
    "    commit_df = load_commit_history(fault_dir, tool)\n",
    "\n",
    "    # load FBL-BERT ranking\n",
    "    fdf = pd.read_csv(result_path, sep=\"\\t\", header=None)[[2, 5]]\n",
    "    fdf.columns = [\"commit\", \"score\"]\n",
    "    fdf[\"commit\"] = fdf[\"commit\"].apply(lambda x: x[:7])\n",
    "\n",
    "    # search space\n",
    "    C = get_all_commits(fault_dir)\n",
    "    C_susp = commit_df.commit_hash.unique().tolist()\n",
    "    C_sc = get_style_change_commits(fault_dir, tool, with_Rewrite=True)\n",
    "    C_BIC = [c for c in C_susp if c not in C_sc]\n",
    "\n",
    "    # load BIC ground-truth\n",
    "    BIC = GT[(GT.pid == pid) & (GT.vid == vid)].commit.values[0]\n",
    "\n",
    "    if (fdf.commit == BIC).any():\n",
    "        # check if BIC is in the ranking retrieved by FBL-BERT\n",
    "        fdf[\"rank\"] = (-fdf[\"score\"]).rank(method=\"max\").astype(int)\n",
    "\n",
    "        fdf_susp = fdf[fdf.commit.isin(C_susp)].copy()\n",
    "        fdf_susp[\"rank\"] = (-fdf_susp[\"score\"]).rank(method=\"max\").astype(int)\n",
    "\n",
    "        fdf_BIC = fdf[fdf.commit.isin(C_BIC)].copy()\n",
    "        fdf_BIC[\"rank\"] = (-fdf_BIC[\"score\"]).rank(method=\"max\").astype(int)\n",
    "\n",
    "        rank_C = fdf[fdf.commit == BIC][\"rank\"].values[0]\n",
    "        rank_C_susp = fdf_susp[fdf_susp.commit == BIC][\"rank\"].values[0]\n",
    "        rank_C_BIC = fdf_BIC[fdf_BIC.commit == BIC][\"rank\"].values[0]\n",
    "\n",
    "        fbl_rows.append([pid, vid, BIC, rank_C, rank_C_susp, rank_C_BIC])\n",
    "    else:\n",
    "        # Worst case: BIC is not in the retrieved ranking\n",
    "        fbl_rows.append([pid, vid, BIC, len(C), len(C_susp), len(C_BIC)])\n",
    "\n",
    "fbl_df = pd.DataFrame(fbl_rows,\n",
    "    columns=[\"pid\", \"vid\", \"BIC\", \"rank_C\", \"rank_C_susp\", \"rank_C_BIC\"])\n",
    "fbl_df.sort_values(by=[\"pid\", \"vid\"], inplace=True)\n",
    "fbl_df = fbl_df.join(ss_df.set_index([\"pid\", \"vid\"]), on=[\"pid\", \"vid\"])\n",
    "print(fbl_df.shape)\n",
    "\n",
    "ss_cols = {\n",
    "    # postfix: column\n",
    "    \"_C_BIC\": \"C_BIC\",\n",
    "    \"_C_susp\": \"C_susp\",\n",
    "    \"\": \"C\",\n",
    "}\n",
    "\n",
    "for postfix in ss_cols:\n",
    "    tmp_df = fbl_df[[\"pid\", \"vid\", \"BIC\", \"rank_\" + ss_cols[postfix], ss_cols[postfix], \"C\"]].copy()\n",
    "    tmp_df.rename(columns={\n",
    "        \"rank_\" + ss_cols[postfix]: \"rank\",\n",
    "        ss_cols[postfix]: \"num_candidates\",\n",
    "        \"C\": \"num_total_commits\"\n",
    "    }, inplace=True)\n",
    "    savepath = os.path.join(RANKING_DIR, \"FBL-BERT\" + postfix + \".csv\")\n",
    "    tmp_df.to_csv(savepath, index=False)\n",
    "    print(f\"Saved to {savepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bug2Commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANKING_FILE_NAME = \"ranking_Bug2Commit.csv\"\n",
    "\n",
    "tool = \"git\"\n",
    "\n",
    "b2c_rows = []\n",
    "for dirname in os.listdir(BASELINE_DATA_DIR):\n",
    "    result_path = os.path.join(BASELINE_DATA_DIR, dirname, RANKING_FILE_NAME)\n",
    "    if not os.path.exists(result_path):\n",
    "        continue\n",
    "    m = re.match(\"(\\w+)-(\\d+)b\", dirname)\n",
    "    pid, vid = m.group(1), m.group(2)\n",
    "    fault_dir = fault_dirs[(pid, vid)]\n",
    "    commit_df = load_commit_history(fault_dir, tool)\n",
    "\n",
    "    # load FBL-BERT ranking\n",
    "    bdf = pd.read_csv(result_path, header=None)[[0, 3]]\n",
    "    bdf.columns = [\"commit\", \"score\"]\n",
    "    bdf[\"commit\"] = bdf[\"commit\"].apply(lambda x: x[:7])\n",
    "\n",
    "    # search space\n",
    "    C = get_all_commits(fault_dir)\n",
    "    C_susp = commit_df.commit_hash.unique().tolist()\n",
    "    C_sc = get_style_change_commits(fault_dir, tool, with_Rewrite=True)\n",
    "    C_BIC = [c for c in C_susp if c not in C_sc]\n",
    "\n",
    "    # load BIC ground-truth\n",
    "    BIC = GT[(GT.pid == pid) & (GT.vid == vid)].commit.values[0]\n",
    "\n",
    "    bdf[\"rank\"] = (-bdf[\"score\"]).rank(method=\"max\").astype(int)\n",
    "\n",
    "    bdf_susp = bdf[bdf.commit.isin(C_susp)].copy()\n",
    "    bdf_susp[\"rank\"] = (-bdf_susp[\"score\"]).rank(method=\"max\").astype(int)\n",
    "\n",
    "    bdf_BIC = bdf[bdf.commit.isin(C_BIC)].copy()\n",
    "    bdf_BIC[\"rank\"] = (-bdf_BIC[\"score\"]).rank(method=\"max\").astype(int)\n",
    "\n",
    "    rank_C = bdf[bdf.commit == BIC][\"rank\"].values[0]\n",
    "    rank_C_susp = bdf_susp[bdf_susp.commit == BIC][\"rank\"].values[0]\n",
    "    rank_C_BIC = bdf_BIC[bdf_BIC.commit == BIC][\"rank\"].values[0]\n",
    "\n",
    "    b2c_rows.append([pid, vid, BIC, rank_C, rank_C_susp, rank_C_BIC])\n",
    "\n",
    "\n",
    "b2c_df = pd.DataFrame(b2c_rows,\n",
    "    columns=[\"pid\", \"vid\", \"BIC\", \"rank_C\", \"rank_C_susp\", \"rank_C_BIC\"])\n",
    "b2c_df.sort_values(by=[\"pid\", \"vid\"], inplace=True)\n",
    "b2c_df = b2c_df.join(ss_df.set_index([\"pid\", \"vid\"]), on=[\"pid\", \"vid\"])\n",
    "print(b2c_df.shape)\n",
    "\n",
    "ss_cols = {\n",
    "    # postfix: column\n",
    "    \"_C_BIC\": \"C_BIC\",\n",
    "    \"_C_susp\": \"C_susp\",\n",
    "    \"\": \"C\",\n",
    "}\n",
    "\n",
    "for postfix in ss_cols:\n",
    "    tmp_df = b2c_df[[\"pid\", \"vid\", \"BIC\", \"rank_\" + ss_cols[postfix], ss_cols[postfix], \"C\"]].copy()\n",
    "    tmp_df.rename(columns={\n",
    "        \"rank_\" + ss_cols[postfix]: \"rank\",\n",
    "        ss_cols[postfix]: \"num_candidates\",\n",
    "        \"C\": \"num_total_commits\"\n",
    "    }, inplace=True)\n",
    "    savepath = os.path.join(RANKING_DIR, \"Bug2Commit\" + postfix + \".csv\")\n",
    "    tmp_df.to_csv(savepath, index=False)\n",
    "    print(f\"Saved to {savepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {}\n",
    "for lam in [0.0, 0.1, 0.2, 0.3]:\n",
    "    for tau in [\"max\", \"dense\"]:\n",
    "        for alpha in [0, 1]:\n",
    "            key = (f\"$\\\\alpha={alpha}$, $\\\\tau={tau}$\", lam, \"ours\")\n",
    "            paths[key] = os.path.join(\n",
    "                RANKING_DIR, \"git_line_Ochiai_voting_C_BIC\",\n",
    "                f\"{tau}-{alpha}-{lam}.csv\"\n",
    "            )\n",
    "    for vot in [\"score\", \"equal\"]:\n",
    "        paths[(vot, lam, \"baseline\")] = os.path.join(\n",
    "            RANKING_DIR, \"git_line_Ochiai_voting_C_BIC\",\n",
    "            f\"{vot}-{lam}.csv\"\n",
    "        )\n",
    "\n",
    "MRR_rows = []\n",
    "for key in paths:\n",
    "    vot, lam, category = key\n",
    "    rank_df = pd.read_csv(paths[key])\n",
    "    MRR = (1/rank_df[\"rank\"]).mean()\n",
    "    MRR_rows.append([vot, lam, category, MRR])\n",
    "MRR_df = pd.DataFrame(data=MRR_rows,\n",
    "    columns=[\"voting\", \"lambda\", \"category\", \"MRR\"])\n",
    "\n",
    "plt.figure(figsize=(5, 3.5))\n",
    "hue_order = MRR_df[MRR_df[\"lambda\"] == 0.1].sort_values(\n",
    "    by=\"MRR\", ascending=False).voting.tolist()\n",
    "sns.lineplot(data=MRR_df, x=\"lambda\", y=\"MRR\", hue=\"voting\", style=\"category\",\n",
    "    hue_order=hue_order)\n",
    "ax = sns.scatterplot(data=MRR_df, x=\"lambda\", y=\"MRR\", hue=\"voting\",\n",
    "    style=\"category\", hue_order=hue_order)\n",
    "legend_len = len(hue_order) + 2 + MRR_df.category.unique().shape[0]\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles[:legend_len], labels[:legend_len], loc=(1.01, 0.07))\n",
    "plt.xticks(MRR_df[\"lambda\"].unique().tolist())\n",
    "plt.xlabel(\"$\\\\lambda$\")\n",
    "\n",
    "savepath = os.path.join(RESULTS_DIR, \"RQ1_MRR.pdf\")\n",
    "plt.savefig(savepath, bbox_inches=\"tight\")\n",
    "print(f\"Saved to {savepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    \"Ours\": os.path.join(RANKING_DIR, \"git_line_Ochiai_voting_C_BIC\", \"max-0-0.1.csv\"),\n",
    "    \"Ours w/o Stage 2\": os.path.join(RANKING_DIR, \"git_line_Ochiai_voting_C_susp\", \"max-0-0.1.csv\"),\n",
    "    \"Equal Voting\": os.path.join(RANKING_DIR, \"git_line_Ochiai_voting_C_BIC\", \"equal-0.1.csv\"),\n",
    "    \"Max Aggr.\": os.path.join(RANKING_DIR, \"git_line_Ochiai_maxAggr_C_BIC.csv\"),\n",
    "    \"FBL-BERT\": os.path.join(RANKING_DIR, \"FBL-BERT_C_BIC.csv\"),\n",
    "    \"Bug2Commit\": os.path.join(RANKING_DIR, \"Bug2Commit_C_BIC.csv\"),\n",
    "    \"Random\": os.path.join(RANKING_DIR, \"Random_C_BIC.csv\"),\n",
    "    \"Worst\": os.path.join(RANKING_DIR, \"Worst_C_BIC.csv\"),\n",
    "    \"FBL-BERT (entire commit)\": os.path.join(RANKING_DIR, \"FBL-BERT.csv\"),\n",
    "    \"Bug2Commit (entire commit)\": os.path.join(RANKING_DIR, \"Bug2Commit.csv\"),\n",
    "    \"Random (entire commit)\": os.path.join(RANKING_DIR, \"Random.csv\"),\n",
    "    \"Worst (entire commit)\": os.path.join(RANKING_DIR, \"Worst.csv\"),\n",
    "}\n",
    "\n",
    "N = [1, 2, 3, 5, 10] # for acc@n\n",
    "eval_rows = []\n",
    "for method in paths:\n",
    "    rank_df = pd.read_csv(paths[method])\n",
    "\n",
    "    num_subjects = rank_df.shape[0]\n",
    "\n",
    "    eval_rows.append(\n",
    "        [method]\n",
    "        + [(1/rank_df[\"rank\"]).mean().round(3)]\n",
    "        + [int((rank_df[\"rank\"] <= n).sum()) for n in N]\n",
    "    )\n",
    "\n",
    "eval_df = pd.DataFrame(data=eval_rows,\n",
    "    columns=[\"method\", \"MRR\"] + [f\"acc@{n}\" for n in N])\n",
    "eval_df.sort_values(by=\"MRR\", ascending=False, inplace=True)\n",
    "savepath = os.path.join(RESULTS_DIR, \"RQ1_ranking.tex\") \n",
    "eval_df.to_latex(savepath, index=False)\n",
    "print(f\"Saved to {savepath}\")\n",
    "\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Research Question 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "hp = {\n",
    "    \"tool\": \"git\",\n",
    "    \"formula\": \"Ochiai\",\n",
    "    \"voting\": \"max-0\",\n",
    "    \"decay\": 0.1,\n",
    "    \"score_level\": \"line\",\n",
    "    \"stage2\": True,\n",
    "}\n",
    "\n",
    "savepath = os.path.join(RESULTS_DIR, \"RQ2_bisection_simulation.csv\")\n",
    "\n",
    "if os.path.exists(savepath):\n",
    "    print(f\"{savepath} exists\")\n",
    "    simul_df = pd.read_csv(os.path.join(RESULTS_DIR, \"RQ2_bisection_simulation.csv\"))\n",
    "    simul_df[\"vid\"] =simul_df[\"vid\"].astype(str)\n",
    "else:\n",
    "    simul_rows = []\n",
    "\n",
    "    for _, row in tqdm(GT.iterrows(), total=GT.shape[0]):\n",
    "        fault = (row.pid, row.vid)\n",
    "\n",
    "        if fault not in fault_dirs:\n",
    "            continue\n",
    "\n",
    "        BIC = row.commit\n",
    "        fault_dir = fault_dirs[fault]\n",
    "\n",
    "        # get commit_ranking\n",
    "        style_change_commits = get_style_change_commits(\n",
    "            fault_dir, hp[\"tool\"], with_Rewrite=True) if hp[\"stage2\"] else []\n",
    "\n",
    "        vote_df = vote_for_commits(fault_dir, hp[\"tool\"], hp[\"formula\"],\n",
    "            hp[\"decay\"], voting_functions[hp[\"voting\"]],\n",
    "            use_method_level_score=(hp[\"score_level\"] == \"method\"),\n",
    "            excluded=style_change_commits)\n",
    "        rank_of_BIC = vote_df.vote.rank(ascending=False, method=\"max\")[BIC]\n",
    "\n",
    "        # C\n",
    "        all_commits = get_all_commits(fault_dir)\n",
    "        \n",
    "        # C_susp\n",
    "        C_susp = [\n",
    "            c for c in all_commits if c in vote_df.index\n",
    "        ]\n",
    "        scores = [float(vote_df.loc[c, \"vote\"]) for c in C_susp]\n",
    "\n",
    "        # C_BIC\n",
    "        C_BIC = [\n",
    "            c for c in all_commits\n",
    "            if c in vote_df.index and c not in style_change_commits\n",
    "        ]\n",
    "        simul_rows.append([\n",
    "            row.pid,\n",
    "            row.vid,\n",
    "            rank_of_BIC,\n",
    "            standard_bisection(all_commits, BIC),\n",
    "            standard_bisection(C_susp, BIC),\n",
    "            standard_bisection(C_BIC, BIC),\n",
    "            weighted_bisection(C_susp, scores, BIC)\n",
    "        ])\n",
    "        # print(simul_rows[-1])\n",
    "\n",
    "    simul_df = pd.DataFrame(data=simul_rows, columns=[\"pid\", \"vid\",\n",
    "        \"rank_of_BIC\",\n",
    "        \"standard_bisection_on_C\",\n",
    "        \"standard_bisection_on_C_susp\",\n",
    "        \"standard_bisection_on_C_BIC\",\n",
    "        \"weighted_bisection\"]\n",
    "    )\n",
    "    simul_df.to_csv(savepath, index=False)\n",
    "    print(f\"Saved to {savepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simul_jdf = simul_df.sort_values(by=\"rank_of_BIC\").join(\n",
    "    ss_df.set_index([\"pid\", \"vid\"]), on = [\"pid\", \"vid\"])\n",
    "simul_jdf[\"saving\"] = simul_jdf[\"standard_bisection_on_C_BIC\"] - simul_jdf[\"weighted_bisection\"]\n",
    "simul_jdf[\"rankPercentage\"] = (simul_jdf.rank_of_BIC) / simul_jdf[\"C_BIC\"]\n",
    "\n",
    "print(simul_jdf[[\"rankPercentage\", \"saving\"]].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_col = \"weighted_bisection\"\n",
    "for b_col in [\"standard_bisection_on_C\", \"standard_bisection_on_C_BIC\"]:\n",
    "    print(\"lose,draw,win\")\n",
    "    print((\n",
    "        (simul_df[b_col] <  simul_df[w_col]).sum(),\\\n",
    "        (simul_df[b_col] == simul_df[w_col]).sum(),\\\n",
    "        (simul_df[b_col] >  simul_df[w_col]).sum()\n",
    "    ))\n",
    "\n",
    "    cost_saving = simul_df[b_col] - simul_df[w_col]\n",
    "    print(\"Avg. Reduction\", 1 - (simul_df[w_col]/simul_df[b_col]).mean().round(2))\n",
    "    reduced = (cost_saving > 0).mean()\n",
    "    same = (cost_saving == 0).mean()\n",
    "    increased = (cost_saving < 0).mean()\n",
    "\n",
    "    # print(cost_saving.sort_values())\n",
    "\n",
    "    plt.figure(figsize=(9, 2))\n",
    "    plt.title(\"# saved search iterations by changing the search algorithm to the weighted bisection\")\n",
    "\n",
    "    cost_saving = list(reversed(sorted(cost_saving.tolist())))\n",
    "\n",
    "    w, p = wilcoxon(cost_saving)\n",
    "    #To confirm that the median of the differences can be assumed to be positive, we use:\n",
    "    w, p = wilcoxon(cost_saving, alternative='greater')\n",
    "    print(\"Wilcoxon signed rank test\", w, p)\n",
    "    N = len(cost_saving)\n",
    "\n",
    "    plt.bar(range(0, N), cost_saving,\n",
    "        color=[\"red\" if d < 0 else \"green\" for d in cost_saving])\n",
    "    plt.axhline(0, color=\"black\")\n",
    "\n",
    "    plt.yticks(range(min(cost_saving), max(cost_saving)+1))\n",
    "\n",
    "    plt.axvspan(-0.5, N * reduced - 0.5, facecolor='green', alpha=0.1)\n",
    "    plt.axvspan(N * (reduced + same)-0.5, N-0.5, facecolor='red', alpha=0.1)\n",
    "\n",
    "    if reduced > 0.05:\n",
    "        plt.text(N * reduced/2 - 0.5, max(cost_saving)-1, f\"{reduced*100:.1f}%\", horizontalalignment=\"center\")\n",
    "    if same > 0.05:\n",
    "        plt.text(N * (reduced + same/2) - 0.5, max(cost_saving)-1, f\"{same*100:.1f}%\", horizontalalignment=\"center\")\n",
    "    if increased > 0.05:\n",
    "        plt.text(N * (reduced + same + increased/2) - 0.5, max(cost_saving)-1, f\"{increased*100:.1f}%\", horizontalalignment=\"center\")\n",
    "\n",
    "    plt.xlim((0-0.5, N-0.5))\n",
    "    ax = plt.gca()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "\n",
    "    if b_col == \"standard_bisection_on_C\":\n",
    "        plt.axhline(np.mean(cost_saving), color=\"black\", linestyle=\"--\", label=f\"Average Saved Iterations: {np.mean(cost_saving).round(1)}\")\n",
    "        print(\"Average # Saved Iterations\", np.mean(cost_saving))\n",
    "        plt.legend(loc=\"upper right\")\n",
    "\n",
    "    savepath = os.path.join(RESULTS_DIR,\n",
    "        f\"RQ2_cost_saving_by_{w_col}_compared_to_{b_col}.pdf\")\n",
    "    plt.savefig(savepath, bbox_inches=\"tight\")\n",
    "    print(f\"Saved to {savepath}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Research Question 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "hp = {\n",
    "    \"tool\": \"git\",\n",
    "    \"formula\": \"Ochiai\",\n",
    "    \"voting\": \"max-0\",\n",
    "    \"decay\": 0.1,\n",
    "    \"score_level\": \"line\",\n",
    "    \"stage2\": True,\n",
    "}\n",
    "\n",
    "savepath = os.path.join(RESULTS_DIR, \"RQ3_FL_and_Fonte.csv\")\n",
    "if os.path.exists(savepath):\n",
    "    print(f\"{savepath} exists\")\n",
    "    fl_df = pd.read_csv(savepath)\n",
    "    fl_df[\"vid\"] = fl_df[\"vid\"].astype(str)\n",
    "else:\n",
    "    with open(\"data/Defects4J/buggy_methods.json\", \"r\") as f:\n",
    "        buggy_method_infos = json.load(f)\n",
    "\n",
    "    fl_rows = []\n",
    "    for _, row in tqdm(GT.iterrows(), total=GT.shape[0]):\n",
    "        fault = (row.pid, row.vid)\n",
    "\n",
    "        if fault not in fault_dirs:\n",
    "            continue\n",
    "\n",
    "        BIC = row.commit\n",
    "        fault_dir = fault_dirs[fault]\n",
    "\n",
    "        # get commit_ranking\n",
    "        style_change_commits = get_style_change_commits(\n",
    "            fault_dir, hp[\"tool\"], with_Rewrite=True) if hp[\"stage2\"] else []\n",
    "\n",
    "        for in_class_only in [True, False]:\n",
    "            vote_df = vote_for_commits(fault_dir, hp[\"tool\"], hp[\"formula\"],\n",
    "                hp[\"decay\"], voting_functions[hp[\"voting\"]],\n",
    "                use_method_level_score=(hp[\"score_level\"] == \"method\"),\n",
    "                excluded=style_change_commits, in_class_only=in_class_only)\n",
    "            rank_of_BIC = vote_df.vote.rank(ascending=False, method=\"max\")[BIC]\n",
    "            path_to_coverage = os.path.join(fault_dir, \"coverage.pkl\")\n",
    "            FL_results, cov_df = get_sbfl_scores_from_coverage(path_to_coverage,\n",
    "                formula=hp[\"formula\"], use_cache=False, in_class_only=in_class_only,\n",
    "                return_coverage_matrix=True)\n",
    "            num_used_tests = cov_df.shape[0]\n",
    "            mFL = FL_results[\"score\"].groupby(\n",
    "                [\"class_file\", \"method_name\", \"method_signature\"]).max().to_frame()\n",
    "            mFL[\"rank\"] = mFL[\"score\"].rank(\n",
    "                ascending=False, method=\"max\")\n",
    "            mFL[\"rank_percentage\"] = (mFL[\"rank\"]-1)/mFL.shape[0]\n",
    "            mFL = mFL.reset_index()\n",
    "            mFL[\"arg_types\"] = mFL[\"method_signature\"].apply(\n",
    "                lambda s: s.split(')')[0][1:]\n",
    "            )\n",
    "            buggy_methods = [\n",
    "                (bm[\"class_file\"], bm[\"method_name\"], bm[\"arg_types\"])\n",
    "                for bm in buggy_method_infos[f\"{row.pid}-{row.vid}b\"]\n",
    "            ]\n",
    "            if len(buggy_methods) == 0:\n",
    "                print(f\"{fault}: No buggy method info\")\n",
    "                continue\n",
    "            mFL = mFL.set_index([\"class_file\", \"method_name\", \"arg_types\"])[\n",
    "                [\"rank\", \"rank_percentage\"]]\n",
    "\n",
    "            for bm in buggy_methods:\n",
    "                if bm in mFL.index:\n",
    "                    fl_rows.append([row.pid, row.vid, in_class_only, num_used_tests, bm, mFL.loc[bm, \"rank\"].min(), mFL.loc[bm, \"rank_percentage\"].min(), rank_of_BIC])\n",
    "                else:\n",
    "                    print(f\"{fault}: {bm} is not in the coverage matrix\")\n",
    "                    display(mFL.loc[bm[0]])\n",
    "\n",
    "    fl_df = pd.DataFrame(data=fl_rows,\n",
    "        columns=[\"pid\", \"vid\", \"in_class_only\", \"num_used_tests\", \"buggy_method\", \"buggy_method_rank\", \"buggy_method_rank_percentage\", \"BIC_rank\"])\n",
    "    fl_df.to_csv(savepath, index=False)\n",
    "    print(f\"Saved to {savepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_mdf = fl_df.groupby([\"pid\", \"vid\", \"in_class_only\"]).min()\n",
    "\n",
    "pivoted = fl_mdf.reset_index().pivot([\"pid\", \"vid\"], \"in_class_only\")\n",
    "increased = pivoted.index[pivoted[(\"buggy_method_rank\", False)] < pivoted[(\"buggy_method_rank\", True)]].tolist()\n",
    "print(f\"FL accuracy is increased in {len(increased)} subjects\")\n",
    "\n",
    "BIC_rank = pivoted.loc[increased, (\"BIC_rank\", True)]\n",
    "BIC_rank.name = \"with_T_prime\"\n",
    "BIC_rank = BIC_rank.to_frame()\n",
    "BIC_rank[\"with_T\"] = pivoted.loc[increased, (\"BIC_rank\", False)]\n",
    "BIC_rank[\"diff\"] = BIC_rank[\"with_T\"] - BIC_rank[\"with_T_prime\"]\n",
    "\n",
    "\n",
    "savepath = os.path.join(RESULTS_DIR, \"RQ3_comparison.pdf\")\n",
    "plt.figure(figsize=(6, 2.5))\n",
    "plt.plot([0, BIC_rank.max().max()], [0, BIC_rank.max().max()], color=\"grey\",\n",
    "    linestyle=\"dashed\")\n",
    "sns.scatterplot(data=BIC_rank[BIC_rank[\"diff\"] < 0],\n",
    "    y=\"with_T_prime\", x=\"with_T\", color=\"green\")\n",
    "sns.scatterplot(data=BIC_rank[BIC_rank[\"diff\"] == 0],\n",
    "    y=\"with_T_prime\", x=\"with_T\", color=\"grey\")\n",
    "sns.scatterplot(data=BIC_rank[BIC_rank[\"diff\"] > 0],\\\n",
    "    y=\"with_T_prime\", x=\"with_T\", color=\"red\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"BIC rank w/ more accurate FL\")\n",
    "plt.ylabel(\"BIC rank w/ less accruate FL\")\n",
    "plt.savefig(savepath, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(f\"Saved to {savepath}\")\n",
    "\n",
    "w, p = wilcoxon(BIC_rank[\"diff\"], alternative='less')\n",
    "print(\"Wilcoxon signed rank test\", w, p)\n",
    "\n",
    "for n in [1,2,3,5,10]:\n",
    "    print(f\"Acc@{n} {(BIC_rank['with_T'] <= n).sum()}/{len(increased)} -> {(BIC_rank['with_T_prime'] <= n).sum()}/{len(increased)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Industrial Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_rows = []\n",
    "for filename in os.listdir(INDUSTRY_DATA_DIR):\n",
    "    if not filename.endswith(\".csv\"):\n",
    "        continue\n",
    "    df = pd.read_csv(os.path.join(INDUSTRY_DATA_DIR, filename), float_precision=\"high\")\n",
    "    assert df.is_BIC.sum() == 1\n",
    "    df[\"rank\"] = df.score.rank(ascending=False, method=\"max\").astype(int)\n",
    "    df[\"submitted\"] = pd.to_datetime(df[\"submitted\"])\n",
    "    df.sort_values(by=\"submitted\", ascending=False, inplace=True)\n",
    "    BIC = df[df.is_BIC == 1][\"change_id\"].values[0]\n",
    "    BIC_rank = df[df.is_BIC == 1][\"rank\"].values[0]\n",
    "    changes = df.change_id.tolist()\n",
    "    scores = df.score.tolist()\n",
    "    ind_rows.append([filename, BIC_rank, len(changes),\n",
    "        standard_bisection(changes, BIC),\n",
    "        weighted_bisection(changes, scores, BIC)])\n",
    "\n",
    "ind_df = pd.DataFrame(ind_rows, columns=[\"filename\", \"rank\", \"total\",\n",
    "    \"standard_bisection\", \"weighted_bisection\"])\n",
    "ind_df[\"saving\"] = ind_df[\"standard_bisection\"] - ind_df[\"weighted_bisection\"]\n",
    "print(\"============= Fonte ==============\")\n",
    "print(f\"MRR: {(1/ind_df['rank']).mean():.3f}\")\n",
    "for n in [1,2,3,5,10]:\n",
    "    print(f\"acc@{n}: {(ind_df['rank'] <= n).sum()}/{ind_df.shape[0]} ({(ind_df['rank'] <= n).sum()/ind_df.shape[0]*100:.0f}%)\")\n",
    "\n",
    "print(\"============= Random ==============\")\n",
    "\n",
    "ind_df[\"random_rank\"] = (ind_df.total + 1)/2\n",
    "print(f\"MRR: {(1/ind_df['random_rank']).mean():.3f}\")\n",
    "for n in [1,2,3,5,10]:\n",
    "    print(f\"acc@{n}: {(ind_df['random_rank'] <= n).sum()}/{ind_df.shape[0]} ({(ind_df['random_rank'] <= n).sum()/ind_df.shape[0]*100:.0f}%)\")\n",
    "\n",
    "print(\"============= MRR Improvement ==============\")\n",
    "print((1/ind_df['rank']).mean()/(1/ind_df['random_rank']).mean())\n",
    "\n",
    "print(\"============= Weighted Bisection ==============\")\n",
    "print(\"Lose\", (ind_df.saving < 0).sum(), (ind_df.saving < 0).mean().round(2))   # Lose\n",
    "print(\"Draw\", (ind_df.saving == 0).sum(), (ind_df.saving == 0).mean().round(2)) # Draw\n",
    "print(\"Win\", (ind_df.saving > 0).sum(), (ind_df.saving > 0).mean().round(2))   # Win\n",
    "\n",
    "print(f\"Avg. # commits in a batch: {ind_df.total.mean()}\")\n",
    "\n",
    "ind_df.standard_bisection.mean(), ind_df.weighted_bisection.mean(), ind_df.saving.mean()\n",
    "\n",
    "\"Avg. Reduction\", (1 - (ind_df.weighted_bisection/ind_df.standard_bisection).mean()).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('fonte-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d3582efeacc6ca267dfa9aca45da3d9b971c6edc7d188114c9f7e5e6055563f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
