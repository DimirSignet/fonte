{"sha": "d44620d208a423dc5c2d7db5ac49683ccd6da20e", "log": "Allow tokenizer state to be adjusted before and after tokenizing  ", "commit": "\n--- a/src/java/org/apache/commons/lang/text/StrTokenizer.java\n+++ b/src/java/org/apache/commons/lang/text/StrTokenizer.java\n package org.apache.commons.lang.text;\n \n import java.util.ArrayList;\n+import java.util.Collections;\n import java.util.List;\n import java.util.ListIterator;\n import java.util.NoSuchElementException;\n-\n-import org.apache.commons.lang.ArrayUtils;\n \n /**\n  * Tokenizes a string based based on delimiters (separators)\n         TSV_TOKENIZER_PROTOTYPE.setIgnoreEmptyTokens(false);\n     }\n \n-    /** The text to work on */\n+    /** The text to work on. */\n     private char chars[];\n-    /** The input text, null if char[] input */\n-    private String text;\n     /** The parsed tokens */\n     private String tokens[];\n     /** The current iteration position */\n      */\n     public StrTokenizer() {\n         super();\n-        this.text = \"\";\n-        this.chars = new char[0];\n+        this.chars = null;\n     }\n \n     /**\n      */\n     public StrTokenizer(String input) {\n         super();\n-        text = input;\n         if (input != null) {\n             chars = input.toCharArray();\n         } else {\n      */\n     public StrTokenizer(char[] input) {\n         super();\n-        this.text = null;\n         this.chars = input;\n     }\n \n      * @return the number of matched tokens\n      */\n     public int size() {\n-        tokenize();\n+        checkTokenized();\n         return tokens.length;\n     }\n \n      * @return the tokens as a String array\n      */\n     public String[] getTokenArray() {\n-        tokenize();\n+        checkTokenized();\n         return (String[]) tokens.clone();\n     }\n \n      * @return the tokens as a String array\n      */\n     public List getTokenList() {\n-        tokenize();\n+        checkTokenized();\n         List list = new ArrayList(tokens.length);\n         for (int i = 0; i < tokens.length; i++) {\n             list.add(tokens[i]);\n      */\n     public StrTokenizer reset(String input) {\n         reset();\n-        text = input;\n         if (input != null) {\n-            chars = input.toCharArray();\n+            this.chars = input.toCharArray();\n         } else {\n-            chars = null;\n+            this.chars = null;\n         }\n         return this;\n     }\n      */\n     public StrTokenizer reset(char[] input) {\n         reset();\n-        text = null;\n-        chars = input;\n+        this.chars = input;\n         return this;\n     }\n \n      * @return true if there are more tokens\n      */\n     public boolean hasNext() {\n-        tokenize();\n+        checkTokenized();\n         return tokenPos < tokens.length;\n     }\n \n      * @return true if there are previous tokens\n      */\n     public boolean hasPrevious() {\n-        tokenize();\n+        checkTokenized();\n         return tokenPos > 0;\n     }\n \n     // Implementation\n     //-----------------------------------------------------------------------\n     /**\n-     * Performs the tokenization if it hasn't already been done.\n-     */\n-    private void tokenize() {\n+     * Checks if tokenization has been done, and if not then do it.\n+     */\n+    private void checkTokenized() {\n         if (tokens == null) {\n-            tokens = readTokens();\n-        }\n-    }\n-\n-    /**\n-     * Read all the tokens.\n+            if (chars == null) {\n+                // still call tokenize as subclass may do some work\n+                List split = tokenize(null, 0, 0);\n+                tokens = (String[]) split.toArray(new String[split.size()]);\n+            } else {\n+                List split = tokenize(chars, 0, chars.length);\n+                tokens = (String[]) split.toArray(new String[split.size()]);\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Internal method to performs the tokenization.\n+     * <p>\n+     * Most users of this class do not need to call this method. This method\n+     * will be called automatically by other (public) methods when required.\n+     * <p>\n+     * This method exists to allow subclasses to add code before or after the\n+     * tokenization. For example, a subclass could alter the character array,\n+     * offset or count to be parsed, or call the tokenizer multiple times on\n+     * multiple strings. It is also be possible to filter the results.\n+     * <p>\n+     * <code>StrTokenizer</code> will always pass a zero offset and a count\n+     * equal to the length of the array to this method, however a subclass\n+     * may pass other values, or even an entirely different array.\n      * \n-     * @return array containing the tokens.\n-     */\n-    private String[] readTokens() {\n-        if (chars == null) {\n-            return ArrayUtils.EMPTY_STRING_ARRAY;\n-        }\n-        int len = chars.length;\n-        if (len == 0) {\n-            return ArrayUtils.EMPTY_STRING_ARRAY;\n+     * @param chars  the character array being tokenized, may be null\n+     * @param offset  the start position within the character array, must be valid\n+     * @param count  the number of characters to tokenize, must be valid\n+     * @return the modifiable list of String tokens, unmodifiable if null array or zero count\n+     */\n+    protected List tokenize(char[] chars, int offset, int count) {\n+        if (chars == null || count == 0) {\n+            return Collections.EMPTY_LIST;\n         }\n         StrBuilder buf = new StrBuilder();\n         List tokens = new ArrayList();\n-        int start = 0;\n+        int pos = offset;\n         \n         // loop around the entire buffer\n-        while (start >= 0 && start < len) {\n+        while (pos >= 0 && pos < count) {\n             // find next token\n-            start = readNextToken(chars, start, len, buf, tokens);\n+            pos = readNextToken(chars, pos, count, buf, tokens);\n             \n             // handle case where end of string is a delimiter\n-            if (start >= len) {\n+            if (pos >= count) {\n                 addToken(tokens, \"\");\n             }\n         }\n-        return (String[]) tokens.toArray(new String[tokens.size()]);\n+        return tokens;\n     }\n \n     /**\n      * @return the string content being parsed\n      */\n     public String getContent() {\n-        if (text == null) {\n-            text = new String(chars);\n-        }\n-        return text;\n+        return new String(chars);\n     }\n \n     //-----------------------------------------------------------------------\n--- a/src/test/org/apache/commons/lang/text/StrTokenizerTest.java\n+++ b/src/test/org/apache/commons/lang/text/StrTokenizerTest.java\n package org.apache.commons.lang.text;\n \n import java.util.Arrays;\n+import java.util.Collections;\n import java.util.List;\n import java.util.NoSuchElementException;\n \n     public void testGetContent() {\n         String input = \"a   b c \\\"d e\\\" f \";\n         StrTokenizer tok = new StrTokenizer(input);\n-        assertSame(input, tok.getContent());\n+        assertEquals(input, tok.getContent());\n \n         tok = new StrTokenizer(input.toCharArray());\n         assertEquals(input, tok.getContent());\n         assertEquals(false, tkn.hasNext());\n     }\n \n+    //-----------------------------------------------------------------------\n+    public void testTokenizeSubclassInputChange() {\n+        StrTokenizer tkn = new StrTokenizer(\"a b c d e\") {\n+            protected List tokenize(char[] chars, int offset, int count) {\n+                return super.tokenize(\"w x y z\".toCharArray(), 2, 5);\n+            }\n+        };\n+        assertEquals(\"x\", tkn.next());\n+        assertEquals(\"y\", tkn.next());\n+    }\n+\n+    //-----------------------------------------------------------------------\n+    public void testTokenizeSubclassOutputChange() {\n+        StrTokenizer tkn = new StrTokenizer(\"a b c\") {\n+            protected List tokenize(char[] chars, int offset, int count) {\n+                List list = super.tokenize(chars, offset, count);\n+                Collections.reverse(list);\n+                return list;\n+            }\n+        };\n+        assertEquals(\"c\", tkn.next());\n+        assertEquals(\"b\", tkn.next());\n+        assertEquals(\"a\", tkn.next());\n+    }\n+\n }", "timestamp": 1153589138, "metainfo": ""}