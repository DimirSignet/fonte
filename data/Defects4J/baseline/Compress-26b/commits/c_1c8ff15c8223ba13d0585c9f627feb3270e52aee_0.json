{"sha": "1c8ff15c8223ba13d0585c9f627feb3270e52aee", "log": "merge from trunk  ", "commit": "\n--- a/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveInputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveInputStream.java\n \n         byte[] headerBuf = getRecord();\n \n-        if (hasHitEOF) {\n+        if (headerBuf == null) {\n+            /* hit EOF */\n             currEntry = null;\n             return null;\n         }\n      * over any remaining data in the current entry, if there\n      * is one, and place the input stream at the header of the\n      * next entry.\n-     * If there are no more entries in the archive, null will\n-     * be returned to indicate that the end of the archive has\n-     * been reached.\n+     *\n+     * <p>If there are no more entries in the archive, null will be\n+     * returned to indicate that the end of the archive has been\n+     * reached.  At the same time the {@code hasHitEOF} marker will be\n+     * set to true.</p>\n      *\n      * @return The next header in the archive, or null.\n      * @throws IOException on error\n      */\n     private byte[] getRecord() throws IOException {\n-        if (hasHitEOF) {\n-            return null;\n-        }\n-\n-        byte[] headerBuf = buffer.readRecord();\n-\n-        if (buffer.isEOFRecord(headerBuf)) {\n-            hasHitEOF = true;\n-            if (headerBuf != null) {\n+        byte[] headerBuf = null;\n+        if (!hasHitEOF) {\n+            headerBuf = buffer.readRecord();\n+            hasHitEOF = buffer.isEOFRecord(headerBuf);\n+            if (hasHitEOF && headerBuf != null) {\n                 buffer.tryToConsumeSecondEOFRecord();\n-            }\n-        }\n-\n-        return hasHitEOF ? null : headerBuf;\n+                headerBuf = null;\n+            }\n+        }\n+\n+        return headerBuf;\n     }\n \n     private void paxHeaders() throws IOException{\n             TarArchiveSparseEntry entry;\n             do {\n                 byte[] headerBuf = getRecord();\n-                if (hasHitEOF) {\n+                if (headerBuf == null) {\n                     currEntry = null;\n                     break;\n                 }\n--- a/src/main/java/org/apache/commons/compress/archivers/tar/TarBuffer.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarBuffer.java\n     /** Default block size */\n     public static final int DEFAULT_BLKSIZE = (DEFAULT_RCDSIZE * 20);\n \n+    private static final byte[] DEFAULT_EOF_RECORD = new byte[DEFAULT_RCDSIZE];\n+\n     // TODO make these final? (would need to change close() method)\n     private InputStream     inStream;\n     private OutputStream    outStream;\n     private final int             recordSize;\n     private final int             recsPerBlock;\n     private final byte[]          blockBuffer;\n+    private final byte[]          eofRecord;\n \n     private int             currBlkIdx;\n     private int             currRecIdx;\n         this.recordSize = recordSize;\n         this.recsPerBlock = (this.blockSize / this.recordSize);\n         this.blockBuffer = new byte[this.blockSize];\n+        this.eofRecord = recordSize == DEFAULT_RCDSIZE\n+            ? DEFAULT_EOF_RECORD : new byte[recordSize];\n \n         if (this.inStream != null) {\n             this.currBlkIdx = -1;\n      * @return true if the record data is an End of Archive\n      */\n     public boolean isEOFRecord(byte[] record) {\n-        if (record != null) {\n-            for (int i = 0, sz = getRecordSize(); i < sz; ++i) {\n-                if (record[i] != 0) {\n-                    return false;\n-                }\n-            }\n-        }\n-        return true;\n+        return record == null || Arrays.equals(record, eofRecord);\n     }\n \n     /**\n--- a/src/main/java/org/apache/commons/compress/archivers/zip/UnicodeCommentExtraField.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/UnicodeCommentExtraField.java\n  * <p>Stores the UTF-8 version of the file comment as stored in the\n  * central directory header.</p>\n  *\n- * <pre>\n- *         Value         Size        Description\n- *         -----         ----        -----------\n- *  (UCom) 0x6375        Short       tag for this extra block type (\"uc\")\n- *         TSize         Short       total data size for this block\n- *         Version       1 byte      version of this extra field, currently 1\n- *         ComCRC32      4 bytes     Comment Field CRC32 Checksum\n- *         UnicodeCom    Variable    UTF-8 version of the entry comment\n- * </pre>\n+ * <p>See {@link\n+ * \"http://www.pkware.com/documents/casestudies/APPNOTE.TXT PKWARE's\n+ * APPNOTE.TXT, section 4.6.8\"}.</p>\n+ *\n  * @NotThreadSafe super-class is not thread-safe\n  */\n public class UnicodeCommentExtraField extends AbstractUnicodeExtraField {\n--- a/src/main/java/org/apache/commons/compress/archivers/zip/UnicodePathExtraField.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/UnicodePathExtraField.java\n  * <p>Stores the UTF-8 version of the file name field as stored in the \n  * local header and central directory header.</p>\n  *\n- * <pre>\n- *         Value         Size        Description\n- *         -----         ----        -----------\n- * (UPath) 0x7075        Short       tag for this extra block type (\"up\")\n- *         TSize         Short       total data size for this block\n- *         Version       1 byte      version of this extra field, currently 1\n- *         NameCRC32     4 bytes     File Name Field CRC32 Checksum\n- *         UnicodeName   Variable    UTF-8 version of the entry File Name\n- * </pre>\n+ * <p>See {@link\n+ * \"http://www.pkware.com/documents/casestudies/APPNOTE.TXT PKWARE's\n+ * APPNOTE.TXT, section 4.6.9\"}.</p>\n  * @NotThreadSafe super-class is not thread-safe\n  */\n public class UnicodePathExtraField extends AbstractUnicodeExtraField {\n--- a/src/main/java/org/apache/commons/compress/archivers/zip/Zip64ExtendedInformationExtraField.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/Zip64ExtendedInformationExtraField.java\n  * Holds size and other extended information for entries that use Zip64\n  * features.\n  *\n- * <p>From {@link \"http://www.pkware.com/documents/casestudies/APPNOTE.TXT PKWARE's APPNOTE.TXT\"}\n- * <pre>\n- * Zip64 Extended Information Extra Field (0x0001):\n- *\n- *          The following is the layout of the zip64 extended \n- *          information \"extra\" block. If one of the size or\n- *          offset fields in the Local or Central directory\n- *          record is too small to hold the required data,\n- *          a Zip64 extended information record is created.\n- *          The order of the fields in the zip64 extended \n- *          information record is fixed, but the fields will\n- *          only appear if the corresponding Local or Central\n- *          directory record field is set to 0xFFFF or 0xFFFFFFFF.\n- *\n- *          Note: all fields stored in Intel low-byte/high-byte order.\n- *\n- *          Value      Size       Description\n- *          -----      ----       -----------\n- *  (ZIP64) 0x0001     2 bytes    Tag for this \"extra\" block type\n- *          Size       2 bytes    Size of this \"extra\" block\n- *          Original \n- *          Size       8 bytes    Original uncompressed file size\n- *          Compressed\n- *          Size       8 bytes    Size of compressed data\n- *          Relative Header\n- *          Offset     8 bytes    Offset of local header record\n- *          Disk Start\n- *          Number     4 bytes    Number of the disk on which\n- *                                this file starts \n- *\n- *          This entry in the Local header must include BOTH original\n- *          and compressed file size fields. If encrypting the \n- *          central directory and bit 13 of the general purpose bit\n- *          flag is set indicating masking, the value stored in the\n- *          Local Header for the original file size will be zero.\n- * </pre></p>\n+ * <p>See {@link\n+ * \"http://www.pkware.com/documents/casestudies/APPNOTE.TXT PKWARE's\n+ * APPNOTE.TXT, section 4.5.3\"}.</p>\n  *\n  * <p>Currently Commons Compress doesn't support encrypting the\n  * central directory so the note about masking doesn't apply.</p>\n--- a/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveInputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveInputStream.java\n \n     private static final int LFH_LEN = 30;\n     /*\n-      local file header signature     4 bytes  (0x04034b50)\n-      version needed to extract       2 bytes\n-      general purpose bit flag        2 bytes\n-      compression method              2 bytes\n-      last mod file time              2 bytes\n-      last mod file date              2 bytes\n-      crc-32                          4 bytes\n-      compressed size                 4 bytes\n-      uncompressed size               4 bytes\n-      file name length                2 bytes\n-      extra field length              2 bytes\n+      local file header signature     WORD\n+      version needed to extract       SHORT\n+      general purpose bit flag        SHORT\n+      compression method              SHORT\n+      last mod file time              SHORT\n+      last mod file date              SHORT\n+      crc-32                          WORD\n+      compressed size                 WORD\n+      uncompressed size               WORD\n+      file name length                SHORT\n+      extra field length              SHORT\n     */\n \n     private static final int CFH_LEN = 46;\n     /*\n-        central file header signature   4 bytes  (0x02014b50)\n-        version made by                 2 bytes\n-        version needed to extract       2 bytes\n-        general purpose bit flag        2 bytes\n-        compression method              2 bytes\n-        last mod file time              2 bytes\n-        last mod file date              2 bytes\n-        crc-32                          4 bytes\n-        compressed size                 4 bytes\n-        uncompressed size               4 bytes\n-        file name length                2 bytes\n-        extra field length              2 bytes\n-        file comment length             2 bytes\n-        disk number start               2 bytes\n-        internal file attributes        2 bytes\n-        external file attributes        4 bytes\n-        relative offset of local header 4 bytes\n+        central file header signature   WORD\n+        version made by                 SHORT\n+        version needed to extract       SHORT\n+        general purpose bit flag        SHORT\n+        compression method              SHORT\n+        last mod file time              SHORT\n+        last mod file date              SHORT\n+        crc-32                          WORD\n+        compressed size                 WORD\n+        uncompressed size               WORD\n+        file name length                SHORT\n+        extra field length              SHORT\n+        file comment length             SHORT\n+        disk number start               SHORT\n+        internal file attributes        SHORT\n+        external file attributes        WORD\n+        relative offset of local header WORD\n     */\n \n     private static final long TWO_EXP_32 = ZIP64_MAGIC + 1;\n     }\n \n     // End of Central Directory Record\n-    //   end of central dir signature    4 bytes  (0x06054b50)\n-    //   number of this disk             2 bytes\n+    //   end of central dir signature    WORD\n+    //   number of this disk             SHORT\n     //   number of the disk with the\n-    //   start of the central directory  2 bytes\n+    //   start of the central directory  SHORT\n     //   total number of entries in the\n-    //   central directory on this disk  2 bytes\n+    //   central directory on this disk  SHORT\n     //   total number of entries in\n-    //   the central directory           2 bytes\n-    //   size of the central directory   4 bytes\n+    //   the central directory           SHORT\n+    //   size of the central directory   WORD\n     //   offset of start of central\n     //   directory with respect to\n-    //   the starting disk number        4 bytes\n-    //   .ZIP file comment length        2 bytes\n-    //   .ZIP file comment       (variable size)\n+    //   the starting disk number        WORD\n+    //   .ZIP file comment length        SHORT\n+    //   .ZIP file comment               up to 64KB\n     //\n \n     /**\n--- a/src/main/java/org/apache/commons/compress/archivers/sevenz/Coders.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/sevenz/Coders.java\n import javax.crypto.spec.SecretKeySpec;\n \n import org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;\n+import org.tukaani.xz.LZMAInputStream;\n import org.tukaani.xz.LZMA2InputStream;\n \n class Coders {\n     \n     static CoderId[] coderTable = new CoderId[] {\n         new CoderId(new byte[] { (byte)0x00 }, new CopyDecoder()),\n+        new CoderId(new byte[] { (byte)0x03, (byte)0x01, (byte)0x01 }, new LZMADecoder()),\n         new CoderId(new byte[] { (byte)0x21 }, new LZMA2Decoder()),\n         // FIXME: gives corrupt output\n         //new CoderId(new byte[] { (byte)0x04, (byte)0x01, (byte)0x08 }, new DeflateDecoder()),\n                 dictionarySize = (2 | (dictionarySizeBits & 0x1)) << (dictionarySizeBits / 2 + 11);\n             }\n             return new LZMA2InputStream(in, dictionarySize);\n+        }\n+    }\n+    \n+    static class LZMADecoder extends CoderBase {\n+        @Override\n+        InputStream decode(final InputStream in, final Coder coder,\n+                String password) throws IOException {\n+            byte propsByte = coder.properties[0];\n+            long dictSize = coder.properties[1];\n+            for (int i = 1; i < 4; i++) {\n+                dictSize |= (coder.properties[i + 1] << (8 * i));\n+            }\n+            if (dictSize > LZMAInputStream.DICT_SIZE_MAX) {\n+                throw new IOException(\"Dictionary larger than 4GiB maximum size\");\n+            }\n+            return new LZMAInputStream(in, -1, propsByte, (int) dictSize);\n         }\n     }\n     \n--- a/src/main/java/org/apache/commons/compress/compressors/CompressorStreamFactory.java\n+++ b/src/main/java/org/apache/commons/compress/compressors/CompressorStreamFactory.java\n import org.apache.commons.compress.compressors.bzip2.BZip2CompressorOutputStream;\n import org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream;\n import org.apache.commons.compress.compressors.gzip.GzipCompressorOutputStream;\n+import org.apache.commons.compress.compressors.lzma.LZMACompressorInputStream;\n import org.apache.commons.compress.compressors.xz.XZCompressorInputStream;\n import org.apache.commons.compress.compressors.xz.XZCompressorOutputStream;\n import org.apache.commons.compress.compressors.xz.XZUtils;\n      * @since 1.4\n      */\n     public static final String XZ = \"xz\";\n+\n+    /**\n+     * Constant used to identify the LZMA compression method.\n+     * @since 1.6\n+     */\n+    public static final String LZMA = \"lzma\";\n \n     private boolean decompressConcatenated = false;\n \n     /**\n      * Create a compressor input stream from a compressor name and an input stream.\n      * \n-     * @param name of the compressor, i.e. \"gz\", \"bzip2\", \"xz\", or \"pack200\"\n+     * @param name of the compressor, i.e. \"gz\", \"bzip2\", \"xz\", \"lzma\", or \"pack200\"\n      * @param in the input stream\n      * @return compressor input stream\n      * @throws CompressorException if the compressor name is not known\n \n             if (XZ.equalsIgnoreCase(name)) {\n                 return new XZCompressorInputStream(in);\n+            }\n+\n+            if (LZMA.equalsIgnoreCase(name)) {\n+                return new LZMACompressorInputStream(in);\n             }\n \n             if (PACK200.equalsIgnoreCase(name)) {\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/compressors/lzma/LZMACompressorInputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.compressors.lzma;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import org.tukaani.xz.LZMAInputStream;\n+\n+import org.apache.commons.compress.compressors.CompressorInputStream;\n+\n+/**\n+ * LZMA decompressor.\n+ * @since 1.6\n+ */\n+public class LZMACompressorInputStream extends CompressorInputStream {\n+    private final InputStream in;\n+\n+    /**\n+     * Creates a new input stream that decompresses LZMA-compressed data\n+     * from the specified input stream.\n+     *\n+     * @param       inputStream where to read the compressed data\n+     *\n+     * @throws      IOException if the input is not in the .lzma format,\n+     *                          the input is corrupt or truncated, the .lzma\n+     *                          headers specify sizes that are not supported\n+     *                          by this implementation, or the underlying\n+     *                          <code>inputStream</code> throws an exception\n+     */\n+    public LZMACompressorInputStream(InputStream inputStream)\n+            throws IOException {\n+        in = new LZMAInputStream(inputStream);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    public int read() throws IOException {\n+        int ret = in.read();\n+        count(ret == -1 ? -1 : 1);\n+        return ret;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    public int read(byte[] buf, int off, int len) throws IOException {\n+        int ret = in.read(buf, off, len);\n+        count(ret);\n+        return ret;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    public long skip(long n) throws IOException {\n+        return in.skip(n);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    public int available() throws IOException {\n+        return in.available();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    public void close() throws IOException {\n+        in.close();\n+    }\n+}\n--- a/src/test/java/org/apache/commons/compress/archivers/sevenz/SevenZFileTest.java\n+++ b/src/test/java/org/apache/commons/compress/archivers/sevenz/SevenZFileTest.java\n import org.apache.commons.compress.AbstractTestCase;\n \n public class SevenZFileTest extends AbstractTestCase {\n+    private static String TEST2_CONTENT = \"<?xml version = '1.0'?>\\r\\n<!DOCTYPE\"\n+        + \" connections>\\r\\n<meinxml>\\r\\n\\t<leer />\\r\\n</meinxml>\\n\";\n+\n     public void testAllEmptyFilesArchive() throws Exception {\n         SevenZFile archive = new SevenZFile(getFile(\"7z-empty-mhc-off.7z\"));\n         try {\n \n     public void testHelloWorldHeaderCompressionOffLZMA2() throws Exception {\n         checkHelloWorld(\"7z-hello-mhc-off-lzma2.7z\");\n+    }\n+\n+    public void test7zUnarchive() throws Exception {\n+        SevenZFile sevenZFile = new SevenZFile(getFile(\"bla.7z\"));\n+        try {\n+            SevenZArchiveEntry entry = sevenZFile.getNextEntry();\n+            assertEquals(\"test1.xml\", entry.getName());\n+            entry = sevenZFile.getNextEntry();\n+            assertEquals(\"test2.xml\", entry.getName());\n+            byte[] contents = new byte[(int)entry.getSize()];\n+            int off = 0;\n+            while ((off < contents.length)) {\n+                int bytesRead = sevenZFile.read(contents, off, contents.length - off);\n+                assert(bytesRead >= 0);\n+                off += bytesRead;\n+            }\n+            assertEquals(TEST2_CONTENT, new String(contents, \"UTF-8\"));\n+            assertNull(sevenZFile.getNextEntry());\n+        } finally {\n+            sevenZFile.close();\n+        }\n     }\n \n     private void checkHelloWorld(final String filename) throws Exception {\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/compress/compressors/LZMATestCase.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.compressors;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.InputStream;\n+\n+import org.apache.commons.compress.AbstractTestCase;\n+import org.apache.commons.compress.compressors.lzma.LZMACompressorInputStream;\n+import org.apache.commons.compress.utils.IOUtils;\n+\n+public final class LZMATestCase extends AbstractTestCase {\n+\n+    public void testLZMAUnarchive() throws Exception {\n+        final File input = getFile(\"bla.tar.lzma\");\n+        final File output = new File(dir, \"bla.tar\");\n+        final InputStream is = new FileInputStream(input);\n+        try {\n+            final CompressorInputStream in = new LZMACompressorInputStream(is);\n+            FileOutputStream out = null;\n+            try {\n+                out = new FileOutputStream(output);\n+                IOUtils.copy(in, out);\n+            } finally {\n+                if (out != null) {\n+                    out.close();\n+                }\n+                in.close();\n+            }\n+        } finally {\n+            is.close();\n+        }\n+    }\n+}", "timestamp": 1374071949, "metainfo": ""}