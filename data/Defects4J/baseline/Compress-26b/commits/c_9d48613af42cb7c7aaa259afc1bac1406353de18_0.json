{"sha": "9d48613af42cb7c7aaa259afc1bac1406353de18", "log": "Convenience overloads  ", "commit": "\n--- a/src/main/java/org/apache/commons/compress/compressors/pack200/Pack200Utils.java\n+++ b/src/main/java/org/apache/commons/compress/compressors/pack200/Pack200Utils.java\n import java.io.FileOutputStream;\n import java.io.IOException;\n import java.io.OutputStream;\n+import java.util.HashMap;\n import java.util.Map;\n import java.util.jar.JarFile;\n import java.util.jar.JarOutputStream;\n  */\n public class Pack200Utils {\n     private Pack200Utils() { }\n+\n+    /**\n+     * Normalizes a JAR archive in-place so it can be safely signed\n+     * and packed.\n+     *\n+     * <p>As stated in <a\n+     * href=\"http://download.oracle.com/javase/1.5.0/docs/api/java/util/jar/Pack200.Packer.html\">Pack200.Packer's</a>\n+     * javadocs applying a Pack200 compression to a JAR archive will\n+     * in general make its sigantures invalid.  In order to prepare a\n+     * JAR for signing it should be \"normalized\" by packing and\n+     * unpacking it.  This is what this method does.</p>\n+     *\n+     * <p>Note this methods implicitly sets the segment length to\n+     * -1.</p>\n+     *\n+     * @param jar the JAR archive to normalize\n+     */\n+    public static void normalize(File jar)\n+        throws IOException {\n+        normalize(jar, jar, null);\n+    }\n+\n+    /**\n+     * Normalizes a JAR archive in-place so it can be safely signed\n+     * and packed.\n+     *\n+     * <p>As stated in <a\n+     * href=\"http://download.oracle.com/javase/1.5.0/docs/api/java/util/jar/Pack200.Packer.html\">Pack200.Packer's</a>\n+     * javadocs applying a Pack200 compression to a JAR archive will\n+     * in general make its sigantures invalid.  In order to prepare a\n+     * JAR for signing it should be \"normalized\" by packing and\n+     * unpacking it.  This is what this method does.</p>\n+     *\n+     * @param jar the JAR archive to normalize\n+     * @param props properties to set for the pack operation.  This\n+     * method will implicitly set the segment limit to -1.\n+     */\n+    public static void normalize(File jar, Map<String, String> props)\n+        throws IOException {\n+        normalize(jar, jar, props);\n+    }\n+\n+    /**\n+     * Normalizes a JAR archive so it can be safely signed and packed.\n+     *\n+     * <p>As stated in <a\n+     * href=\"http://download.oracle.com/javase/1.5.0/docs/api/java/util/jar/Pack200.Packer.html\">Pack200.Packer's</a>\n+     * javadocs applying a Pack200 compression to a JAR archive will\n+     * in general make its sigantures invalid.  In order to prepare a\n+     * JAR for signing it should be \"normalized\" by packing and\n+     * unpacking it.  This is what this method does.</p>\n+     *\n+     * <p>This method does not replace the existing archive but creates\n+     * a new one.</p>\n+     *\n+     * <p>Note this methods implicitly sets the segment length to\n+     * -1.</p>\n+     *\n+     * @param from the JAR archive to normalize\n+     * @param to the normalized archive\n+     */\n+    public static void normalize(File from, File to)\n+        throws IOException {\n+        normalize(from, to, null);\n+    }\n \n     /**\n      * Normalizes a JAR archive so it can be safely signed and packed.\n      */\n     public static void normalize(File from, File to, Map<String, String> props)\n         throws IOException {\n+        if (props == null) {\n+            props = new HashMap<String, String>();\n+        }\n         props.put(Pack200.Packer.SEGMENT_LIMIT, \"-1\");\n         File f = File.createTempFile(\"commons-compress\", \"pack200normalize\");\n         f.deleteOnExit();\n--- a/src/test/java/org/apache/commons/compress/compressors/pack200/Pack200UtilsTest.java\n+++ b/src/test/java/org/apache/commons/compress/compressors/pack200/Pack200UtilsTest.java\n         }\n     }\n \n+    public void testNormalizeInPlace() throws Throwable {\n+        final File input = getFile(\"bla.jar\");\n+        final File[] output = createTempDirAndFile();\n+        try {\n+            FileInputStream is = new FileInputStream(input);\n+            OutputStream os = null;\n+            try {\n+                os = new FileOutputStream(output[1]);\n+                IOUtils.copy(is, os);\n+            } finally {\n+                is.close();\n+                if (os != null) {\n+                    os.close();\n+                }\n+            }\n+\n+            Pack200Utils.normalize(output[1]);\n+            is = new FileInputStream(output[1]);\n+            try {\n+                final ArchiveInputStream in = new ArchiveStreamFactory()\n+                    .createArchiveInputStream(\"jar\", is);\n+\n+                ArchiveEntry entry = in.getNextEntry();\n+                while (entry != null) {\n+                    File archiveEntry = new File(dir, entry.getName());\n+                    archiveEntry.getParentFile().mkdirs();\n+                    if (entry.isDirectory()) {\n+                        archiveEntry.mkdir();\n+                        entry = in.getNextEntry();\n+                        continue;\n+                    }\n+                    OutputStream out = new FileOutputStream(archiveEntry);\n+                    IOUtils.copy(in, out);\n+                    out.close();\n+                    entry = in.getNextEntry();\n+                }\n+\n+                in.close();\n+            } finally {\n+                is.close();\n+            }\n+        } finally {\n+            output[1].delete();\n+            output[0].delete();\n+        }\n+    }\n+\n }", "timestamp": 1316091505, "metainfo": ""}