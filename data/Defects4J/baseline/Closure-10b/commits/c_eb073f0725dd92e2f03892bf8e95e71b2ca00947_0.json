{"sha": "eb073f0725dd92e2f03892bf8e95e71b2ca00947", "log": "Allow spaces in the flag file fixes issue 709 Contributed by cpeisert  R=johnlenz DELTA=45  (37 added, 6 deleted, 2 changed)   Revision created by MOE tool push_codebase. MOE_MIGRATION=4557   ", "commit": "\n--- a/src/com/google/javascript/jscomp/CommandLineRunner.java\n+++ b/src/com/google/javascript/jscomp/CommandLineRunner.java\n import java.util.Map;\n import java.util.ResourceBundle;\n import java.util.Set;\n-import java.util.StringTokenizer;\n import java.util.logging.Level;\n import java.util.regex.Matcher;\n import java.util.regex.Pattern;\n     initConfigFromFlags(args, err);\n   }\n \n+  /**\n+   * Split strings into tokens delimited by whitespace, but treat quoted\n+   * strings as single tokens. Non-whitespace characters adjacent to quoted\n+   * strings will be returned as part of the token. For example, the string\n+   * {@code \"--js='/home/my project/app.js'\"} would be returned as a single\n+   * token.\n+   *\n+   * @param lines strings to tokenize\n+   * @return a list of tokens\n+   */\n+  private List<String> tokenizeKeepingQuotedStrings(List<String> lines) {\n+    List<String> tokens = Lists.newArrayList();\n+    Pattern tokenPattern =\n+        Pattern.compile(\"(?:[^ \\t\\f\\\\x0B'\\\"]|(?:'[^']*'|\\\"[^\\\"]*\\\"))+\");\n+\n+    for (String line : lines) {\n+      Matcher matcher = tokenPattern.matcher(line);\n+      while (matcher.find()) {\n+        tokens.add(matcher.group(0));\n+      }\n+    }\n+    return tokens;\n+  }\n+\n   private List<String> processArgs(String[] args) {\n     // Args4j has a different format that the old command-line parser.\n     // So we use some voodoo to get the args into the format that args4j\n \n   private void processFlagFile(PrintStream err)\n             throws CmdLineException, IOException {\n-    List<String> argsInFile = Lists.newArrayList();\n     File flagFileInput = new File(flags.flag_file);\n-    StringTokenizer tokenizer = new StringTokenizer(\n-        Files.toString(flagFileInput, Charset.defaultCharset()));\n-\n-    while (tokenizer.hasMoreTokens()) {\n-        argsInFile.add(tokenizer.nextToken());\n-    }\n+    List<String> argsInFile = tokenizeKeepingQuotedStrings(\n+        Files.readLines(flagFileInput, Charset.defaultCharset()));\n \n     flags.flag_file = \"\";\n     List<String> processedFileArgs", "timestamp": 1334696713, "metainfo": ""}