{"sha": "31485240cc4a5dda6496ea4fbab82f86330de328", "log": "switching trunk to redesign branch    ", "commit": "\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/ArchiveEntry.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers;\n+\n+/**\n+ * Represents an entry of an archive.\n+ */\n+public interface ArchiveEntry {\n+\n+\tpublic String getName();\n+\t\n+\tpublic long getSize();\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/ArchiveException.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers;\n+\n+/**\n+ * Archiver related Exception \n+ */\n+public class ArchiveException extends Exception {\n+\n+\tprivate static final long serialVersionUID = 3256440322136748848L;\n+\n+\tpublic ArchiveException() {\n+\t\tsuper();\n+\t}\n+\n+\tpublic ArchiveException(String message) {\n+\t\tsuper(message);\n+\t}\n+\t\n+\tpublic ArchiveException(String message, Exception e) {\n+\t\tsuper(message);\n+\t\tthis.initCause(e);\n+\t}\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/ArchiveInputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+public abstract class ArchiveInputStream extends InputStream {\n+\n+\t/**\n+     * Returns the next Archive Entry in this Stream.\n+     * @return the next entry\n+     * @throws IOException if the next entry could not be read\n+     */\n+    public abstract ArchiveEntry getNextEntry() throws IOException;\n+    \n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/ArchiveOutputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+\n+public abstract class ArchiveOutputStream extends OutputStream {\n+\n+\tpublic abstract void putArchiveEntry(ArchiveEntry entry) throws IOException;\n+\t\n+    public abstract void closeArchiveEntry() throws IOException;\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/ArchiveStreamFactory.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.lang.reflect.Constructor;\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+\n+import org.apache.commons.compress.archivers.ar.ArArchiveInputStream;\n+import org.apache.commons.compress.archivers.ar.ArArchiveOutputStream;\n+import org.apache.commons.compress.archivers.jar.JarArchiveInputStream;\n+import org.apache.commons.compress.archivers.jar.JarArchiveOutputStream;\n+import org.apache.commons.compress.archivers.tar.TarArchiveInputStream;\n+import org.apache.commons.compress.archivers.tar.TarArchiveOutputStream;\n+import org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;\n+import org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream;\n+import org.apache.commons.compress.utils.ReflectionUtils;\n+\n+public class ArchiveStreamFactory {\n+\n+\tfinal Map inputStreamClasses = new HashMap();\n+\tfinal Map outputStreamClasses = new HashMap();\n+\t\n+\tpublic ArchiveStreamFactory() throws ArchiveException {\n+\t\tregisterArchiveInputStream(\"zip\", ZipArchiveInputStream.class);\n+\t\tregisterArchiveOutputStream(\"zip\", ZipArchiveOutputStream.class);\n+\n+        registerArchiveInputStream(\"tar\", TarArchiveInputStream.class);\n+        registerArchiveOutputStream(\"tar\", TarArchiveOutputStream.class);\n+\n+        registerArchiveInputStream(\"ar\", ArArchiveInputStream.class);\n+        registerArchiveOutputStream(\"ar\", ArArchiveOutputStream.class);\n+\n+        registerArchiveInputStream(\"jar\", JarArchiveInputStream.class);\t\t\n+        registerArchiveOutputStream(\"jar\", JarArchiveOutputStream.class);\n+\t}\n+\t\n+\t\n+\tpublic void registerArchiveInputStream( final String name, final Class stream ) throws ArchiveException {\n+\t\tif (ArchiveInputStream.class.isAssignableFrom(stream) && !(stream.isInterface())) {\n+\t\t\tinputStreamClasses.put(name, stream);\n+        } else {\n+            throw new ArchiveException(\"Archive does not implement the ArchiveInputStream interface.\");\n+        }\t\n+\t}\n+\n+\tpublic void registerArchiveOutputStream( final String name, final Class stream ) throws ArchiveException {\n+\t\tReflectionUtils.registerClazz(outputStreamClasses, name, ArchiveOutputStream.class, stream);\t\t\n+\t\tif (ArchiveOutputStream.class.isAssignableFrom(stream) && !(stream.isInterface())) {\n+\t\t\toutputStreamClasses.put(name, stream);\n+        } else {\n+            throw new ArchiveException(\"Archive does not implement the ArchiveOutputStream interface.\");\n+        }\n+\t}\n+\t\n+    public ArchiveInputStream createArchiveInputStream( final String archiverName, final InputStream out ) throws ArchiveException {\n+        try {\n+            final Class clazz = (Class) inputStreamClasses.get(archiverName);\n+\n+            if (clazz == null) {\n+            \tthrow new ArchiveException(\"ArchiverFactory could not create instance\");\n+            }\n+\n+            final Class[] params = { InputStream.class };\n+            final Constructor constructor = clazz.getConstructor(params);\n+            final Object[] initargs = { out };\n+            return (ArchiveInputStream) constructor.newInstance(initargs);\n+        } catch (InstantiationException e) {\n+            throw new ArchiveException(\"ArchiverFactory could not create instance\", e);\n+        } catch (IllegalAccessException e) {\n+            throw new ArchiveException(\"ArchiverFactory could not create instance\", e);\n+        } catch (SecurityException e) {\n+            throw new ArchiveException(\"ArchiverFactory could not create instance\", e);\n+        } catch (NoSuchMethodException e) {\n+            throw new ArchiveException(\"ArchiverFactory could not create instance\", e);\n+        } catch (IllegalArgumentException e) {\n+            throw new ArchiveException(\"ArchiverFactory could not create instance\", e);\n+        } catch (InvocationTargetException e) {\n+            throw new ArchiveException(\"ArchiverFactory could not create instance\", e);\n+        }\n+    }\n+\n+    public ArchiveOutputStream createArchiveOutputStream( final String archiverName, final OutputStream out ) throws ArchiveException {\n+        try {\n+            final Class clazz = (Class) outputStreamClasses.get(archiverName);\n+            \n+            if (clazz == null) {\n+            \tthrow new ArchiveException(\"ArchiverFactory could not create instance\");\n+            }\n+            \n+            final Class[] params = { OutputStream.class };\n+            final Constructor constructor = clazz.getConstructor(params);\n+            final Object[] initargs = { out };\n+            return (ArchiveOutputStream) constructor.newInstance(initargs);\n+        } catch (InstantiationException e) {\n+            throw new ArchiveException(\"ArchiverFactory could not create instance\", e);\n+        } catch (IllegalAccessException e) {\n+            throw new ArchiveException(\"ArchiverFactory could not create instance\", e);\n+        } catch (SecurityException e) {\n+            throw new ArchiveException(\"ArchiverFactory could not create instance\", e);\n+        } catch (NoSuchMethodException e) {\n+            throw new ArchiveException(\"ArchiverFactory could not create instance\", e);\n+        } catch (IllegalArgumentException e) {\n+            throw new ArchiveException(\"ArchiverFactory could not create instance\", e);\n+        } catch (InvocationTargetException e) {\n+            throw new ArchiveException(\"ArchiverFactory could not create instance\", e);\n+        }\n+    }\n+\n+    public ArchiveInputStream createArchiveInputStream( final InputStream input ) throws IOException {\n+\n+\t\tfinal byte[] signature = new byte[12];\n+\t\tinput.mark(signature.length);\n+\t\tinput.read(signature);\n+\t\t// reset not supported exception?\n+\t\tinput.reset();\n+\n+//\t\tfor (int i = 0; i < signature.length; i++) {\n+//\t\t\tSystem.out.print(Integer.toHexString(signature[i]));\n+//\t\t\tSystem.out.print(\",\");\n+//\t\t}\n+//\t\tSystem.out.println(\"\");\n+\t\t\n+\t\tfor (Iterator it = inputStreamClasses.values().iterator(); it.hasNext();) {\n+\t\t\tfinal Class clazz = (Class) it.next();\n+\t\t\ttry {\n+\t\t\t\tfinal Method method = clazz.getMethod(\"matches\", new Class[] { byte[].class });\n+\t\t\t\t\n+\t\t\t\tfinal Object result = method.invoke(null, new Object[] { signature } );\n+\t\t\t\t\n+\t\t\t\tif (result.equals(Boolean.TRUE)) {\n+\t\t            final Class[] params = { InputStream.class };\n+\t\t            final Constructor constructor = clazz.getConstructor(params);\n+\t\t            final Object[] initargs = { input };\n+\t\t            return (ArchiveInputStream) constructor.newInstance(initargs);\t\t\t\t\t\n+\t\t\t\t}\n+\t\t\t} catch (SecurityException e) {\n+\t\t\t} catch (NoSuchMethodException e) {\n+\t\t\t} catch (IllegalArgumentException e) {\n+\t\t\t} catch (IllegalAccessException e) {\n+\t\t\t} catch (InvocationTargetException e) {\n+\t\t\t} catch (InstantiationException e) {\n+\t\t\t}\n+\t\t}\n+\t\treturn null;\n+\t}\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/ar/ArArchiveEntry.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.ar;\n+\n+import org.apache.commons.compress.archivers.ArchiveEntry;\n+\n+public class ArArchiveEntry implements ArchiveEntry {\n+\n+\tprivate final String name;\n+\tprivate int userId;\n+\tprivate int groupId;\n+\tprivate int mode;\n+\tprivate long lastModified;\n+\tprivate long length;\n+\n+\tpublic ArArchiveEntry(String name, long length) {\n+\t\tthis(name, length, 0, 0, 33188, System.currentTimeMillis());\n+\t}\n+\t\n+\tpublic ArArchiveEntry(String name, long length, int userId, int groupId, int mode, long lastModified) {\n+\t\tthis.name = name;\n+\t\tthis.length = length;\n+\t\tthis.userId = userId;\n+\t\tthis.groupId = groupId;\n+\t\tthis.mode = mode;\n+\t\tthis.lastModified = lastModified;\n+\t}\n+\n+\tpublic long getSize() {\n+\t\treturn this.getLength();\n+\t}\n+\t\n+\tpublic String getName() {\n+\t\treturn name;\n+\t}\n+\t\n+\tpublic int getUserId() {\n+\t\treturn userId;\n+\t}\n+\t\n+\tpublic int getGroupId() {\n+\t\treturn groupId;\n+\t}\n+\t\n+\tpublic int getMode() {\n+\t\treturn mode;\n+\t}\n+\t\n+\tpublic long getLastModified() {\n+\t\treturn lastModified;\n+\t}\n+\t\n+\tpublic long getLength() {\n+\t\treturn length;\n+\t}\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/ar/ArArchiveInputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.ar;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import org.apache.commons.compress.archivers.ArchiveEntry;\n+import org.apache.commons.compress.archivers.ArchiveInputStream;\n+\n+public class ArArchiveInputStream extends ArchiveInputStream {\n+\n+\tprivate final InputStream input;\n+\tprivate long offset = 0;\n+\t\n+\tpublic ArArchiveInputStream( final InputStream pInput ) {\n+\t\tinput = pInput;\n+\t}\n+\t\n+\tpublic ArchiveEntry getNextEntry() throws IOException {\n+\t\t\n+\t\tif (offset == 0) {\n+\t\t\tfinal byte[] expected = \"!<arch>\\n\".getBytes();\t\t\t\n+\t\t\tfinal byte[] realized = new byte[expected.length]; \n+\t\t\tfinal int read = input.read(realized);\n+\t\t\tif (read != expected.length) {\n+\t\t\t\tthrow new IOException(\"failed to read header\");\n+\t\t\t}\n+\t\t\tfor (int i = 0; i < expected.length; i++) {\n+\t\t\t\tif (expected[i] != realized[i]) {\n+\t\t\t\t\tthrow new IOException(\"invalid header \" + new String(realized));\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n+\t\tif (input.available() == 0) {\n+\t\t\treturn null;\n+\t\t}\n+\t\t\t\t\n+\t\tif (offset % 2 != 0) {\n+\t\t\tread();\n+\t\t}\n+\n+\t\tfinal byte[] name = new byte[16];\n+\t\tfinal byte[] lastmodified = new byte[12];\n+\t\tfinal byte[] userid = new byte[6];\n+\t\tfinal byte[] groupid = new byte[6];\n+\t\tfinal byte[] filemode = new byte[8];\n+\t\tfinal byte[] length = new byte[10];\n+\t\t\n+\t\tread(name);\n+\t\tread(lastmodified);\n+\t\tread(userid);\n+\t\tread(groupid);\n+\t\tread(filemode);\n+\t\tread(length);\n+\n+\t\t{\n+\t\t\tfinal byte[] expected = \"`\\012\".getBytes();\t\t\t\n+\t\t\tfinal byte[] realized = new byte[expected.length]; \n+\t\t\tfinal int read = input.read(realized);\n+\t\t\tif (read != expected.length) {\n+\t\t\t\tthrow new IOException(\"failed to read entry header\");\n+\t\t\t}\n+\t\t\tfor (int i = 0; i < expected.length; i++) {\n+\t\t\t\tif (expected[i] != realized[i]) {\n+\t\t\t\t\tthrow new IOException(\"invalid entry header. not read the content?\");\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\t\n+\t\treturn new ArArchiveEntry(new String(name).trim(), Long.parseLong(new String(length).trim()));\n+\t\n+\t}\n+\t\n+\t\n+\tpublic int read() throws IOException {\n+\t\tfinal int ret = input.read();\n+\t\toffset++;\n+\t\treturn ret;\n+\t}\n+\n+\tpublic int read(byte[] b, int off, int len) throws IOException {\n+\t\treturn this.input.read(b, off, len);\n+\t}\n+\t\n+\tpublic static boolean matches( byte[] signature ) {\n+\t\t// 3c21 7261 6863 0a3e\n+    \t\n+    \tif (signature[0] != 0x21) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[1] != 0x3c) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[2] != 0x61) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[3] != 0x72) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[4] != 0x63) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[5] != 0x68) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[6] != 0x3e) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[7] != 0x0a) {\n+    \t\treturn false;\n+    \t}\n+    \t\n+    \treturn true;\n+\t}\n+\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/ar/ArArchiveOutputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.ar;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+\n+import org.apache.commons.compress.archivers.ArchiveEntry;\n+import org.apache.commons.compress.archivers.ArchiveOutputStream;\n+\n+public class ArArchiveOutputStream extends ArchiveOutputStream {\n+\n+\tprivate final OutputStream out;\n+\tprivate long archiveOffset = 0;\n+\tprivate long entryOffset = 0;\n+\tprivate ArArchiveEntry prevEntry;\n+\n+\tpublic ArArchiveOutputStream( final OutputStream pOut ) {\n+\t\tout = pOut;\n+\t\t\n+\t}\n+\n+\tprivate long writeArchiveHeader() throws IOException {\t\t\n+\t\tfinal String header = \"!<arch>\\n\";\n+\t\tout.write(header.getBytes());\n+\t\treturn header.length();\n+\t}\n+\n+\tpublic void closeArchiveEntry() throws IOException {\n+\t\tif ((entryOffset % 2) != 0) {\n+        \twrite('\\n');\n+        \tarchiveOffset++;\n+        }\t\t\n+\t}\n+\t\n+\tpublic void putArchiveEntry( final ArchiveEntry pEntry ) throws IOException {\n+\t\tArArchiveEntry pArEntry = (ArArchiveEntry)pEntry;\n+\t\tif (prevEntry == null) {\n+\t\t\tarchiveOffset += writeArchiveHeader();\t\t\t\n+\t\t} else {\n+\t\t\tif (prevEntry.getLength() != entryOffset) {\n+\t\t\t\tthrow new IOException(\"length does not match entry (\" + prevEntry.getLength() + \" != \" + entryOffset);\n+\t\t\t}\n+\t\t\t\n+\t\t\tcloseArchiveEntry();\n+\t\t}\n+\t\t\n+\t\tprevEntry = pArEntry;\n+\t\t\n+\t\tarchiveOffset += writeEntryHeader(pArEntry);\n+\n+\t\tentryOffset = 0;\n+\t}\n+\n+\tprivate long fill( final long pOffset, final long pNewOffset, final char pFill ) throws IOException { \n+\t\tfinal long diff = pNewOffset - pOffset;\n+\t\n+\t\tif (diff > 0) {\n+\t\t\tfor (int i = 0; i < diff; i++) {\n+\t\t\t\twrite(pFill);\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn pNewOffset;\n+\t}\n+\t\n+\tprivate long write( final String data ) throws IOException {\n+\t\tfinal byte[] bytes = data.getBytes(\"ascii\");\n+\t\twrite(bytes);\n+\t\treturn bytes.length;\n+\t}\n+\t\n+\tprivate long writeEntryHeader( final ArArchiveEntry pEntry ) throws IOException {\n+\t\t\n+\t\tlong offset = 0;\n+\t\t\n+\t\tfinal String n = pEntry.getName();\n+\t\tif (n.length() > 16) {\n+\t\t\tthrow new IOException(\"filename too long\");\n+\t\t}\t\t\n+\t\toffset += write(n);\n+\t\t\n+\t\toffset = fill(offset, 16, ' ');\n+\t\tfinal String m = \"\" + (pEntry.getLastModified() / 1000);\n+\t\tif (m.length() > 12) {\n+\t\t\tthrow new IOException(\"modified too long\");\n+\t\t}\t\t\n+\t\toffset += write(m);\t\t\n+\n+\t\toffset = fill(offset, 28, ' ');\n+\t\tfinal String u = \"\" + pEntry.getUserId();\n+\t\tif (u.length() > 6) {\n+\t\t\tthrow new IOException(\"userid too long\");\n+\t\t}\t\t\n+\t\toffset += write(u);\n+\n+\t\toffset = fill(offset, 34, ' ');\n+\t\tfinal String g = \"\" + pEntry.getGroupId();\n+\t\tif (g.length() > 6) {\n+\t\t\tthrow new IOException(\"groupid too long\");\n+\t\t}\t\t\n+\t\toffset += write(g);\n+\n+\t\toffset = fill(offset, 40, ' ');\n+\t\tfinal String fm = \"\" + Integer.toString(pEntry.getMode(), 8);\n+\t\tif (fm.length() > 8) {\n+\t\t\tthrow new IOException(\"filemode too long\");\n+\t\t}\t\t\n+\t\toffset += write(fm);\n+\n+\t\toffset = fill(offset, 48, ' ');\n+\t\tfinal String s = \"\" + pEntry.getLength();\n+\t\tif (s.length() > 10) {\n+\t\t\tthrow new IOException(\"size too long\");\n+\t\t}\t\t\n+\t\toffset += write(s);\n+\n+\t\toffset = fill(offset, 58, ' ');\n+\n+\t\toffset += write(\"`\\012\");\n+\t\t\n+\t\treturn offset;\n+\t}\t\t\n+\t\n+\tpublic void write(int b) throws IOException {\n+\t\tout.write(b);\n+\t\tentryOffset++;\n+\t}\n+\n+\tpublic void write(byte[] b, int off, int len) throws IOException {\n+\t\tout.write(b, off, len);\n+\t\tentryOffset += len;\n+\t}\n+\n+\tpublic void write(byte[] b) throws IOException {\n+\t\tout.write(b);\n+\t\tentryOffset += b.length;\n+\t}\n+\n+\tpublic void close() throws IOException {\n+\t\tcloseArchiveEntry();\n+\t\tout.close();\n+\t\tprevEntry = null;\n+\t}\n+\n+\tpublic String getDefaultFileExtension() {\n+\t\treturn \"ar\";\n+\t}\n+\n+\tpublic byte[] getHeader() {\n+\t\t// TODO Auto-generated method stub\n+\t\treturn null;\n+\t}\n+\n+\tpublic String getName() {\n+\t\treturn \"ar\";\n+\t}\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/jar/JarArchiveEntry.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.jar;\n+\n+import java.security.cert.Certificate;\n+import java.util.jar.Attributes;\n+import java.util.jar.JarEntry;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipException;\n+\n+import org.apache.commons.compress.archivers.ArchiveEntry;\n+import org.apache.commons.compress.archivers.zip.ZipArchiveEntry;\n+\n+public class JarArchiveEntry extends ZipArchiveEntry implements ArchiveEntry {\n+\n+\tprivate Attributes manifestAttributes = null;\n+\tprivate Certificate[] certificates = null; \n+\t\n+\tpublic JarArchiveEntry(ZipEntry entry) throws ZipException {\n+\t\tsuper(entry);\n+\t}\n+\n+\tpublic JarArchiveEntry(String name) {\n+\t\tsuper(name);\n+\t}\n+\n+\tpublic JarArchiveEntry(ZipArchiveEntry entry) throws ZipException {\n+\t\tsuper(entry);\n+\t}\n+\n+\tpublic JarArchiveEntry(JarEntry entry) throws ZipException {\n+\t\tsuper(entry);\n+\t\t\n+\t}\n+\n+\tpublic Attributes getManifestAttributes() {\n+\t\treturn manifestAttributes;\n+\t}\n+\n+\tpublic Certificate[] getCertificates() {\n+\t\treturn certificates;\n+\t}\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/jar/JarArchiveInputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.jar;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import org.apache.commons.compress.archivers.ArchiveEntry;\n+import org.apache.commons.compress.archivers.zip.ZipArchiveEntry;\n+import org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;\n+\n+public class JarArchiveInputStream extends ZipArchiveInputStream {\n+\n+\tpublic JarArchiveInputStream( final InputStream inputStream ) throws IOException {\n+\t\tsuper(inputStream);\n+\t}\n+\t\n+\tpublic ArchiveEntry getNextEntry() throws IOException {\n+\t\treturn (ArchiveEntry)new JarArchiveEntry((ZipArchiveEntry)super.getNextEntry());\n+\t}\n+\t\n+\tpublic static boolean matches( byte[] signature ) {\n+\t\t// 4b50 0403 0014 0008\n+\n+    \tif (signature[0] != 0x50) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[1] != 0x4b) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[2] != 0x03) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[3] != 0x04) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[4] != 0x14) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[5] != 0x00) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[6] != 0x08) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[7] != 0x00) {\n+    \t\treturn false;\n+    \t}\n+    \t\n+    \treturn true;\n+\t}\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/jar/JarArchiveOutputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.jar;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+\n+import org.apache.commons.compress.archivers.ArchiveEntry;\n+import org.apache.commons.compress.archivers.zip.ZipArchiveEntry;\n+import org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream;\n+\n+public class JarArchiveOutputStream extends ZipArchiveOutputStream {\n+\n+\tpublic JarArchiveOutputStream( final OutputStream out ) {\n+\t\tsuper(out);\n+\t}\n+\n+\tpublic void putArchiveEntry(ArchiveEntry entry) throws IOException {\n+\t\t// TODO special jar stuff\n+\t\t super.putArchiveEntry((ZipArchiveEntry) entry);\n+\t}\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveEntry.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.tar;\n+\n+import java.io.File;\n+import java.util.Date;\n+import java.util.Locale;\n+\n+import org.apache.commons.compress.archivers.ArchiveEntry;\n+\n+/**\n+ * This class represents an entry in a Tar archive. It consists of the entry's\n+ * header, as well as the entry's File. Entries can be instantiated in one of\n+ * three ways, depending on how they are to be used. <p>\n+ *\n+ * TarEntries that are created from the header bytes read from an archive are\n+ * instantiated with the TarEntry( byte[] ) constructor. These entries will be\n+ * used when extracting from or listing the contents of an archive. These\n+ * entries have their header filled in using the header bytes. They also set the\n+ * File to null, since they reference an archive entry not a file. <p>\n+ *\n+ * TarEntries that are created from Files that are to be written into an archive\n+ * are instantiated with the TarEntry( File ) constructor. These entries have\n+ * their header filled in using the File's information. They also keep a\n+ * reference to the File for convenience when writing entries. <p>\n+ *\n+ * Finally, TarEntries can be constructed from nothing but a name. This allows\n+ * the programmer to construct the entry by hand, for instance when only an\n+ * InputStream is available for writing to the archive, and the header\n+ * information is constructed from other information. In this case the header\n+ * fields are set to defaults and the File is set to null. <p>\n+ *\n+ * The C structure for a Tar Entry's header is: <pre>\n+ * struct header {\n+ * char name[NAMSIZ];\n+ * char mode[8];\n+ * char uid[8];\n+ * char gid[8];\n+ * char size[12];\n+ * char mtime[12];\n+ * char chksum[8];\n+ * char linkflag;\n+ * char linkname[NAMSIZ];\n+ * char magic[8];\n+ * char uname[TUNMLEN];\n+ * char gname[TGNMLEN];\n+ * char devmajor[8];\n+ * char devminor[8];\n+ * } header;\n+ * </pre>\n+ */\n+public class TarArchiveEntry implements ArchiveEntry {\n+    /**\n+     * The length of the name field in a header buffer.\n+     */\n+    public static final int NAMELEN = 100;\n+\n+    /**\n+     * The entry's modification time.\n+     */\n+    private int m_checkSum;\n+\n+    /**\n+     * The entry's group name.\n+     */\n+    private int m_devMajor;\n+\n+    /**\n+     * The entry's major device number.\n+     */\n+    private int m_devMinor;\n+\n+    /**\n+     * The entry's minor device number.\n+     */\n+    private File m_file;\n+\n+    /**\n+     * The entry's user id.\n+     */\n+    private int m_groupID;\n+\n+    /**\n+     * The entry's user name.\n+     */\n+    private StringBuffer m_groupName;\n+\n+    /**\n+     * The entry's checksum.\n+     */\n+    private byte m_linkFlag;\n+\n+    /**\n+     * The entry's link flag.\n+     */\n+    private StringBuffer m_linkName;\n+\n+    /**\n+     * The entry's link name.\n+     */\n+    private StringBuffer m_magic;\n+\n+    /**\n+     * The entry's size.\n+     */\n+    private long m_modTime;\n+\n+    /**\n+     * The entry's name.\n+     */\n+    private int m_mode;\n+\n+    private StringBuffer m_name;\n+\n+    /**\n+     * The entry's group id.\n+     */\n+    private long m_size;\n+\n+    /**\n+     * The entry's permission mode.\n+     */\n+    private int m_userID;\n+\n+    /**\n+     * The entry's magic tag.\n+     */\n+    private StringBuffer m_userName;\n+\n+    /**\n+     * Construct an entry with only a name. This allows the programmer to\n+     * construct the entry's header \"by hand\". File is set to null.\n+     *\n+     * @param name the name of the entry\n+     */\n+    public TarArchiveEntry( final String name )\n+    {\n+        this();\n+\n+        final boolean isDir = name.endsWith( \"/\" );\n+\n+        m_name = new StringBuffer( name );\n+        m_mode = isDir ? 040755 : 0100644;\n+        m_linkFlag = isDir ? TarConstants.LF_DIR : TarConstants.LF_NORMAL;\n+        m_modTime = ( new Date() ).getTime() / 1000;\n+        m_linkName = new StringBuffer( \"\" );\n+        m_userName = new StringBuffer( \"\" );\n+        m_groupName = new StringBuffer( \"\" );\n+    }\n+\n+    /**\n+     * Construct an entry with a name an a link flag.\n+     *\n+     * @param name Description of Parameter\n+     * @param linkFlag Description of Parameter\n+     */\n+    public TarArchiveEntry( final String name, final byte linkFlag )\n+    {\n+        this( name );\n+        m_linkFlag = linkFlag;\n+    }\n+\n+    /**\n+     * Construct an entry for a file. File is set to file, and the header is\n+     * constructed from information from the file.\n+     *\n+     * @param file The file that the entry represents.\n+     */\n+    public TarArchiveEntry( final File file )\n+    {\n+        this();\n+\n+        m_file = file;\n+\n+        String name = file.getPath();\n+\n+        // Strip off drive letters!\n+        final String osName =\n+            System.getProperty( \"os.name\" ).toLowerCase( Locale.US );\n+        if( -1 != osName.indexOf( \"netware\" ) )\n+        {\n+            if( name.length() > 2 )\n+            {\n+                final char ch1 = name.charAt( 0 );\n+                final char ch2 = name.charAt( 1 );\n+\n+                if( ch2 == ':' &&\n+                    ( ( ch1 >= 'a' && ch1 <= 'z' ) ||\n+                    ( ch1 >= 'A' && ch1 <= 'Z' ) ) )\n+                {\n+                    name = name.substring( 2 );\n+                }\n+            }\n+        }\n+        else if( -1 != osName.indexOf( \"netware\" ) )\n+        {\n+            final int colon = name.indexOf( ':' );\n+            if( colon != -1 )\n+            {\n+                name = name.substring( colon + 1 );\n+            }\n+        }\n+\n+        name = name.replace( File.separatorChar, '/' );\n+\n+        // No absolute pathnames\n+        // Windows (and Posix?) paths can start with \"\\\\NetworkDrive\\\",\n+        // so we loop on starting /'s.\n+        while( name.startsWith( \"/\" ) )\n+        {\n+            name = name.substring( 1 );\n+        }\n+\n+        m_linkName = new StringBuffer( \"\" );\n+        m_name = new StringBuffer( name );\n+\n+        if( file.isDirectory() )\n+        {\n+            m_mode = 040755;\n+            m_linkFlag = TarConstants.LF_DIR;\n+\n+            if( m_name.charAt( m_name.length() - 1 ) != '/' )\n+            {\n+                m_name.append( \"/\" );\n+            }\n+        }\n+        else\n+        {\n+            m_mode = 0100644;\n+            m_linkFlag = TarConstants.LF_NORMAL;\n+        }\n+\n+        m_size = file.length();\n+        m_modTime = file.lastModified() / 1000;\n+        m_checkSum = 0;\n+        m_devMajor = 0;\n+        m_devMinor = 0;\n+    }\n+\n+    /**\n+     * Construct an entry from an archive's header bytes. File is set to null.\n+     *\n+     * @param header The header bytes from a tar archive entry.\n+     */\n+    public TarArchiveEntry( final byte[] header )\n+    {\n+        this();\n+        parseTarHeader( header );\n+    }\n+\n+    /**\n+     * Construct an empty entry and prepares the header values.\n+     */\n+    private TarArchiveEntry()\n+    {\n+        m_magic = new StringBuffer( TarConstants.TMAGIC );\n+        m_name = new StringBuffer();\n+        m_linkName = new StringBuffer();\n+\n+        String user = System.getProperty( \"user.name\", \"\" );\n+        if( user.length() > 31 )\n+        {\n+            user = user.substring( 0, 31 );\n+        }\n+\n+        m_userName = new StringBuffer( user );\n+        m_groupName = new StringBuffer( \"\" );\n+    }\n+\n+    /**\n+     * Set this entry's group id.\n+     *\n+     * @param groupId This entry's new group id.\n+     */\n+    public void setGroupID( final int groupId )\n+    {\n+        m_groupID = groupId;\n+    }\n+\n+    /**\n+     * Set this entry's group id.\n+     *\n+     * @param groupId This entry's new group id.\n+     * @deprecated Use setGroupID() instead\n+     * @see #setGroupID(int)\n+     */\n+    public void setGroupId( final int groupId )\n+    {\n+        m_groupID = groupId;\n+    }\n+\n+    /**\n+     * Set this entry's group name.\n+     *\n+     * @param groupName This entry's new group name.\n+     */\n+    public void setGroupName( final String groupName )\n+    {\n+        m_groupName = new StringBuffer( groupName );\n+    }\n+\n+    /**\n+     * Set this entry's modification time. The parameter passed to this method\n+     * is in \"Java time\".\n+     *\n+     * @param time This entry's new modification time.\n+     */\n+    public void setModTime( final long time )\n+    {\n+        m_modTime = time / 1000;\n+    }\n+\n+    /**\n+     * Set this entry's modification time.\n+     *\n+     * @param time This entry's new modification time.\n+     */\n+    public void setModTime( final Date time )\n+    {\n+        m_modTime = time.getTime() / 1000;\n+    }\n+\n+    /**\n+     * Set the mode for this entry\n+     *\n+     * @param mode The new Mode value\n+     */\n+    public void setMode( final int mode )\n+    {\n+        m_mode = mode;\n+    }\n+\n+    /**\n+     * Set this entry's name.\n+     *\n+     * @param name This entry's new name.\n+     */\n+    public void setName( final String name )\n+    {\n+        m_name = new StringBuffer( name );\n+    }\n+\n+    /**\n+     * Set this entry's file size.\n+     *\n+     * @param size This entry's new file size.\n+     */\n+    public void setSize( final long size )\n+    {\n+        m_size = size;\n+    }\n+\n+    /**\n+     * Set this entry's user id.\n+     *\n+     * @param userId This entry's new user id.\n+     */\n+    public void setUserID( final int userId )\n+    {\n+        m_userID = userId;\n+    }\n+\n+    /**\n+     * Set this entry's user id.\n+     *\n+     * @param userId This entry's new user id.\n+     * @deprecated Use setUserID() instead\n+     * @see #setUserID(int)\n+     */\n+    public void setUserId( final int userId )\n+    {\n+        m_userID = userId;\n+    }\n+\n+    /**\n+     * Set this entry's user name.\n+     *\n+     * @param userName This entry's new user name.\n+     */\n+    public void setUserName( final String userName )\n+    {\n+        m_userName = new StringBuffer( userName );\n+    }\n+\n+    /**\n+     * If this entry represents a file, and the file is a directory, return an\n+     * array of TarEntries for this entry's children.\n+     *\n+     * @return An array of TarEntry's for this entry's children.\n+     */\n+    public TarArchiveEntry[] getDirectoryEntries()\n+    {\n+        if( null == m_file || !m_file.isDirectory() )\n+        {\n+            return new TarArchiveEntry[ 0 ];\n+        }\n+\n+        final String[] list = m_file.list();\n+        final TarArchiveEntry[] result = new TarArchiveEntry[ list.length ];\n+\n+        for( int i = 0; i < list.length; ++i )\n+        {\n+            result[ i ] = new TarArchiveEntry( new File( m_file, list[ i ] ) );\n+        }\n+\n+        return result;\n+    }\n+\n+    /**\n+     * Get this entry's file.\n+     *\n+     * @return This entry's file.\n+     */\n+    public File getFile()\n+    {\n+        return m_file;\n+    }\n+\n+    /**\n+     * Get this entry's group id.\n+     *\n+     * @return This entry's group id.\n+     * @deprecated Use getGroupID() instead\n+     * @see #getGroupID()\n+     */\n+    public int getGroupId()\n+    {\n+        return m_groupID;\n+    }\n+\n+    /**\n+     * Get this entry's group id.\n+     *\n+     * @return This entry's group id.\n+     */\n+    public int getGroupID()\n+    {\n+        return m_groupID;\n+    }\n+\n+    /**\n+     * Get this entry's group name.\n+     *\n+     * @return This entry's group name.\n+     */\n+    public String getGroupName()\n+    {\n+        return m_groupName.toString();\n+    }\n+\n+    /**\n+     * Set this entry's modification time.\n+     *\n+     * @return The ModTime value\n+     */\n+    public Date getModTime()\n+    {\n+        return new Date( m_modTime * 1000 );\n+    }\n+\n+    /**\n+     * Get this entry's mode.\n+     *\n+     * @return This entry's mode.\n+     */\n+    public int getMode()\n+    {\n+        return m_mode;\n+    }\n+\n+    /**\n+     * Get this entry's name.\n+     *\n+     * @return This entry's name.\n+     */\n+    public String getName()\n+    {\n+        return m_name.toString();\n+    }\n+\n+    /**\n+     * Get this entry's file size.\n+     *\n+     * @return This entry's file size.\n+     */\n+    public long getSize()\n+    {\n+        return m_size;\n+    }\n+\n+    /**\n+     * Get this entry's checksum.\n+     *\n+     * @return This entry's checksum.\n+     */\n+    public int getCheckSum()\n+    {\n+        return m_checkSum;\n+    }\n+\n+    /**\n+     * Get this entry's user id.\n+     *\n+     * @return This entry's user id.\n+     * @deprecated Use getUserID() instead\n+     * @see #getUserID()\n+     */\n+    public int getUserId()\n+    {\n+        return m_userID;\n+    }\n+\n+    /**\n+     * Get this entry's user id.\n+     *\n+     * @return This entry's user id.\n+     */\n+    public int getUserID()\n+    {\n+        return m_userID;\n+    }\n+\n+    /**\n+     * Get this entry's user name.\n+     *\n+     * @return This entry's user name.\n+     */\n+    public String getUserName()\n+    {\n+        return m_userName.toString();\n+    }\n+\n+    /**\n+     * Determine if the given entry is a descendant of this entry. Descendancy\n+     * is determined by the name of the descendant starting with this entry's\n+     * name.\n+     *\n+     * @param desc Entry to be checked as a descendent of\n+     * @return True if entry is a descendant of\n+     */\n+    public boolean isDescendent( final TarArchiveEntry desc )\n+    {\n+        return desc.getName().startsWith( getName() );\n+    }\n+\n+    /**\n+     * Return whether or not this entry represents a directory.\n+     *\n+     * @return True if this entry is a directory.\n+     */\n+    public boolean isDirectory()\n+    {\n+        if( m_file != null )\n+        {\n+            return m_file.isDirectory();\n+        }\n+\n+        if( m_linkFlag == TarConstants.LF_DIR )\n+        {\n+            return true;\n+        }\n+\n+        if( getName().endsWith( \"/\" ) )\n+        {\n+            return true;\n+        }\n+\n+        return false;\n+    }\n+\n+    /**\n+     * Indicate if this entry is a GNU long name block\n+     *\n+     * @return true if this is a long name extension provided by GNU tar\n+     */\n+    public boolean isGNULongNameEntry()\n+    {\n+        return m_linkFlag == TarConstants.LF_GNUTYPE_LONGNAME &&\n+            m_name.toString().equals( TarConstants.GNU_LONGLINK );\n+    }\n+\n+    /**\n+     * Determine if the two entries are equal. Equality is determined by the\n+     * header names being equal.\n+     *\n+     * @param other Entry to be checked for equality.\n+     * @return True if the entries are equal.\n+     */\n+    public boolean equals( final TarArchiveEntry other )\n+    {\n+        return getName().equals( other.getName() );\n+    }\n+\n+    /**\n+     * Parse an entry's header information from a header buffer.\n+     *\n+     * @param header The tar entry header buffer to get information from.\n+     */\n+    private void parseTarHeader( final byte[] header )\n+    {\n+        int offset = 0;\n+\n+        m_name = TarUtils.parseName( header, offset, NAMELEN );\n+        offset += NAMELEN;\n+        m_mode = (int)TarUtils.parseOctal( header, offset, TarConstants.MODELEN );\n+        offset += TarConstants.MODELEN;\n+        m_userID = (int)TarUtils.parseOctal( header, offset, TarConstants.UIDLEN );\n+        offset += TarConstants.UIDLEN;\n+        m_groupID = (int)TarUtils.parseOctal( header, offset, TarConstants.GIDLEN );\n+        offset += TarConstants.GIDLEN;\n+        m_size = TarUtils.parseOctal( header, offset, TarConstants.SIZELEN );\n+        offset += TarConstants.SIZELEN;\n+        m_modTime = TarUtils.parseOctal( header, offset, TarConstants.MODTIMELEN );\n+        offset += TarConstants.MODTIMELEN;\n+        m_checkSum = (int)TarUtils.parseOctal( header, offset, TarConstants.CHKSUMLEN );\n+        offset += TarConstants.CHKSUMLEN;\n+        m_linkFlag = header[ offset++ ];\n+        m_linkName = TarUtils.parseName( header, offset, NAMELEN );\n+        offset += NAMELEN;\n+        m_magic = TarUtils.parseName( header, offset, TarConstants.MAGICLEN );\n+        offset += TarConstants.MAGICLEN;\n+        m_userName = TarUtils.parseName( header, offset, TarConstants.UNAMELEN );\n+        offset += TarConstants.UNAMELEN;\n+        m_groupName = TarUtils.parseName( header, offset, TarConstants.GNAMELEN );\n+        offset += TarConstants.GNAMELEN;\n+        m_devMajor = (int)TarUtils.parseOctal( header, offset, TarConstants.DEVLEN );\n+        offset += TarConstants.DEVLEN;\n+        m_devMinor = (int)TarUtils.parseOctal( header, offset, TarConstants.DEVLEN );\n+    }\n+\n+    /**\n+     * Write an entry's header information to a header buffer.\n+     *\n+     * @param buffer The tar entry header buffer to fill in.\n+     */\n+    public void writeEntryHeader( final byte[] buffer )\n+    {\n+        int offset = 0;\n+\n+        offset = TarUtils.getNameBytes( m_name, buffer, offset, NAMELEN );\n+        offset = TarUtils.getOctalBytes( m_mode, buffer, offset, TarConstants.MODELEN );\n+        offset = TarUtils.getOctalBytes( m_userID, buffer, offset, TarConstants.UIDLEN );\n+        offset = TarUtils.getOctalBytes( m_groupID, buffer, offset, TarConstants.GIDLEN );\n+        offset = TarUtils.getLongOctalBytes( m_size, buffer, offset, TarConstants.SIZELEN );\n+        offset = TarUtils.getLongOctalBytes( m_modTime, buffer, offset, TarConstants.MODTIMELEN );\n+\n+        final int checkSumOffset = offset;\n+        for( int i = 0; i < TarConstants.CHKSUMLEN; ++i )\n+        {\n+            buffer[ offset++ ] = (byte)' ';\n+        }\n+\n+        buffer[ offset++ ] = m_linkFlag;\n+        offset = TarUtils.getNameBytes( m_linkName, buffer, offset, NAMELEN );\n+        offset = TarUtils.getNameBytes( m_magic, buffer, offset, TarConstants.MAGICLEN );\n+        offset = TarUtils.getNameBytes( m_userName, buffer, offset, TarConstants.UNAMELEN );\n+        offset = TarUtils.getNameBytes( m_groupName, buffer, offset, TarConstants.GNAMELEN );\n+        offset = TarUtils.getOctalBytes( m_devMajor, buffer, offset, TarConstants.DEVLEN );\n+        offset = TarUtils.getOctalBytes( m_devMinor, buffer, offset, TarConstants.DEVLEN );\n+\n+        while( offset < buffer.length )\n+        {\n+            buffer[ offset++ ] = 0;\n+        }\n+\n+        final long checkSum = TarUtils.computeCheckSum( buffer );\n+        TarUtils.getCheckSumOctalBytes( checkSum, buffer, checkSumOffset, TarConstants.CHKSUMLEN );\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveInputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.tar;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import org.apache.commons.compress.archivers.ArchiveEntry;\n+import org.apache.commons.compress.archivers.ArchiveInputStream;\n+\n+public class TarArchiveInputStream extends ArchiveInputStream {\n+    private final TarInputStream in;\n+    \n+\tpublic TarArchiveInputStream( InputStream inputStream ) {\n+\t\tin = new TarInputStream(inputStream);\n+\t}\n+\n+    public ArchiveEntry getNextEntry() throws IOException {\n+        return (ArchiveEntry)in.getNextEntry();\n+    }\n+\n+    public int read(byte[] b, int off, int len) throws IOException {\n+        return in.read(b, off, len);\n+    }\n+\n+    public int read() throws IOException {\n+        return in.read();\n+    }\n+    \n+    public static boolean matches( byte[] signature ) {\n+    \t// 6574 7473 2e31 6d78\n+    \t\n+    \tif (signature[0] != 0x74) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[1] != 0x65) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[2] != 0x73) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[3] != 0x74) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[4] != 0x31) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[5] != 0x2e) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[6] != 0x78) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[7] != 0x6d) {\n+    \t\treturn false;\n+    \t}\n+    \t\n+    \treturn true;\n+    }\n+    \n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveOutputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.tar;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+\n+import org.apache.commons.compress.archivers.ArchiveEntry;\n+import org.apache.commons.compress.archivers.ArchiveOutputStream;\n+\n+public class TarArchiveOutputStream extends ArchiveOutputStream {\n+\n+    private TarOutputStream out = null;\n+    \n+    public TarArchiveOutputStream(OutputStream out) {\n+        this.out = new TarOutputStream(out);\n+    }\n+    \n+    public void close() throws IOException {\n+        this.out.close();\n+    }\n+\n+    public void closeArchiveEntry() throws IOException {\n+        this.out.closeEntry();\n+    }\n+\n+    public void putArchiveEntry(ArchiveEntry entry) throws IOException {\n+        this.out.putNextEntry((TarArchiveEntry)entry);\n+    }\n+\n+    public void write(byte[] buffer, int offset, int length) throws IOException {\n+        this.out.write(buffer, offset, length);\n+    }\n+\n+    public String getDefaultFileExtension() {\n+        return \"tar\";\n+    }\n+\n+    public byte[] getHeader() {\n+        // TODO Auto-generated method stub\n+        return null;\n+    }\n+\n+    public String getName() {\n+        return \"tar\";\n+    }\n+\n+    public void write(int b) throws IOException {\n+        this.out.write(b);\n+    }\n+}\n+\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarBuffer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.tar;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.util.Arrays;\n+\n+/**\n+ * The TarBuffer class implements the tar archive concept of a buffered input\n+ * stream. This concept goes back to the days of blocked tape drives and special\n+ * io devices. In the Java universe, the only real function that this class\n+ * performs is to ensure that files have the correct \"block\" size, or other tars\n+ * will complain. <p>\n+ *\n+ * You should never have a need to access this class directly. TarBuffers are\n+ * created by Tar IO Streams.\n+ */\n+class TarBuffer\n+{\n+    public static final int DEFAULT_RECORDSIZE = ( 512 );\n+    public static final int DEFAULT_BLOCKSIZE = ( DEFAULT_RECORDSIZE * 20 );\n+\n+    private byte[] m_blockBuffer;\n+    private int m_blockSize;\n+    private int m_currBlkIdx;\n+    private int m_currRecIdx;\n+    private boolean m_debug;\n+\n+    private InputStream m_input;\n+    private OutputStream m_output;\n+    private int m_recordSize;\n+    private int m_recsPerBlock;\n+\n+    public TarBuffer( final InputStream input )\n+    {\n+        this( input, TarBuffer.DEFAULT_BLOCKSIZE );\n+    }\n+\n+    public TarBuffer( final InputStream input, final int blockSize )\n+    {\n+        this( input, blockSize, TarBuffer.DEFAULT_RECORDSIZE );\n+    }\n+\n+    public TarBuffer( final InputStream input,\n+                      final int blockSize,\n+                      final int recordSize )\n+    {\n+        m_input = input;\n+        initialize( blockSize, recordSize );\n+    }\n+\n+    public TarBuffer( final OutputStream output )\n+    {\n+        this( output, TarBuffer.DEFAULT_BLOCKSIZE );\n+    }\n+\n+    public TarBuffer( final OutputStream output, final int blockSize )\n+    {\n+        this( output, blockSize, TarBuffer.DEFAULT_RECORDSIZE );\n+    }\n+\n+    public TarBuffer( final OutputStream output,\n+                      final int blockSize,\n+                      final int recordSize )\n+    {\n+        m_output = output;\n+        initialize( blockSize, recordSize );\n+    }\n+\n+    /**\n+     * Set the debugging flag for the buffer.\n+     *\n+     * @param debug If true, print debugging output.\n+     */\n+    public void setDebug( final boolean debug )\n+    {\n+        m_debug = debug;\n+    }\n+\n+    /**\n+     * Get the TAR Buffer's block size. Blocks consist of multiple records.\n+     *\n+     * @return The BlockSize value\n+     */\n+    public int getBlockSize()\n+    {\n+        return m_blockSize;\n+    }\n+\n+    /**\n+     * Get the current block number, zero based.\n+     *\n+     * @return The current zero based block number.\n+     */\n+    public int getCurrentBlockNum()\n+    {\n+        return m_currBlkIdx;\n+    }\n+\n+    /**\n+     * Get the current record number, within the current block, zero based.\n+     * Thus, current offset = (currentBlockNum * recsPerBlk) + currentRecNum.\n+     *\n+     * @return The current zero based record number.\n+     */\n+    public int getCurrentRecordNum()\n+    {\n+        return m_currRecIdx - 1;\n+    }\n+\n+    /**\n+     * Get the TAR Buffer's record size.\n+     *\n+     * @return The RecordSize value\n+     */\n+    public int getRecordSize()\n+    {\n+        return m_recordSize;\n+    }\n+\n+    /**\n+     * Determine if an archive record indicate End of Archive. End of archive is\n+     * indicated by a record that consists entirely of null bytes.\n+     *\n+     * @param record The record data to check.\n+     * @return The EOFRecord value\n+     */\n+    public boolean isEOFRecord( final byte[] record )\n+    {\n+        final int size = getRecordSize();\n+        for( int i = 0; i < size; ++i )\n+        {\n+            if( record[ i ] != 0 )\n+            {\n+                return false;\n+            }\n+        }\n+\n+        return true;\n+    }\n+\n+    /**\n+     * Close the TarBuffer. If this is an output buffer, also flush the current\n+     * block before closing.\n+     */\n+    public void close()\n+        throws IOException\n+    {\n+        if( m_debug )\n+        {\n+            debug( \"TarBuffer.closeBuffer().\" );\n+        }\n+\n+        if( null != m_output )\n+        {\n+            flushBlock();\n+\n+            if( m_output != System.out && m_output != System.err )\n+            {\n+                m_output.close();\n+                m_output = null;\n+            }\n+        }\n+        else if( m_input != null )\n+        {\n+            if( m_input != System.in )\n+            {\n+                m_input.close();\n+                m_input = null;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Read a record from the input stream and return the data.\n+     *\n+     * @return The record data.\n+     * @exception IOException Description of Exception\n+     */\n+    public byte[] readRecord()\n+        throws IOException\n+    {\n+        if( m_debug )\n+        {\n+            final String message = \"ReadRecord: recIdx = \" + m_currRecIdx +\n+                \" blkIdx = \" + m_currBlkIdx;\n+            debug( message );\n+        }\n+\n+        if( null == m_input )\n+        {\n+            final String message = \"reading from an output buffer\";\n+            throw new IOException( message );\n+        }\n+\n+        if( m_currRecIdx >= m_recsPerBlock )\n+        {\n+            if( !readBlock() )\n+            {\n+                return null;\n+            }\n+        }\n+\n+        final byte[] result = new byte[ m_recordSize ];\n+        System.arraycopy( m_blockBuffer,\n+                          ( m_currRecIdx * m_recordSize ),\n+                          result,\n+                          0,\n+                          m_recordSize );\n+\n+        m_currRecIdx++;\n+\n+        return result;\n+    }\n+\n+    /**\n+     * Skip over a record on the input stream.\n+     */\n+    public void skipRecord()\n+        throws IOException\n+    {\n+        if( m_debug )\n+        {\n+            final String message = \"SkipRecord: recIdx = \" + m_currRecIdx +\n+                \" blkIdx = \" + m_currBlkIdx;\n+            debug( message );\n+        }\n+\n+        if( null == m_input )\n+        {\n+            final String message = \"reading (via skip) from an output buffer\";\n+            throw new IOException( message );\n+        }\n+\n+        if( m_currRecIdx >= m_recsPerBlock )\n+        {\n+            if( !readBlock() )\n+            {\n+                return;// UNDONE\n+            }\n+        }\n+\n+        m_currRecIdx++;\n+    }\n+\n+    /**\n+     * Write an archive record to the archive.\n+     *\n+     * @param record The record data to write to the archive.\n+     */\n+    public void writeRecord( final byte[] record )\n+        throws IOException\n+    {\n+        if( m_debug )\n+        {\n+            final String message = \"WriteRecord: recIdx = \" + m_currRecIdx +\n+                \" blkIdx = \" + m_currBlkIdx;\n+            debug( message );\n+        }\n+\n+        if( null == m_output )\n+        {\n+            final String message = \"writing to an input buffer\";\n+            throw new IOException( message );\n+        }\n+\n+        if( record.length != m_recordSize )\n+        {\n+            final String message = \"record to write has length '\" +\n+                record.length + \"' which is not the record size of '\" +\n+                m_recordSize + \"'\";\n+            throw new IOException( message );\n+        }\n+\n+        if( m_currRecIdx >= m_recsPerBlock )\n+        {\n+            writeBlock();\n+        }\n+\n+        System.arraycopy( record,\n+                          0,\n+                          m_blockBuffer,\n+                          ( m_currRecIdx * m_recordSize ),\n+                          m_recordSize );\n+\n+        m_currRecIdx++;\n+    }\n+\n+    /**\n+     * Write an archive record to the archive, where the record may be inside of\n+     * a larger array buffer. The buffer must be \"offset plus record size\" long.\n+     *\n+     * @param buffer The buffer containing the record data to write.\n+     * @param offset The offset of the record data within buf.\n+     */\n+    public void writeRecord( final byte[] buffer, final int offset )\n+        throws IOException\n+    {\n+        if( m_debug )\n+        {\n+            final String message = \"WriteRecord: recIdx = \" + m_currRecIdx +\n+                \" blkIdx = \" + m_currBlkIdx;\n+            debug( message );\n+        }\n+\n+        if( null == m_output )\n+        {\n+            final String message = \"writing to an input buffer\";\n+            throw new IOException( message );\n+        }\n+\n+        if( ( offset + m_recordSize ) > buffer.length )\n+        {\n+            final String message = \"record has length '\" + buffer.length +\n+                \"' with offset '\" + offset + \"' which is less than the record size of '\" +\n+                m_recordSize + \"'\";\n+            throw new IOException( message );\n+        }\n+\n+        if( m_currRecIdx >= m_recsPerBlock )\n+        {\n+            writeBlock();\n+        }\n+\n+        System.arraycopy( buffer,\n+                          offset,\n+                          m_blockBuffer,\n+                          ( m_currRecIdx * m_recordSize ),\n+                          m_recordSize );\n+\n+        m_currRecIdx++;\n+    }\n+\n+    /**\n+     * Flush the current data block if it has any data in it.\n+     */\n+    private void flushBlock()\n+        throws IOException\n+    {\n+        if( m_debug )\n+        {\n+            final String message = \"TarBuffer.flushBlock() called.\";\n+            debug( message );\n+        }\n+\n+        if( m_output == null )\n+        {\n+            final String message = \"writing to an input buffer\";\n+            throw new IOException( message );\n+        }\n+\n+        if( m_currRecIdx > 0 )\n+        {\n+            writeBlock();\n+        }\n+    }\n+\n+    /**\n+     * Initialization common to all constructors.\n+     */\n+    private void initialize( final int blockSize, final int recordSize )\n+    {\n+        m_debug = false;\n+        m_blockSize = blockSize;\n+        m_recordSize = recordSize;\n+        m_recsPerBlock = ( m_blockSize / m_recordSize );\n+        m_blockBuffer = new byte[ m_blockSize ];\n+\n+        if( null != m_input )\n+        {\n+            m_currBlkIdx = -1;\n+            m_currRecIdx = m_recsPerBlock;\n+        }\n+        else\n+        {\n+            m_currBlkIdx = 0;\n+            m_currRecIdx = 0;\n+        }\n+    }\n+\n+    /**\n+     * @return false if End-Of-File, else true\n+     */\n+    private boolean readBlock()\n+        throws IOException\n+    {\n+        if( m_debug )\n+        {\n+            final String message = \"ReadBlock: blkIdx = \" + m_currBlkIdx;\n+            debug( message );\n+        }\n+\n+        if( null == m_input )\n+        {\n+            final String message = \"reading from an output buffer\";\n+            throw new IOException( message );\n+        }\n+\n+        m_currRecIdx = 0;\n+\n+        int offset = 0;\n+        int bytesNeeded = m_blockSize;\n+\n+        while( bytesNeeded > 0 )\n+        {\n+            final long numBytes = m_input.read( m_blockBuffer, offset, bytesNeeded );\n+\n+            //\n+            // NOTE\n+            // We have fit EOF, and the block is not full!\n+            //\n+            // This is a broken archive. It does not follow the standard\n+            // blocking algorithm. However, because we are generous, and\n+            // it requires little effort, we will simply ignore the error\n+            // and continue as if the entire block were read. This does\n+            // not appear to break anything upstream. We used to return\n+            // false in this case.\n+            //\n+            // Thanks to 'Yohann.Roussel@alcatel.fr' for this fix.\n+            //\n+            if( numBytes == -1 )\n+            {\n+                // However, just leaving the unread portion of the buffer dirty does\n+                // cause problems in some cases.  This problem is described in\n+                // http://issues.apache.org/bugzilla/show_bug.cgi?id=29877\n+                //\n+                // The solution is to fill the unused portion of the buffer with zeros.\n+\n+                Arrays.fill(m_blockBuffer, offset, offset + bytesNeeded, (byte) 0);\n+\n+                break;\n+            }\n+\n+            offset += numBytes;\n+            bytesNeeded -= numBytes;\n+\n+            if( numBytes != m_blockSize )\n+            {\n+                if( m_debug )\n+                {\n+                    System.err.println( \"ReadBlock: INCOMPLETE READ \"\n+                                        + numBytes + \" of \" + m_blockSize\n+                                        + \" bytes read.\" );\n+                }\n+            }\n+        }\n+\n+        m_currBlkIdx++;\n+\n+        return true;\n+    }\n+\n+    /**\n+     * Write a TarBuffer block to the archive.\n+     *\n+     * @exception IOException Description of Exception\n+     */\n+    private void writeBlock()\n+        throws IOException\n+    {\n+        if( m_debug )\n+        {\n+            final String message = \"WriteBlock: blkIdx = \" + m_currBlkIdx;\n+            debug( message );\n+        }\n+\n+        if( null == m_output )\n+        {\n+            final String message = \"writing to an input buffer\";\n+            throw new IOException( message );\n+        }\n+\n+        m_output.write( m_blockBuffer, 0, m_blockSize );\n+        m_output.flush();\n+\n+        m_currRecIdx = 0;\n+        m_currBlkIdx++;\n+    }\n+\n+    protected void debug( final String message )\n+    {\n+        if( m_debug )\n+        {\n+            System.err.println( message );\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarConstants.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.tar;\n+\n+/**\n+ * This interface contains all the definitions used in the package.\n+ */\n+interface TarConstants\n+{\n+    /**\n+     * The length of the mode field in a header buffer.\n+     */\n+    int MODELEN = 8;\n+\n+    /**\n+     * The length of the user id field in a header buffer.\n+     */\n+    int UIDLEN = 8;\n+\n+    /**\n+     * The length of the group id field in a header buffer.\n+     */\n+    int GIDLEN = 8;\n+\n+    /**\n+     * The length of the checksum field in a header buffer.\n+     */\n+    int CHKSUMLEN = 8;\n+\n+    /**\n+     * The length of the size field in a header buffer.\n+     */\n+    int SIZELEN = 12;\n+\n+    /**\n+     * The length of the magic field in a header buffer.\n+     */\n+    int MAGICLEN = 8;\n+\n+    /**\n+     * The length of the modification time field in a header buffer.\n+     */\n+    int MODTIMELEN = 12;\n+\n+    /**\n+     * The length of the user name field in a header buffer.\n+     */\n+    int UNAMELEN = 32;\n+\n+    /**\n+     * The length of the group name field in a header buffer.\n+     */\n+    int GNAMELEN = 32;\n+\n+    /**\n+     * The length of the devices field in a header buffer.\n+     */\n+    int DEVLEN = 8;\n+\n+    /**\n+     * LF_ constants represent the \"link flag\" of an entry, or more commonly,\n+     * the \"entry type\". This is the \"old way\" of indicating a normal file.\n+     */\n+    byte LF_OLDNORM = 0;\n+\n+    /**\n+     * Normal file type.\n+     */\n+    byte LF_NORMAL = (byte)'0';\n+\n+    /**\n+     * Link file type.\n+     */\n+    byte LF_LINK = (byte)'1';\n+\n+    /**\n+     * Symbolic link file type.\n+     */\n+    byte LF_SYMLINK = (byte)'2';\n+\n+    /**\n+     * Character device file type.\n+     */\n+    byte LF_CHR = (byte)'3';\n+\n+    /**\n+     * Block device file type.\n+     */\n+    byte LF_BLK = (byte)'4';\n+\n+    /**\n+     * Directory file type.\n+     */\n+    byte LF_DIR = (byte)'5';\n+\n+    /**\n+     * FIFO (pipe) file type.\n+     */\n+    byte LF_FIFO = (byte)'6';\n+\n+    /**\n+     * Contiguous file type.\n+     */\n+    byte LF_CONTIG = (byte)'7';\n+\n+    /**\n+     * The magic tag representing a POSIX tar archive.\n+     */\n+    String TMAGIC = \"ustar\";\n+\n+    /**\n+     * The magic tag representing a GNU tar archive.\n+     */\n+    String GNU_TMAGIC = \"ustar  \";\n+\n+    /**\n+     * The namr of the GNU tar entry which contains a long name.\n+     */\n+    String GNU_LONGLINK = \"././@LongLink\";\n+\n+    /**\n+     * Identifies the *next* file on the tape as having a long name.\n+     */\n+    byte LF_GNUTYPE_LONGNAME = (byte)'L';\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarInputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.tar;\n+\n+import java.io.FilterInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+\n+/**\n+ * The TarInputStream reads a UNIX tar archive as an InputStream. methods are\n+ * provided to position at each successive entry in the archive, and the read\n+ * each entry as a normal input stream using read().\n+ */\n+public class TarInputStream\n+    extends FilterInputStream\n+{\n+    private TarBuffer m_buffer;\n+    private TarArchiveEntry m_currEntry;\n+    private boolean m_debug;\n+    private int m_entryOffset;\n+    private int m_entrySize;\n+    private boolean m_hasHitEOF;\n+    private byte[] m_oneBuf;\n+    private byte[] m_readBuf;\n+\n+    /**\n+     * Construct a TarInputStream using specified input\n+     * stream and default block and record sizes.\n+     *\n+     * @param input stream to create TarInputStream from\n+     * @see TarBuffer#DEFAULT_BLOCKSIZE\n+     * @see TarBuffer#DEFAULT_RECORDSIZE\n+     */\n+    public TarInputStream( final InputStream input )\n+    {\n+        this( input, TarBuffer.DEFAULT_BLOCKSIZE, TarBuffer.DEFAULT_RECORDSIZE );\n+    }\n+\n+    /**\n+     * Construct a TarInputStream using specified input\n+     * stream, block size and default record sizes.\n+     *\n+     * @param input stream to create TarInputStream from\n+     * @param blockSize the block size to use\n+     * @see TarBuffer#DEFAULT_RECORDSIZE\n+     */\n+    public TarInputStream( final InputStream input,\n+                           final int blockSize )\n+    {\n+        this( input, blockSize, TarBuffer.DEFAULT_RECORDSIZE );\n+    }\n+\n+    /**\n+     * Construct a TarInputStream using specified input\n+     * stream, block size and record sizes.\n+     *\n+     * @param input stream to create TarInputStream from\n+     * @param blockSize the block size to use\n+     * @param recordSize the record size to use\n+     */\n+    public TarInputStream( final InputStream input,\n+                           final int blockSize,\n+                           final int recordSize )\n+    {\n+        super( input );\n+\n+        m_buffer = new TarBuffer( input, blockSize, recordSize );\n+        m_oneBuf = new byte[ 1 ];\n+    }\n+\n+    /**\n+     * Sets the debugging flag.\n+     *\n+     * @param debug The new Debug value\n+     */\n+    public void setDebug( final boolean debug )\n+    {\n+        m_debug = debug;\n+        m_buffer.setDebug( debug );\n+    }\n+\n+    /**\n+     * Get the next entry in this tar archive. This will skip over any remaining\n+     * data in the current entry, if there is one, and place the input stream at\n+     * the header of the next entry, and read the header and instantiate a new\n+     * TarEntry from the header bytes and return that entry. If there are no\n+     * more entries in the archive, null will be returned to indicate that the\n+     * end of the archive has been reached.\n+     *\n+     * @return The next TarEntry in the archive, or null.\n+     * @exception IOException Description of Exception\n+     */\n+    public TarArchiveEntry getNextEntry()\n+        throws IOException\n+    {\n+        if( m_hasHitEOF )\n+        {\n+            return null;\n+        }\n+\n+        if( m_currEntry != null )\n+        {\n+            final int numToSkip = m_entrySize - m_entryOffset;\n+\n+            if( m_debug )\n+            {\n+                final String message = \"TarInputStream: SKIP currENTRY '\" +\n+                    m_currEntry.getName() + \"' SZ \" + m_entrySize +\n+                    \" OFF \" + m_entryOffset + \"  skipping \" + numToSkip + \" bytes\";\n+                debug( message );\n+            }\n+\n+            if( numToSkip > 0 )\n+            {\n+                skip( numToSkip );\n+            }\n+\n+            m_readBuf = null;\n+        }\n+\n+        final byte[] headerBuf = m_buffer.readRecord();\n+        if( headerBuf == null )\n+        {\n+            if( m_debug )\n+            {\n+                debug( \"READ NULL RECORD\" );\n+            }\n+            m_hasHitEOF = true;\n+        }\n+        else if( m_buffer.isEOFRecord( headerBuf ) )\n+        {\n+            if( m_debug )\n+            {\n+                debug( \"READ EOF RECORD\" );\n+            }\n+            m_hasHitEOF = true;\n+        }\n+\n+        if( m_hasHitEOF )\n+        {\n+            m_currEntry = null;\n+        }\n+        else\n+        {\n+            m_currEntry = new TarArchiveEntry( headerBuf );\n+\n+            if( !( headerBuf[ 257 ] == 'u' && headerBuf[ 258 ] == 's' &&\n+                headerBuf[ 259 ] == 't' && headerBuf[ 260 ] == 'a' &&\n+                headerBuf[ 261 ] == 'r' ) )\n+            {\n+                //Must be v7Format\n+            }\n+\n+            if( m_debug )\n+            {\n+                final String message = \"TarInputStream: SET CURRENTRY '\" +\n+                    m_currEntry.getName() + \"' size = \" + m_currEntry.getSize();\n+                debug( message );\n+            }\n+\n+            m_entryOffset = 0;\n+\n+            // REVIEW How do we resolve this discrepancy?!\n+            m_entrySize = (int)m_currEntry.getSize();\n+        }\n+\n+        if( null != m_currEntry && m_currEntry.isGNULongNameEntry() )\n+        {\n+            // read in the name\n+            final StringBuffer longName = new StringBuffer();\n+            final byte[] buffer = new byte[ 256 ];\n+            int length = 0;\n+            while( ( length = read( buffer ) ) >= 0 )\n+            {\n+                final String str = new String( buffer, 0, length );\n+                longName.append( str );\n+            }\n+            getNextEntry();\n+\n+            // remove trailing null terminator\n+            if (longName.length() > 0\n+                && longName.charAt(longName.length() - 1) == 0) {\n+                longName.deleteCharAt(longName.length() - 1);\n+            }\n+            \n+            m_currEntry.setName( longName.toString() );\n+        }\n+\n+        return m_currEntry;\n+    }\n+\n+    /**\n+     * Get the record size being used by this stream's TarBuffer.\n+     *\n+     * @return The TarBuffer record size.\n+     */\n+    public int getRecordSize()\n+    {\n+        return m_buffer.getRecordSize();\n+    }\n+\n+    /**\n+     * Get the available data that can be read from the current entry in the\n+     * archive. This does not indicate how much data is left in the entire\n+     * archive, only in the current entry. This value is determined from the\n+     * entry's size header field and the amount of data already read from the\n+     * current entry.\n+     *\n+     * @return The number of available bytes for the current entry.\n+     * @exception IOException when an IO error causes operation to fail\n+     */\n+    public int available()\n+        throws IOException\n+    {\n+        return m_entrySize - m_entryOffset;\n+    }\n+\n+    /**\n+     * Closes this stream. Calls the TarBuffer's close() method.\n+     *\n+     * @exception IOException when an IO error causes operation to fail\n+     */\n+    public void close()\n+        throws IOException\n+    {\n+        m_buffer.close();\n+    }\n+\n+    /**\n+     * Copies the contents of the current tar archive entry directly into an\n+     * output stream.\n+     *\n+     * @param output The OutputStream into which to write the entry's data.\n+     * @exception IOException when an IO error causes operation to fail\n+     */\n+    public void copyEntryContents( final OutputStream output )\n+        throws IOException\n+    {\n+        final byte[] buffer = new byte[ 32 * 1024 ];\n+        while( true )\n+        {\n+            final int numRead = read( buffer, 0, buffer.length );\n+            if( numRead == -1 )\n+            {\n+                break;\n+            }\n+\n+            output.write( buffer, 0, numRead );\n+        }\n+    }\n+\n+    /**\n+     * Since we do not support marking just yet, we do nothing.\n+     *\n+     * @param markLimit The limit to mark.\n+     */\n+    public void mark( int markLimit )\n+    {\n+    }\n+\n+    /**\n+     * Since we do not support marking just yet, we return false.\n+     *\n+     * @return False.\n+     */\n+    public boolean markSupported()\n+    {\n+        return false;\n+    }\n+\n+    /**\n+     * Reads a byte from the current tar archive entry. This method simply calls\n+     * read( byte[], int, int ).\n+     *\n+     * @return The byte read, or -1 at EOF.\n+     * @exception IOException when an IO error causes operation to fail\n+     */\n+    public int read()\n+        throws IOException\n+    {\n+        final int num = read( m_oneBuf, 0, 1 );\n+        if( num == -1 )\n+        {\n+            return num;\n+        }\n+        else\n+        {\n+            return (int)m_oneBuf[ 0 ];\n+        }\n+    }\n+\n+    /**\n+     * Reads bytes from the current tar archive entry. This method simply calls\n+     * read( byte[], int, int ).\n+     *\n+     * @param buffer The buffer into which to place bytes read.\n+     * @return The number of bytes read, or -1 at EOF.\n+     * @exception IOException when an IO error causes operation to fail\n+     */\n+    public int read( final byte[] buffer )\n+        throws IOException\n+    {\n+        return read( buffer, 0, buffer.length );\n+    }\n+\n+    /**\n+     * Reads bytes from the current tar archive entry. This method is aware of\n+     * the boundaries of the current entry in the archive and will deal with\n+     * them as if they were this stream's start and EOF.\n+     *\n+     * @param buffer The buffer into which to place bytes read.\n+     * @param offset The offset at which to place bytes read.\n+     * @param count The number of bytes to read.\n+     * @return The number of bytes read, or -1 at EOF.\n+     * @exception IOException when an IO error causes operation to fail\n+     */\n+    public int read( final byte[] buffer,\n+                     final int offset,\n+                     final int count )\n+        throws IOException\n+    {\n+        int position = offset;\n+        int numToRead = count;\n+        int totalRead = 0;\n+\n+        if( m_entryOffset >= m_entrySize )\n+        {\n+            return -1;\n+        }\n+\n+        if( ( numToRead + m_entryOffset ) > m_entrySize )\n+        {\n+            numToRead = ( m_entrySize - m_entryOffset );\n+        }\n+\n+        if( null != m_readBuf )\n+        {\n+            final int size =\n+                ( numToRead > m_readBuf.length ) ? m_readBuf.length : numToRead;\n+\n+            System.arraycopy( m_readBuf, 0, buffer, position, size );\n+\n+            if( size >= m_readBuf.length )\n+            {\n+                m_readBuf = null;\n+            }\n+            else\n+            {\n+                final int newLength = m_readBuf.length - size;\n+                final byte[] newBuffer = new byte[ newLength ];\n+\n+                System.arraycopy( m_readBuf, size, newBuffer, 0, newLength );\n+\n+                m_readBuf = newBuffer;\n+            }\n+\n+            totalRead += size;\n+            numToRead -= size;\n+            position += size;\n+        }\n+\n+        while( numToRead > 0 )\n+        {\n+            final byte[] rec = m_buffer.readRecord();\n+            if( null == rec )\n+            {\n+                // Unexpected EOF!\n+                final String message =\n+                    \"unexpected EOF with \" + numToRead + \" bytes unread\";\n+                throw new IOException( message );\n+            }\n+\n+            int size = numToRead;\n+            final int recordLength = rec.length;\n+\n+            if( recordLength > size )\n+            {\n+                System.arraycopy( rec, 0, buffer, position, size );\n+\n+                m_readBuf = new byte[ recordLength - size ];\n+\n+                System.arraycopy( rec, size, m_readBuf, 0, recordLength - size );\n+            }\n+            else\n+            {\n+                size = recordLength;\n+\n+                System.arraycopy( rec, 0, buffer, position, recordLength );\n+            }\n+\n+            totalRead += size;\n+            numToRead -= size;\n+            position += size;\n+        }\n+\n+        m_entryOffset += totalRead;\n+\n+        return totalRead;\n+    }\n+\n+    /**\n+     * Since we do not support marking just yet, we do nothing.\n+     */\n+    public void reset()\n+    {\n+    }\n+\n+    /**\n+     * Skip bytes in the input buffer. This skips bytes in the current entry's\n+     * data, not the entire archive, and will stop at the end of the current\n+     * entry's data if the number to skip extends beyond that point.\n+     *\n+     * @param numToSkip The number of bytes to skip.\n+     * @exception IOException when an IO error causes operation to fail\n+     */\n+    public void skip( final int numToSkip )\n+        throws IOException\n+    {\n+        // REVIEW\n+        // This is horribly inefficient, but it ensures that we\n+        // properly skip over bytes via the TarBuffer...\n+        //\n+        final byte[] skipBuf = new byte[ 8 * 1024 ];\n+        int num = numToSkip;\n+        while( num > 0 )\n+        {\n+            final int count = ( num > skipBuf.length ) ? skipBuf.length : num;\n+            final int numRead = read( skipBuf, 0, count );\n+            if( numRead == -1 )\n+            {\n+                break;\n+            }\n+\n+            num -= numRead;\n+        }\n+    }\n+\n+    /**\n+     * Utility method to do debugging.\n+     * Capable of being overidden in sub-classes.\n+     *\n+     * @param message the message to use in debugging\n+     */\n+    protected void debug( final String message )\n+    {\n+        if( m_debug )\n+        {\n+            System.err.println( message );\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarOutputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.tar;\n+\n+import java.io.FilterOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+\n+/**\n+ * The TarOutputStream writes a UNIX tar archive as an OutputStream. Methods are\n+ * provided to put entries, and then write their contents by writing to this\n+ * stream using write().\n+ */\n+public class TarOutputStream\n+    extends FilterOutputStream\n+{\n+    /**\n+     * Flag to indicate that an error should be generated if\n+     * an attempt is made to write an entry that exceeds the 100 char\n+     * POSIX limit.\n+     */\n+    public static final int LONGFILE_ERROR = 0;\n+\n+    /**\n+     * Flag to indicate that entry name should be truncated if\n+     * an attempt is made to write an entry that exceeds the 100 char\n+     * POSIX limit.\n+     */\n+    public static final int LONGFILE_TRUNCATE = 1;\n+\n+    /**\n+     * Flag to indicate that entry name should be formatted\n+     * according to GNU tar extension if an attempt is made\n+     * to write an entry that exceeds the 100 char POSIX\n+     * limit. Note that this makes the jar unreadable by\n+     * non-GNU tar commands.\n+     */\n+    public static final int LONGFILE_GNU = 2;\n+\n+    private int m_longFileMode = LONGFILE_ERROR;\n+    private byte[] m_assemBuf;\n+    private int m_assemLen;\n+    private TarBuffer m_buffer;\n+    private int m_currBytes;\n+    private int m_currSize;\n+\n+    private byte[] m_oneBuf;\n+    private byte[] m_recordBuf;\n+\n+    /**\n+     * Construct a TarOutputStream using specified input\n+     * stream and default block and record sizes.\n+     *\n+     * @param output stream to create TarOutputStream from\n+     * @see TarBuffer#DEFAULT_BLOCKSIZE\n+     * @see TarBuffer#DEFAULT_RECORDSIZE\n+     */\n+    public TarOutputStream( final OutputStream output )\n+    {\n+        this( output, TarBuffer.DEFAULT_BLOCKSIZE, TarBuffer.DEFAULT_RECORDSIZE );\n+    }\n+\n+    /**\n+     * Construct a TarOutputStream using specified input\n+     * stream, block size and default record sizes.\n+     *\n+     * @param output stream to create TarOutputStream from\n+     * @param blockSize the block size\n+     * @see TarBuffer#DEFAULT_RECORDSIZE\n+     */\n+    public TarOutputStream( final OutputStream output,\n+                            final int blockSize )\n+    {\n+        this( output, blockSize, TarBuffer.DEFAULT_RECORDSIZE );\n+    }\n+\n+    /**\n+     * Construct a TarOutputStream using specified input\n+     * stream, block size and record sizes.\n+     *\n+     * @param output stream to create TarOutputStream from\n+     * @param blockSize the block size\n+     * @param recordSize the record size\n+     */\n+    public TarOutputStream( final OutputStream output,\n+                            final int blockSize,\n+                            final int recordSize )\n+    {\n+        super( output );\n+\n+        m_buffer = new TarBuffer( output, blockSize, recordSize );\n+        m_assemLen = 0;\n+        m_assemBuf = new byte[ recordSize ];\n+        m_recordBuf = new byte[ recordSize ];\n+        m_oneBuf = new byte[ 1 ];\n+    }\n+\n+    /**\n+     * Sets the debugging flag in this stream's TarBuffer.\n+     *\n+     * @param debug The new BufferDebug value\n+     */\n+    public void setBufferDebug( boolean debug )\n+    {\n+        m_buffer.setDebug( debug );\n+    }\n+\n+    /**\n+     * Set the mode used to work with entrys exceeding\n+     * 100 chars (and thus break the POSIX standard).\n+     * Must be one of the LONGFILE_* constants.\n+     *\n+     * @param longFileMode the mode\n+     */\n+    public void setLongFileMode( final int longFileMode )\n+    {\n+        if( LONGFILE_ERROR != longFileMode &&\n+            LONGFILE_GNU != longFileMode &&\n+            LONGFILE_TRUNCATE != longFileMode )\n+        {\n+            throw new IllegalArgumentException( \"longFileMode\" );\n+        }\n+        m_longFileMode = longFileMode;\n+    }\n+\n+    /**\n+     * Get the record size being used by this stream's TarBuffer.\n+     *\n+     * @return The TarBuffer record size.\n+     */\n+    public int getRecordSize()\n+    {\n+        return m_buffer.getRecordSize();\n+    }\n+\n+    /**\n+     * Ends the TAR archive and closes the underlying OutputStream. This means\n+     * that finish() is called followed by calling the TarBuffer's close().\n+     *\n+     * @exception IOException when an IO error causes operation to fail\n+     */\n+    public void close()\n+        throws IOException\n+    {\n+        finish();\n+        m_buffer.close();\n+    }\n+\n+    /**\n+     * Close an entry. This method MUST be called for all file entries that\n+     * contain data. The reason is that we must buffer data written to the\n+     * stream in order to satisfy the buffer's record based writes. Thus, there\n+     * may be data fragments still being assembled that must be written to the\n+     * output stream before this entry is closed and the next entry written.\n+     *\n+     * @exception IOException when an IO error causes operation to fail\n+     */\n+    public void closeEntry()\n+        throws IOException\n+    {\n+        if( m_assemLen > 0 )\n+        {\n+            for( int i = m_assemLen; i < m_assemBuf.length; ++i )\n+            {\n+                m_assemBuf[ i ] = 0;\n+            }\n+\n+            m_buffer.writeRecord( m_assemBuf );\n+\n+            m_currBytes += m_assemLen;\n+            m_assemLen = 0;\n+        }\n+\n+        if( m_currBytes < m_currSize )\n+        {\n+            final String message = \"entry closed at '\" + m_currBytes +\n+                \"' before the '\" + m_currSize +\n+                \"' bytes specified in the header were written\";\n+            throw new IOException( message );\n+        }\n+    }\n+\n+    /**\n+     * Ends the TAR archive without closing the underlying OutputStream. The\n+     * result is that the EOF record of nulls is written.\n+     *\n+     * @exception IOException when an IO error causes operation to fail\n+     */\n+    public void finish()\n+        throws IOException\n+    {\n+        writeEOFRecord();\n+    }\n+\n+    /**\n+     * Put an entry on the output stream. This writes the entry's header record\n+     * and positions the output stream for writing the contents of the entry.\n+     * Once this method is called, the stream is ready for calls to write() to\n+     * write the entry's contents. Once the contents are written, closeEntry()\n+     * <B>MUST</B> be called to ensure that all buffered data is completely\n+     * written to the output stream.\n+     *\n+     * @param entry The TarArchiveEntry to be written to the archive.\n+     * @exception IOException when an IO error causes operation to fail\n+     */\n+    public void putNextEntry( final TarArchiveEntry entry )\n+        throws IOException\n+    {\n+        if( entry.getName().length() >= TarArchiveEntry.NAMELEN )\n+        {\n+            if( m_longFileMode == LONGFILE_GNU )\n+            {\n+                // create a TarArchiveEntry for the LongLink, the contents\n+                // of which are the entry's name\n+                final TarArchiveEntry longLinkEntry =\n+                    new TarArchiveEntry( TarConstants.GNU_LONGLINK,\n+                                  TarConstants.LF_GNUTYPE_LONGNAME );\n+\n+                longLinkEntry.setSize( entry.getName().length() );\n+                putNextEntry( longLinkEntry );\n+                write( entry.getName().getBytes() );\n+                //write( 0 );\n+                closeEntry();\n+            }\n+            else if( m_longFileMode != LONGFILE_TRUNCATE )\n+            {\n+                final String message = \"file name '\" + entry.getName() +\n+                    \"' is too long ( > \" + TarArchiveEntry.NAMELEN + \" bytes)\";\n+                throw new IOException( message );\n+            }\n+        }\n+\n+        entry.writeEntryHeader( m_recordBuf );\n+        m_buffer.writeRecord( m_recordBuf );\n+\n+        m_currBytes = 0;\n+\n+        if( entry.isDirectory() )\n+        {\n+            m_currSize = 0;\n+        }\n+        else\n+        {\n+            m_currSize = (int)entry.getSize();\n+        }\n+    }\n+\n+    /**\n+     * Copies the contents of the specified stream into current tar\n+     * archive entry.\n+     *\n+     * @param input The InputStream from which to read entrys data\n+     * @exception IOException when an IO error causes operation to fail\n+     */\n+    public void copyEntryContents( final InputStream input )\n+        throws IOException\n+    {\n+        final byte[] buffer = new byte[ 32 * 1024 ];\n+        while( true )\n+        {\n+            final int numRead = input.read( buffer, 0, buffer.length );\n+            if( numRead == -1 )\n+            {\n+                break;\n+            }\n+\n+            write( buffer, 0, numRead );\n+        }\n+    }\n+\n+    /**\n+     * Writes a byte to the current tar archive entry. This method simply calls\n+     * read( byte[], int, int ).\n+     *\n+     * @param data The byte written.\n+     * @exception IOException when an IO error causes operation to fail\n+     */\n+    public void write( final int data )\n+        throws IOException\n+    {\n+        m_oneBuf[ 0 ] = (byte)data;\n+\n+        write( m_oneBuf, 0, 1 );\n+    }\n+\n+    /**\n+     * Writes bytes to the current tar archive entry. This method simply calls\n+     * write( byte[], int, int ).\n+     *\n+     * @param buffer The buffer to write to the archive.\n+     * @exception IOException when an IO error causes operation to fail\n+     */\n+    public void write( final byte[] buffer )\n+        throws IOException\n+    {\n+        write( buffer, 0, buffer.length );\n+    }\n+\n+    /**\n+     * Writes bytes to the current tar archive entry. This method is aware of\n+     * the current entry and will throw an exception if you attempt to write\n+     * bytes past the length specified for the current entry. The method is also\n+     * (painfully) aware of the record buffering required by TarBuffer, and\n+     * manages buffers that are not a multiple of recordsize in length,\n+     * including assembling records from small buffers.\n+     *\n+     * @param buffer The buffer to write to the archive.\n+     * @param offset The offset in the buffer from which to get bytes.\n+     * @param count The number of bytes to write.\n+     * @exception IOException when an IO error causes operation to fail\n+     */\n+    public void write( final byte[] buffer,\n+                       final int offset,\n+                       final int count )\n+        throws IOException\n+    {\n+        int position = offset;\n+        int numToWrite = count;\n+        if( ( m_currBytes + numToWrite ) > m_currSize )\n+        {\n+            final String message = \"request to write '\" + numToWrite +\n+                \"' bytes exceeds size in header of '\" + m_currSize + \"' bytes\";\n+            throw new IOException( message );\n+            //\n+            // We have to deal with assembly!!!\n+            // The programmer can be writing little 32 byte chunks for all\n+            // we know, and we must assemble complete records for writing.\n+            // REVIEW Maybe this should be in TarBuffer? Could that help to\n+            // eliminate some of the buffer copying.\n+            //\n+        }\n+\n+        if( m_assemLen > 0 )\n+        {\n+            if( ( m_assemLen + numToWrite ) >= m_recordBuf.length )\n+            {\n+                final int length = m_recordBuf.length - m_assemLen;\n+\n+                System.arraycopy( m_assemBuf, 0, m_recordBuf, 0,\n+                                  m_assemLen );\n+                System.arraycopy( buffer, position, m_recordBuf,\n+                                  m_assemLen, length );\n+                m_buffer.writeRecord( m_recordBuf );\n+\n+                m_currBytes += m_recordBuf.length;\n+                position += length;\n+                numToWrite -= length;\n+                m_assemLen = 0;\n+            }\n+            else\n+            {\n+                System.arraycopy( buffer, position, m_assemBuf, m_assemLen,\n+                                  numToWrite );\n+\n+                position += numToWrite;\n+                m_assemLen += numToWrite;\n+                numToWrite -= numToWrite;\n+            }\n+        }\n+\n+        //\n+        // When we get here we have EITHER:\n+        // o An empty \"assemble\" buffer.\n+        // o No bytes to write (numToWrite == 0)\n+        //\n+        while( numToWrite > 0 )\n+        {\n+            if( numToWrite < m_recordBuf.length )\n+            {\n+                System.arraycopy( buffer, position, m_assemBuf, m_assemLen,\n+                                  numToWrite );\n+\n+                m_assemLen += numToWrite;\n+\n+                break;\n+            }\n+\n+            m_buffer.writeRecord( buffer, position );\n+\n+            int num = m_recordBuf.length;\n+\n+            m_currBytes += num;\n+            numToWrite -= num;\n+            position += num;\n+        }\n+    }\n+\n+    /**\n+     * Write an EOF (end of archive) record to the tar archive. An EOF record\n+     * consists of a record of all zeros.\n+     *\n+     * @exception IOException when an IO error causes operation to fail\n+     */\n+    private void writeEOFRecord()\n+        throws IOException\n+    {\n+        for( int i = 0; i < m_recordBuf.length; ++i )\n+        {\n+            m_recordBuf[ i ] = 0;\n+        }\n+\n+        m_buffer.writeRecord( m_recordBuf );\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarUtils.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.tar;\n+\n+/**\n+ * This class provides static utility methods to work with byte streams.\n+ */\n+class TarUtils\n+{\n+    /**\n+     * Parse the checksum octal integer from a header buffer.\n+     *\n+     * @param offset The offset into the buffer from which to parse.\n+     * @param length The number of header bytes to parse.\n+     * @param value Description of Parameter\n+     * @param buf Description of Parameter\n+     * @return The integer value of the entry's checksum.\n+     */\n+    public static int getCheckSumOctalBytes( final long value,\n+                                             final byte[] buf,\n+                                             final int offset,\n+                                             final int length )\n+    {\n+        getOctalBytes( value, buf, offset, length );\n+\n+        buf[ offset + length - 1 ] = (byte)' ';\n+        buf[ offset + length - 2 ] = 0;\n+\n+        return offset + length;\n+    }\n+\n+    /**\n+     * Parse an octal long integer from a header buffer.\n+     *\n+     * @param offset The offset into the buffer from which to parse.\n+     * @param length The number of header bytes to parse.\n+     * @param value Description of Parameter\n+     * @param buf Description of Parameter\n+     * @return The long value of the octal bytes.\n+     */\n+    public static int getLongOctalBytes( final long value,\n+                                         final byte[] buf,\n+                                         final int offset,\n+                                         final int length )\n+    {\n+        byte[] temp = new byte[ length + 1 ];\n+\n+        getOctalBytes( value, temp, 0, length + 1 );\n+        System.arraycopy( temp, 0, buf, offset, length );\n+\n+        return offset + length;\n+    }\n+\n+    /**\n+     * Determine the number of bytes in an entry name.\n+     *\n+     * @param offset The offset into the buffer from which to parse.\n+     * @param length The number of header bytes to parse.\n+     * @param name Description of Parameter\n+     * @param buffer Description of Parameter\n+     * @return The number of bytes in a header's entry name.\n+     */\n+    public static int getNameBytes( final StringBuffer name,\n+                                    final byte[] buffer,\n+                                    final int offset,\n+                                    final int length )\n+    {\n+        int i;\n+\n+        for( i = 0; i < length && i < name.length(); ++i )\n+        {\n+            buffer[ offset + i ] = (byte)name.charAt( i );\n+        }\n+\n+        for( ; i < length; ++i )\n+        {\n+            buffer[ offset + i ] = 0;\n+        }\n+\n+        return offset + length;\n+    }\n+\n+    /**\n+     * Parse an octal integer from a header buffer.\n+     *\n+     * @param offset The offset into the buffer from which to parse.\n+     * @param length The number of header bytes to parse.\n+     * @return The integer value of the octal bytes.\n+     */\n+    public static int getOctalBytes( final long value,\n+                                     final byte[] buffer,\n+                                     final int offset,\n+                                     final int length )\n+    {\n+        int idx = length - 1;\n+\n+        buffer[ offset + idx ] = 0;\n+        --idx;\n+        buffer[ offset + idx ] = (byte)' ';\n+        --idx;\n+\n+        if( value == 0 )\n+        {\n+            buffer[ offset + idx ] = (byte)'0';\n+            --idx;\n+        }\n+        else\n+        {\n+            long val = value;\n+            while( idx >= 0 && val > 0 )\n+            {\n+                buffer[ offset + idx ] = (byte)( (byte)'0' + (byte)( val & 7 ) );\n+                val = val >> 3;\n+                idx--;\n+            }\n+        }\n+\n+        while( idx >= 0 )\n+        {\n+            buffer[ offset + idx ] = (byte)' ';\n+            idx--;\n+        }\n+\n+        return offset + length;\n+    }\n+\n+    /**\n+     * Compute the checksum of a tar entry header.\n+     *\n+     * @param buffer The tar entry's header buffer.\n+     * @return The computed checksum.\n+     */\n+    public static long computeCheckSum( final byte[] buffer )\n+    {\n+        long sum = 0;\n+\n+        for( int i = 0; i < buffer.length; ++i )\n+        {\n+            sum += 255 & buffer[ i ];\n+        }\n+\n+        return sum;\n+    }\n+\n+    /**\n+     * Parse an entry name from a header buffer.\n+     *\n+     * @param header The header buffer from which to parse.\n+     * @param offset The offset into the buffer from which to parse.\n+     * @param length The number of header bytes to parse.\n+     * @return The header's entry name.\n+     */\n+    public static StringBuffer parseName( final byte[] header,\n+                                          final int offset,\n+                                          final int length )\n+    {\n+        StringBuffer result = new StringBuffer( length );\n+        int end = offset + length;\n+\n+        for( int i = offset; i < end; ++i )\n+        {\n+            if( header[ i ] == 0 )\n+            {\n+                break;\n+            }\n+\n+            result.append( (char)header[ i ] );\n+        }\n+\n+        return result;\n+    }\n+\n+    /**\n+     * Parse an octal string from a header buffer. This is used for the file\n+     * permission mode value.\n+     *\n+     * @param header The header buffer from which to parse.\n+     * @param offset The offset into the buffer from which to parse.\n+     * @param length The number of header bytes to parse.\n+     * @return The long value of the octal string.\n+     */\n+    public static long parseOctal( final byte[] header,\n+                                   final int offset,\n+                                   final int length )\n+    {\n+        long result = 0;\n+        boolean stillPadding = true;\n+        int end = offset + length;\n+\n+        for( int i = offset; i < end; ++i )\n+        {\n+            if( header[ i ] == 0 )\n+            {\n+                break;\n+            }\n+\n+            if( header[ i ] == (byte)' ' || header[ i ] == '0' )\n+            {\n+                if( stillPadding )\n+                {\n+                    continue;\n+                }\n+\n+                if( header[ i ] == (byte)' ' )\n+                {\n+                    break;\n+                }\n+            }\n+\n+            stillPadding = false;\n+            result = ( result << 3 ) + ( header[ i ] - '0' );\n+        }\n+\n+        return result;\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/AsiExtraField.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.zip;\n+\n+import java.util.zip.CRC32;\n+import java.util.zip.ZipException;\n+\n+/**\n+ * Adds Unix file permission and UID/GID fields as well as symbolic link\n+ * handling. <p>\n+ *\n+ * This class uses the ASi extra field in the format: <pre>\n+ *         Value         Size            Description\n+ *         -----         ----            -----------\n+ * (Unix3) 0x756e        Short           tag for this extra block type\n+ *         TSize         Short           total data size for this block\n+ *         CRC           Long            CRC-32 of the remaining data\n+ *         Mode          Short           file permissions\n+ *         SizDev        Long            symlink'd size OR major/minor dev num\n+ *         UID           Short           user ID\n+ *         GID           Short           group ID\n+ *         (var.)        variable        symbolic link filename\n+ * </pre> taken from appnote.iz (Info-ZIP note, 981119) found at <a\n+ * href=\"ftp://ftp.uu.net/pub/archiving/zip/doc/\">\n+ * ftp://ftp.uu.net/pub/archiving/zip/doc/</a> </p> <p>\n+ *\n+ * Short is two bytes and Long is four bytes in big endian byte and word order,\n+ * device numbers are currently not supported.</p>\n+ */\n+public class AsiExtraField\n+    implements ZipExtraField, UnixStat, Cloneable\n+{\n+    private static final ZipShort HEADER_ID = new ZipShort( 0x756E );\n+\n+    /**\n+     * Standard Unix stat(2) file mode.\n+     *\n+     * @since 1.1\n+     */\n+    private int m_mode;\n+\n+    /**\n+     * User ID.\n+     *\n+     * @since 1.1\n+     */\n+    private int m_uid;\n+\n+    /**\n+     * Group ID.\n+     *\n+     * @since 1.1\n+     */\n+    private int m_gid;\n+\n+    /**\n+     * File this entry points to, if it is a symbolic link. <p>\n+     *\n+     * empty string - if entry is not a symbolic link.</p>\n+     *\n+     * @since 1.1\n+     */\n+    private String m_link = \"\";\n+\n+    /**\n+     * Is this an entry for a directory?\n+     *\n+     * @since 1.1\n+     */\n+    private boolean m_dirFlag;\n+\n+    /**\n+     * Instance used to calculate checksums.\n+     *\n+     * @since 1.1\n+     */\n+    private CRC32 m_crc = new CRC32();\n+\n+    /**\n+     * Indicate whether this entry is a directory.\n+     *\n+     * @param dirFlag The new Directory value\n+     * @since 1.1\n+     */\n+    public void setDirectory( final boolean dirFlag )\n+    {\n+        m_dirFlag = dirFlag;\n+        m_mode = getMode( m_mode );\n+    }\n+\n+    /**\n+     * Set the group id.\n+     *\n+     * @param gid The new GroupId value\n+     * @since 1.1\n+     */\n+    public void setGroupId( int gid )\n+    {\n+        m_gid = gid;\n+    }\n+\n+    /**\n+     * Indicate that this entry is a symbolic link to the given filename.\n+     *\n+     * @param name Name of the file this entry links to, empty String if it is\n+     *      not a symbolic link.\n+     * @since 1.1\n+     */\n+    public void setLinkedFile( final String name )\n+    {\n+        m_link = name;\n+        m_mode = getMode( m_mode );\n+    }\n+\n+    /**\n+     * File mode of this file.\n+     *\n+     * @param mode The new Mode value\n+     * @since 1.1\n+     */\n+    public void setMode( final int mode )\n+    {\n+        m_mode = getMode( mode );\n+    }\n+\n+    /**\n+     * Set the user id.\n+     *\n+     * @param uid The new UserId value\n+     * @since 1.1\n+     * @deprecated Use setUserID(int)\n+     * @see #setUserID(int)\n+     */\n+    public void setUserId( final int uid )\n+    {\n+        m_uid = uid;\n+    }\n+\n+    /**\n+     * Set the user id.\n+     *\n+     * @param uid The new UserId value\n+     */\n+    public void setUserID( final int uid )\n+    {\n+        m_uid = uid;\n+    }\n+\n+    /**\n+     * Delegate to local file data.\n+     *\n+     * @return The CentralDirectoryData value\n+     * @since 1.1\n+     */\n+    public byte[] getCentralDirectoryData()\n+    {\n+        return getLocalFileDataData();\n+    }\n+\n+    /**\n+     * Delegate to local file data.\n+     *\n+     * @return The CentralDirectoryLength value\n+     * @since 1.1\n+     */\n+    public ZipShort getCentralDirectoryLength()\n+    {\n+        return getLocalFileDataLength();\n+    }\n+\n+    /**\n+     * Get the group id.\n+     *\n+     * @return The GroupId value\n+     * @since 1.1\n+     */\n+    public int getGroupID()\n+    {\n+        return m_gid;\n+    }\n+\n+    /**\n+     * Get the group id.\n+     *\n+     * @return The GroupId value\n+     * @since 1.1\n+     * @deprecated Use getGroupID() instead\n+     * @see #getGroupID()\n+     */\n+    public int getGroupId()\n+    {\n+        return m_gid;\n+    }\n+\n+    /**\n+     * The Header-ID.\n+     *\n+     * @return The HeaderId value\n+     * @since 1.1\n+     */\n+    public ZipShort getHeaderID()\n+    {\n+        return HEADER_ID;\n+    }\n+\n+    /**\n+     * Name of linked file\n+     *\n+     * @return name of the file this entry links to if it is a symbolic link,\n+     *      the empty string otherwise.\n+     * @since 1.1\n+     */\n+    public String getLinkedFile()\n+    {\n+        return m_link;\n+    }\n+\n+    /**\n+     * The actual data to put into local file data - without Header-ID or length\n+     * specifier.\n+     *\n+     * @return The LocalFileDataData value\n+     * @since 1.1\n+     */\n+    public byte[] getLocalFileDataData()\n+    {\n+        // CRC will be added later\n+        byte[] data = new byte[ getLocalFileDataLength().getValue() - 4 ];\n+        System.arraycopy( ( new ZipShort( getMode() ) ).getBytes(), 0, data, 0, 2 );\n+\n+        byte[] linkArray = getLinkedFile().getBytes();\n+        System.arraycopy( ( new ZipLong( linkArray.length ) ).getBytes(),\n+                          0, data, 2, 4 );\n+\n+        System.arraycopy( ( new ZipShort( getUserID() ) ).getBytes(),\n+                          0, data, 6, 2 );\n+        System.arraycopy( ( new ZipShort( getGroupID() ) ).getBytes(),\n+                          0, data, 8, 2 );\n+\n+        System.arraycopy( linkArray, 0, data, 10, linkArray.length );\n+\n+        m_crc.reset();\n+        m_crc.update( data );\n+        long checksum = m_crc.getValue();\n+\n+        byte[] result = new byte[ data.length + 4 ];\n+        System.arraycopy( ( new ZipLong( checksum ) ).getBytes(), 0, result, 0, 4 );\n+        System.arraycopy( data, 0, result, 4, data.length );\n+        return result;\n+    }\n+\n+    /**\n+     * Length of the extra field in the local file data - without Header-ID or\n+     * length specifier.\n+     *\n+     * @return The LocalFileDataLength value\n+     * @since 1.1\n+     */\n+    public ZipShort getLocalFileDataLength()\n+    {\n+        return new ZipShort( 4 + // CRC\n+                             2 + // Mode\n+                             4 + // SizDev\n+                             2 + // UID\n+                             2 + // GID\n+                             getLinkedFile().getBytes().length );\n+    }\n+\n+    /**\n+     * File mode of this file.\n+     *\n+     * @return The Mode value\n+     * @since 1.1\n+     */\n+    public int getMode()\n+    {\n+        return m_mode;\n+    }\n+\n+    /**\n+     * Get the user id.\n+     *\n+     * @return The UserId value\n+     * @since 1.1\n+     * @deprecated Use getUserID()\n+     * @see #getUserID()\n+     */\n+    public int getUserId()\n+    {\n+        return m_uid;\n+    }\n+\n+    /**\n+     * Get the user id.\n+     *\n+     * @return The UserID value\n+     */\n+    public int getUserID()\n+    {\n+        return m_uid;\n+    }\n+\n+    /**\n+     * Is this entry a directory?\n+     *\n+     * @return The Directory value\n+     * @since 1.1\n+     */\n+    public boolean isDirectory()\n+    {\n+        return m_dirFlag && !isLink();\n+    }\n+\n+    /**\n+     * Is this entry a symbolic link?\n+     *\n+     * @return The Link value\n+     * @since 1.1\n+     */\n+    public boolean isLink()\n+    {\n+        return getLinkedFile().length() != 0;\n+    }\n+\n+    /**\n+     * Populate data from this array as if it was in local file data.\n+     *\n+     * @param buffer the buffer\n+     * @param offset the offset into buffer\n+     * @param length the length of data in buffer\n+     * @throws ZipException on error\n+     * @since 1.1\n+     */\n+    public void parseFromLocalFileData( final byte[] buffer,\n+                                        final int offset,\n+                                        final int length )\n+        throws ZipException\n+    {\n+\n+        long givenChecksum = ( new ZipLong( buffer, offset ) ).getValue();\n+        byte[] tmp = new byte[ length - 4 ];\n+        System.arraycopy( buffer, offset + 4, tmp, 0, length - 4 );\n+        m_crc.reset();\n+        m_crc.update( tmp );\n+        long realChecksum = m_crc.getValue();\n+        if( givenChecksum != realChecksum )\n+        {\n+            throw new ZipException( \"bad CRC checksum \" + Long.toHexString( givenChecksum ) +\n+                                    \" instead of \" + Long.toHexString( realChecksum ) );\n+        }\n+\n+        int newMode = ( new ZipShort( tmp, 0 ) ).getValue();\n+        byte[] linkArray = new byte[ (int)( new ZipLong( tmp, 2 ) ).getValue() ];\n+        m_uid = ( new ZipShort( tmp, 6 ) ).getValue();\n+        m_gid = ( new ZipShort( tmp, 8 ) ).getValue();\n+\n+        if( linkArray.length == 0 )\n+        {\n+            m_link = \"\";\n+        }\n+        else\n+        {\n+            System.arraycopy( tmp, 10, linkArray, 0, linkArray.length );\n+            m_link = new String( linkArray );\n+        }\n+        setDirectory( ( newMode & DIR_FLAG ) != 0 );\n+        setMode( newMode );\n+    }\n+\n+    /**\n+     * Get the file mode for given permissions with the correct file type.\n+     *\n+     * @param mode Description of Parameter\n+     * @return The Mode value\n+     * @since 1.1\n+     */\n+    protected int getMode( final int mode )\n+    {\n+        int type = FILE_FLAG;\n+        if( isLink() )\n+        {\n+            type = LINK_FLAG;\n+        }\n+        else if( isDirectory() )\n+        {\n+            type = DIR_FLAG;\n+        }\n+        return type | ( mode & PERM_MASK );\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ExtraFieldUtils.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.zip;\n+\n+import java.util.ArrayList;\n+import java.util.Hashtable;\n+import java.util.zip.ZipException;\n+\n+/**\n+ * ZipExtraField related methods\n+ */\n+public class ExtraFieldUtils\n+{\n+    /**\n+     * Static registry of known extra fields.\n+     *\n+     * @since 1.1\n+     */\n+    private static final Hashtable c_implementations;\n+\n+    static\n+    {\n+        c_implementations = new Hashtable();\n+        register( AsiExtraField.class );\n+    }\n+\n+    /**\n+     * Create an instance of the approriate ExtraField, falls back to {@link\n+     * UnrecognizedExtraField UnrecognizedExtraField}.\n+     *\n+     * Throws java.lang.IllegalAccessException if cant create implementation.\n+     *\n+     * @param headerID the header ID\n+     * @return the extra field implementation\n+     * @throws InstantiationException if cant create implementation\n+     * @throws IllegalAccessException if cant create implementation\n+     * @since 1.1\n+     */\n+    public static ZipExtraField createExtraField( final ZipShort headerID )\n+        throws InstantiationException, IllegalAccessException\n+    {\n+        final Class clazz =\n+            (Class)c_implementations.get( headerID );\n+        if( clazz != null )\n+        {\n+            return (ZipExtraField)clazz.newInstance();\n+        }\n+        final UnrecognizedExtraField unrecognized = new UnrecognizedExtraField();\n+        unrecognized.setHeaderID( headerID );\n+        return unrecognized;\n+    }\n+\n+    /**\n+     * Merges the central directory fields of the given ZipExtraFields.\n+     *\n+     * @param data the central directory data\n+     * @return the merged data\n+     * @since 1.1\n+     */\n+    public static byte[] mergeCentralDirectoryData( final ZipExtraField[] data )\n+    {\n+        int sum = 4 * data.length;\n+        for( int i = 0; i < data.length; i++ )\n+        {\n+            sum += data[ i ].getCentralDirectoryLength().getValue();\n+        }\n+        byte[] result = new byte[ sum ];\n+        int start = 0;\n+        for( int i = 0; i < data.length; i++ )\n+        {\n+            System.arraycopy( data[ i ].getHeaderID().getBytes(),\n+                              0, result, start, 2 );\n+            System.arraycopy( data[ i ].getCentralDirectoryLength().getBytes(),\n+                              0, result, start + 2, 2 );\n+            byte[] local = data[ i ].getCentralDirectoryData();\n+            System.arraycopy( local, 0, result, start + 4, local.length );\n+            start += ( local.length + 4 );\n+        }\n+        return result;\n+    }\n+\n+    /**\n+     * Merges the local file data fields of the given ZipExtraFields.\n+     *\n+     * @param data the data\n+     * @return the merged data\n+     * @since 1.1\n+     */\n+    public static byte[] mergeLocalFileDataData( final ZipExtraField[] data )\n+    {\n+        int sum = 4 * data.length;\n+        for( int i = 0; i < data.length; i++ )\n+        {\n+            sum += data[ i ].getLocalFileDataLength().getValue();\n+        }\n+        byte[] result = new byte[ sum ];\n+        int start = 0;\n+        for( int i = 0; i < data.length; i++ )\n+        {\n+            System.arraycopy( data[ i ].getHeaderID().getBytes(),\n+                              0, result, start, 2 );\n+            System.arraycopy( data[ i ].getLocalFileDataLength().getBytes(),\n+                              0, result, start + 2, 2 );\n+            byte[] local = data[ i ].getLocalFileDataData();\n+            System.arraycopy( local, 0, result, start + 4, local.length );\n+            start += ( local.length + 4 );\n+        }\n+        return result;\n+    }\n+\n+    /**\n+     * Split the array into ExtraFields and populate them with the give data.\n+     *\n+     * @param data the data to parse\n+     * @return the parsed fields\n+     * @exception ZipException on error\n+     * @since 1.1\n+     */\n+    public static ZipExtraField[] parse( final byte[] data )\n+        throws ZipException\n+    {\n+        ArrayList v = new ArrayList();\n+        int start = 0;\n+        while( start <= data.length - 4 )\n+        {\n+            final ZipShort headerID = new ZipShort( data, start );\n+            int length = ( new ZipShort( data, start + 2 ) ).getValue();\n+            if( start + 4 + length > data.length )\n+            {\n+                throw new ZipException( \"data starting at \" + start + \" is in unknown format\" );\n+            }\n+            try\n+            {\n+                ZipExtraField ze = createExtraField( headerID );\n+                ze.parseFromLocalFileData( data, start + 4, length );\n+                v.add( ze );\n+            }\n+            catch( InstantiationException ie )\n+            {\n+                throw new ZipException( ie.getMessage() );\n+            }\n+            catch( IllegalAccessException iae )\n+            {\n+                throw new ZipException( iae.getMessage() );\n+            }\n+            start += ( length + 4 );\n+        }\n+        if( start != data.length )\n+        {// array not exhausted\n+            throw new ZipException( \"data starting at \" + start + \" is in unknown format\" );\n+        }\n+\n+        final ZipExtraField[] result = new ZipExtraField[ v.size() ];\n+        return (ZipExtraField[])v.toArray( result );\n+    }\n+\n+    /**\n+     * Register a ZipExtraField implementation. <p>\n+     *\n+     * The given class must have a no-arg constructor and implement the {@link\n+     * ZipExtraField ZipExtraField interface}.</p>\n+     *\n+     * @param clazz The Class for particular implementation\n+     * @since 1.1\n+     */\n+    public static void register( final Class clazz )\n+    {\n+        try\n+        {\n+            ZipExtraField ze = (ZipExtraField)clazz.newInstance();\n+            c_implementations.put( ze.getHeaderID(), clazz );\n+        }\n+        catch( ClassCastException cc )\n+        {\n+            throw new RuntimeException( clazz +\n+                                        \" doesn\\'t implement ZipExtraField\" );\n+        }\n+        catch( InstantiationException ie )\n+        {\n+            throw new RuntimeException( clazz + \" is not a concrete class\" );\n+        }\n+        catch( IllegalAccessException ie )\n+        {\n+            throw new RuntimeException( clazz +\n+                                        \"\\'s no-arg constructor is not public\" );\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/UnixStat.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.zip;\n+\n+/**\n+ * Constants from stat.h on Unix systems.\n+ */\n+public interface UnixStat\n+{\n+    /**\n+     * Bits used for permissions (and sticky bit)\n+     *\n+     * @since 1.1\n+     */\n+    int PERM_MASK = 07777;\n+    /**\n+     * Indicates symbolic links.\n+     *\n+     * @since 1.1\n+     */\n+    int LINK_FLAG = 0120000;\n+    /**\n+     * Indicates plain files.\n+     *\n+     * @since 1.1\n+     */\n+    int FILE_FLAG = 0100000;\n+    /**\n+     * Indicates directories.\n+     *\n+     * @since 1.1\n+     */\n+    int DIR_FLAG = 040000;\n+\n+    // ----------------------------------------------------------\n+    // somewhat arbitrary choices that are quite common for shared\n+    // installations\n+    // -----------------------------------------------------------\n+\n+    /**\n+     * Default permissions for symbolic links.\n+     *\n+     * @since 1.1\n+     */\n+    int DEFAULT_LINK_PERM = 0777;\n+\n+    /**\n+     * Default permissions for directories.\n+     *\n+     * @since 1.1\n+     */\n+    int DEFAULT_DIR_PERM = 0755;\n+\n+    /**\n+     * Default permissions for plain files.\n+     *\n+     * @since 1.1\n+     */\n+    int DEFAULT_FILE_PERM = 0644;\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/UnrecognizedExtraField.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.zip;\n+\n+/**\n+ * Simple placeholder for all those extra fields we don't want to deal with. <p>\n+ *\n+ * Assumes local file data and central directory entries are identical - unless\n+ * told the opposite.</p>\n+ */\n+public class UnrecognizedExtraField\n+    implements ZipExtraField\n+{\n+    /**\n+     * Extra field data in central directory - without Header-ID or length\n+     * specifier.\n+     *\n+     * @since 1.1\n+     */\n+    private byte[] m_centralData;\n+\n+    /**\n+     * The Header-ID.\n+     *\n+     * @since 1.1\n+     */\n+    private ZipShort m_headerID;\n+\n+    /**\n+     * Extra field data in local file data - without Header-ID or length\n+     * specifier.\n+     *\n+     * @since 1.1\n+     */\n+    private byte[] m_localData;\n+\n+    /**\n+     * Set the central directory data\n+     *\n+     * @param centralData the central directory data\n+     */\n+    public void setCentralDirectoryData( final byte[] centralData )\n+    {\n+        m_centralData = centralData;\n+    }\n+\n+       /**\n+     * Set the header ID.\n+     *\n+     * @param headerID the header ID\n+     */\n+    public void setHeaderID( final ZipShort headerID )\n+    {\n+        m_headerID = headerID;\n+    }\n+\n+    /**\n+     * Set the local file data.\n+     *\n+     * @param localData the local file data\n+     */\n+    public void setLocalFileDataData( final byte[] localData )\n+    {\n+        m_localData = localData;\n+    }\n+\n+    /**\n+     * Get the central directory data.\n+     *\n+     * @return the central directory data.\n+     */\n+    public byte[] getCentralDirectoryData()\n+    {\n+        if( m_centralData != null )\n+        {\n+            return m_centralData;\n+        }\n+        return getLocalFileDataData();\n+    }\n+\n+    /**\n+     * Get the length of the central directory in bytes.\n+     *\n+     * @return the length of the central directory in bytes.\n+     */\n+    public ZipShort getCentralDirectoryLength()\n+    {\n+        if( m_centralData != null )\n+        {\n+            return new ZipShort( m_centralData.length );\n+        }\n+        return getLocalFileDataLength();\n+    }\n+\n+    /**\n+     * Get the HeaderID.\n+     *\n+     * @return the HeaderID\n+     */\n+    public ZipShort getHeaderID()\n+    {\n+        return m_headerID;\n+    }\n+\n+    /**\n+     * Get the local file data.\n+     *\n+     * @return the local file data\n+     */\n+    public byte[] getLocalFileDataData()\n+    {\n+        return m_localData;\n+    }\n+\n+    /**\n+     * Get the length of local file data in bytes.\n+     *\n+     * @return the length of local file data in bytes\n+     */\n+    public ZipShort getLocalFileDataLength()\n+    {\n+        return new ZipShort( m_localData.length );\n+    }\n+\n+    /**\n+     * Parse LocalFiledata out of supplied buffer.\n+     *\n+     * @param buffer the buffer to use\n+     * @param offset the offset into buffer\n+     * @param length then length of data\n+     */\n+    public void parseFromLocalFileData( final byte[] buffer,\n+                                        final int offset,\n+                                        final int length )\n+    {\n+        final byte[] fileData = new byte[ length ];\n+        System.arraycopy( buffer, offset, fileData, 0, length );\n+        setLocalFileDataData( fileData );\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveEntry.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.zip;\n+\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+import java.util.ArrayList;\n+import java.util.zip.ZipException;\n+\n+import org.apache.commons.compress.archivers.ArchiveEntry;\n+\n+/**\n+ * Extension that adds better handling of extra fields and provides access to\n+ * the internal and external file attributes.\n+ */\n+public class ZipArchiveEntry\n+    extends java.util.zip.ZipEntry\n+    implements ArchiveEntry\n+{\n+    /**\n+     * Helper for JDK 1.1\n+     *\n+     * @since 1.2\n+     */\n+    private static Method c_setCompressedSizeMethod;\n+\n+    /**\n+     * Helper for JDK 1.1\n+     *\n+     * @since 1.2\n+     */\n+    private static final Object c_lockReflection = new Object();\n+\n+    /**\n+     * Helper for JDK 1.1\n+     *\n+     * @since 1.2\n+     */\n+    private static boolean c_triedToGetMethod;\n+\n+    private final ArrayList m_extraFields = new ArrayList();\n+\n+    private int m_internalAttributes;\n+    private long m_externalAttributes;\n+\n+    /**\n+     * Helper for JDK 1.1 <-> 1.2 incompatibility.\n+     *\n+     * @since 1.2\n+     */\n+    private Long m_compressedSize;\n+\n+    /**\n+     * Creates a new zip entry with the specified name.\n+     *\n+     * @param name the name of entry\n+     * @since 1.1\n+     */\n+    public ZipArchiveEntry( final String name )\n+    {\n+        super( name );\n+    }\n+\n+    /**\n+     * Creates a new zip entry with fields taken from the specified zip entry.\n+     *\n+     * @param entry the JDK ZipEntry to adapt\n+     * @exception ZipException if can not create entry\n+     * @since 1.1\n+     */\n+    public ZipArchiveEntry( java.util.zip.ZipEntry entry )\n+        throws ZipException\n+    {\n+        /*\n+         * REVISIT: call super(entry) instead of this stuff in Ant2,\n+         * \"copy constructor\" has not been available in JDK 1.1\n+         */\n+        super( entry.getName() );\n+\n+        setComment( entry.getComment() );\n+        setMethod( entry.getMethod() );\n+        setTime( entry.getTime() );\n+\n+        final long size = entry.getSize();\n+        if( size > 0 )\n+        {\n+            setSize( size );\n+        }\n+\n+        final long cSize = entry.getCompressedSize();\n+        if( cSize > 0 )\n+        {\n+            setComprSize( cSize );\n+        }\n+\n+        final long crc = entry.getCrc();\n+        if( crc > 0 )\n+        {\n+            setCrc( crc );\n+        }\n+\n+        final byte[] extra = entry.getExtra();\n+        if( extra != null )\n+        {\n+            setExtraFields( ExtraFieldUtils.parse( extra ) );\n+        }\n+        else\n+        {\n+            // initializes extra data to an empty byte array\n+            setExtra();\n+        }\n+    }\n+\n+    /**\n+     * Creates a new zip entry with fields taken from the specified zip entry.\n+     *\n+     * @param entry the entry to adapt\n+     * @exception ZipException if can not create entry\n+     * @since 1.1\n+     */\n+    public ZipArchiveEntry( final ZipArchiveEntry entry )\n+        throws ZipException\n+    {\n+        this( (java.util.zip.ZipEntry)entry );\n+        setInternalAttributes( entry.getInternalAttributes() );\n+        setExternalAttributes( entry.getExternalAttributes() );\n+        setExtraFields( entry.getExtraFields() );\n+    }\n+\n+    /**\n+     * Try to get a handle to the setCompressedSize method.\n+     *\n+     * @since 1.2\n+     */\n+    private static void checkSCS()\n+    {\n+        if( !c_triedToGetMethod )\n+        {\n+            synchronized( c_lockReflection )\n+            {\n+                c_triedToGetMethod = true;\n+                try\n+                {\n+                    c_setCompressedSizeMethod =\n+                        java.util.zip.ZipEntry.class.getMethod( \"setCompressedSize\",\n+                                                                new Class[]{Long.TYPE} );\n+                }\n+                catch( NoSuchMethodException nse )\n+                {\n+                }\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Are we running JDK 1.2 or higher?\n+     *\n+     * @return Description of the Returned Value\n+     * @since 1.2\n+     */\n+    private static boolean haveSetCompressedSize()\n+    {\n+        checkSCS();\n+        return c_setCompressedSizeMethod != null;\n+    }\n+\n+    /**\n+     * Invoke setCompressedSize via reflection.\n+     *\n+     * @param entry Description of Parameter\n+     * @param size Description of Parameter\n+     * @since 1.2\n+     */\n+    private static void performSetCompressedSize( final ZipArchiveEntry entry,\n+                                                  final long size )\n+    {\n+        final Long[] s = {new Long( size )};\n+        try\n+        {\n+            c_setCompressedSizeMethod.invoke( entry, s );\n+        }\n+        catch( final InvocationTargetException ite )\n+        {\n+            final Throwable nested = ite.getTargetException();\n+            final String message = \"Exception setting the compressed size \" +\n+                \"of \" + entry + \": \" + nested.getMessage();\n+            throw new RuntimeException( message );\n+        }\n+        catch( final Throwable t )\n+        {\n+            final String message = \"Exception setting the compressed size \" +\n+                \"of \" + entry + \": \" + t.getMessage();\n+            throw new RuntimeException( message );\n+        }\n+    }\n+\n+    /**\n+     * Make this class work in JDK 1.1 like a 1.2 class. <p>\n+     *\n+     * This either stores the size for later usage or invokes setCompressedSize\n+     * via reflection.</p>\n+     *\n+     * @param size The new ComprSize value\n+     * @since 1.2\n+     */\n+    public void setComprSize( final long size )\n+    {\n+        if( haveSetCompressedSize() )\n+        {\n+            performSetCompressedSize( this, size );\n+        }\n+        else\n+        {\n+            m_compressedSize = new Long( size );\n+        }\n+    }\n+\n+    /**\n+     * Sets the external file attributes.\n+     *\n+     * @param externalAttributes The new ExternalAttributes value\n+     * @since 1.1\n+     */\n+    public void setExternalAttributes( final long externalAttributes )\n+    {\n+        m_externalAttributes = externalAttributes;\n+    }\n+\n+    /**\n+     * Throws an Exception if extra data cannot be parsed into extra fields.\n+     *\n+     * @param extra The new Extra value\n+     * @throws RuntimeException if fail to set extra data\n+     * @since 1.1\n+     */\n+    public void setExtra( final byte[] extra )\n+        throws RuntimeException\n+    {\n+        try\n+        {\n+            setExtraFields( ExtraFieldUtils.parse( extra ) );\n+        }\n+        catch( final Exception e )\n+        {\n+            throw new RuntimeException( e.getMessage() );\n+        }\n+    }\n+\n+    /**\n+     * Replaces all currently attached extra fields with the new array.\n+     *\n+     * @param fields The new ExtraFields value\n+     * @since 1.1\n+     */\n+    public void setExtraFields( final ZipExtraField[] fields )\n+    {\n+        m_extraFields.clear();\n+        for( int i = 0; i < fields.length; i++ )\n+        {\n+            m_extraFields.add( fields[ i ] );\n+        }\n+        setExtra();\n+    }\n+\n+    /**\n+     * Sets the internal file attributes.\n+     *\n+     * @param value The new InternalAttributes value\n+     * @since 1.1\n+     */\n+    public void setInternalAttributes( final int value )\n+    {\n+        m_internalAttributes = value;\n+    }\n+\n+    /**\n+     * Retrieves the extra data for the central directory.\n+     *\n+     * @return The CentralDirectoryExtra value\n+     * @since 1.1\n+     */\n+    public byte[] getCentralDirectoryExtra()\n+    {\n+        return ExtraFieldUtils.mergeCentralDirectoryData( getExtraFields() );\n+    }\n+\n+    /**\n+     * Override to make this class work in JDK 1.1 like a 1.2 class.\n+     *\n+     * @return The CompressedSize value\n+     * @since 1.2\n+     */\n+    public long getCompressedSize()\n+    {\n+        if( m_compressedSize != null )\n+        {\n+            // has been set explicitly and we are running in a 1.1 VM\n+            return m_compressedSize.longValue();\n+        }\n+        return super.getCompressedSize();\n+    }\n+\n+    /**\n+     * Retrieves the external file attributes.\n+     *\n+     * @return The ExternalAttributes value\n+     * @since 1.1\n+     */\n+    public long getExternalAttributes()\n+    {\n+        return m_externalAttributes;\n+    }\n+\n+    /**\n+     * Retrieves extra fields.\n+     *\n+     * @return The ExtraFields value\n+     * @since 1.1\n+     */\n+    public ZipExtraField[] getExtraFields()\n+    {\n+        final ZipExtraField[] result = new ZipExtraField[ m_extraFields.size() ];\n+        return (ZipExtraField[])m_extraFields.toArray( result );\n+    }\n+\n+    /**\n+     * Retrieves the internal file attributes.\n+     *\n+     * @return The InternalAttributes value\n+     * @since 1.1\n+     */\n+    public int getInternalAttributes()\n+    {\n+        return m_internalAttributes;\n+    }\n+\n+    /**\n+     * Retrieves the extra data for the local file data.\n+     *\n+     * @return The LocalFileDataExtra value\n+     * @since 1.1\n+     */\n+    public byte[] getLocalFileDataExtra()\n+    {\n+        byte[] extra = getExtra();\n+        return extra != null ? extra : new byte[ 0 ];\n+    }\n+\n+    /**\n+     * Adds an extra fields - replacing an already present extra field of the\n+     * same type.\n+     *\n+     * @param extraField The feature to be added to the ExtraField attribute\n+     * @since 1.1\n+     */\n+    public void addExtraField( final ZipExtraField extraField )\n+    {\n+        final ZipShort type = extraField.getHeaderID();\n+        boolean done = false;\n+        for( int i = 0; !done && i < m_extraFields.size(); i++ )\n+        {\n+            final ZipExtraField other = (ZipExtraField)m_extraFields.get( i );\n+            if( other.getHeaderID().equals( type ) )\n+            {\n+                m_extraFields.set( i, extraField );\n+                done = true;\n+            }\n+        }\n+        if( !done )\n+        {\n+            m_extraFields.add( extraField );\n+        }\n+        setExtra();\n+    }\n+\n+    /**\n+     * Overwrite clone\n+     *\n+     * @return Description of the Returned Value\n+     * @since 1.1\n+     */\n+    public Object clone()\n+    {\n+        ZipArchiveEntry entry = null;\n+        try\n+        {\n+            entry = new ZipArchiveEntry( (java.util.zip.ZipEntry)super.clone() );\n+        }\n+        catch( final Exception e )\n+        {\n+            // impossible as extra data is in correct format\n+            e.printStackTrace();\n+            return null;\n+        }\n+\n+        entry.setInternalAttributes( getInternalAttributes() );\n+        entry.setExternalAttributes( getExternalAttributes() );\n+        entry.setExtraFields( getExtraFields() );\n+        return entry;\n+    }\n+\n+    /**\n+     * Remove an extra fields.\n+     *\n+     * @param type Description of Parameter\n+     * @since 1.1\n+     */\n+    public void removeExtraField( final ZipShort type )\n+    {\n+        boolean done = false;\n+        for( int i = 0; !done && i < m_extraFields.size(); i++ )\n+        {\n+            if( ( (ZipExtraField)m_extraFields.get( i ) ).getHeaderID().equals( type ) )\n+            {\n+                m_extraFields.remove( i );\n+                done = true;\n+            }\n+        }\n+        if( !done )\n+        {\n+            throw new java.util.NoSuchElementException();\n+        }\n+        setExtra();\n+    }\n+\n+    /**\n+     * Unfortunately {@link java.util.zip.ZipOutputStream\n+     * java.util.zip.ZipOutputStream} seems to access the extra data directly,\n+     * so overriding getExtra doesn't help - we need to modify super's data\n+     * directly.\n+     *\n+     * @since 1.1\n+     */\n+    protected void setExtra()\n+    {\n+        super.setExtra( ExtraFieldUtils.mergeLocalFileDataData( getExtraFields() ) );\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveInputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.zip;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.zip.ZipInputStream;\n+\n+import org.apache.commons.compress.archivers.ArchiveEntry;\n+import org.apache.commons.compress.archivers.ArchiveInputStream;\n+\n+public class ZipArchiveInputStream extends ArchiveInputStream {\n+\n+\tprivate final ZipInputStream input;\n+\n+\tpublic ZipArchiveInputStream(InputStream inputStream) {\n+\t\tinput = new ZipInputStream(inputStream);\n+\t}\n+\n+    public ArchiveEntry getNextEntry() throws IOException {\n+    \tjava.util.zip.ZipEntry entry = input.getNextEntry();\n+    \tif(entry == null) {\n+    \t\treturn null;\n+    \t}\n+        return (ArchiveEntry)new ZipArchiveEntry(entry);\n+    }\n+\n+    public int read(byte[] b, int off, int len) throws IOException {\n+        return input.read(b, off, len);\n+    }\n+    \n+    public int read() throws IOException {\n+        return input.read();\n+    }\n+\n+    \n+    public static boolean matches( byte[] signature ) {\n+    \t// 4b50 0403 0014 0000\n+\n+    \tif (signature[0] != 0x50) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[1] != 0x4b) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[2] != 0x03) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[3] != 0x04) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[4] != 0x14) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[5] != 0x00) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[6] != 0x00) {\n+    \t\treturn false;\n+    \t}\n+    \tif (signature[7] != 0x00) {\n+    \t\treturn false;\n+    \t}\n+    \t\n+    \treturn true;\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveOutputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.zip;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.util.zip.ZipOutputStream;\n+\n+import org.apache.commons.compress.archivers.ArchiveEntry;\n+import org.apache.commons.compress.archivers.ArchiveOutputStream;\n+\n+public class ZipArchiveOutputStream extends ArchiveOutputStream {\n+\n+    private ZipOutputStream zipOut = null;\n+ \n+    public ZipArchiveOutputStream(OutputStream out) {\n+        this.zipOut = new ZipOutputStream(out);\n+    }\n+    \n+    public void putArchiveEntry(ArchiveEntry entry) throws IOException {\n+        zipOut.putNextEntry((ZipArchiveEntry) entry);\n+    }\n+\n+    public String getDefaultFileExtension() {\n+        return \"zip\";\n+    }\n+\n+    public byte[] getHeader() {\n+        // TODO Auto-generated method stub\n+        return null;\n+    }\n+\n+    public String getName() {\n+        return \"zip\";\n+    }\n+\n+    public void close() throws IOException {\n+        zipOut.close();\n+    }\n+\n+    public void write(byte[] buffer, int offset, int length) throws IOException {\n+        zipOut.write(buffer, offset, length);\n+    }\n+\n+    public void closeArchiveEntry() {\n+        // do nothing\n+    }\n+\n+\tpublic void write(int arg0) throws IOException {\n+\t\tthis.zipOut.write(arg0);\n+\t}\n+ \n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipEntry.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.zip;\n+\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+import java.util.ArrayList;\n+import java.util.zip.ZipException;\n+\n+/**\n+ * Extension that adds better handling of extra fields and provides access to\n+ * the internal and external file attributes.\n+ */\n+public class ZipEntry\n+    extends java.util.zip.ZipEntry\n+{\n+    /**\n+     * Helper for JDK 1.1\n+     *\n+     * @since 1.2\n+     */\n+    private static Method c_setCompressedSizeMethod;\n+\n+    /**\n+     * Helper for JDK 1.1\n+     *\n+     * @since 1.2\n+     */\n+    private static final Object c_lockReflection = new Object();\n+\n+    /**\n+     * Helper for JDK 1.1\n+     *\n+     * @since 1.2\n+     */\n+    private static boolean c_triedToGetMethod;\n+\n+    private final ArrayList m_extraFields = new ArrayList();\n+\n+    private int m_internalAttributes;\n+    private long m_externalAttributes;\n+\n+    /**\n+     * Helper for JDK 1.1 <-> 1.2 incompatibility.\n+     *\n+     * @since 1.2\n+     */\n+    private Long m_compressedSize;\n+\n+    /**\n+     * Creates a new zip entry with the specified name.\n+     *\n+     * @param name the name of entry\n+     * @since 1.1\n+     */\n+    public ZipEntry( final String name )\n+    {\n+        super( name );\n+    }\n+\n+    /**\n+     * Creates a new zip entry with fields taken from the specified zip entry.\n+     *\n+     * @param entry the JDK ZipEntry to adapt\n+     * @exception ZipException if can not create entry\n+     * @since 1.1\n+     */\n+    public ZipEntry( java.util.zip.ZipEntry entry )\n+        throws ZipException\n+    {\n+        /*\n+         * REVISIT: call super(entry) instead of this stuff in Ant2,\n+         * \"copy constructor\" has not been available in JDK 1.1\n+         */\n+        super( entry.getName() );\n+\n+        setComment( entry.getComment() );\n+        setMethod( entry.getMethod() );\n+        setTime( entry.getTime() );\n+\n+        final long size = entry.getSize();\n+        if( size > 0 )\n+        {\n+            setSize( size );\n+        }\n+\n+        final long cSize = entry.getCompressedSize();\n+        if( cSize > 0 )\n+        {\n+            setComprSize( cSize );\n+        }\n+\n+        final long crc = entry.getCrc();\n+        if( crc > 0 )\n+        {\n+            setCrc( crc );\n+        }\n+\n+        final byte[] extra = entry.getExtra();\n+        if( extra != null )\n+        {\n+            setExtraFields( ExtraFieldUtils.parse( extra ) );\n+        }\n+        else\n+        {\n+            // initializes extra data to an empty byte array\n+            setExtra();\n+        }\n+    }\n+\n+    /**\n+     * Creates a new zip entry with fields taken from the specified zip entry.\n+     *\n+     * @param entry the entry to adapt\n+     * @exception ZipException if can not create entry\n+     * @since 1.1\n+     */\n+    public ZipEntry( final ZipEntry entry )\n+        throws ZipException\n+    {\n+        this( (java.util.zip.ZipEntry)entry );\n+        setInternalAttributes( entry.getInternalAttributes() );\n+        setExternalAttributes( entry.getExternalAttributes() );\n+        setExtraFields( entry.getExtraFields() );\n+    }\n+\n+    /**\n+     * Try to get a handle to the setCompressedSize method.\n+     *\n+     * @since 1.2\n+     */\n+    private static void checkSCS()\n+    {\n+        if( !c_triedToGetMethod )\n+        {\n+            synchronized( c_lockReflection )\n+            {\n+                c_triedToGetMethod = true;\n+                try\n+                {\n+                    c_setCompressedSizeMethod =\n+                        java.util.zip.ZipEntry.class.getMethod( \"setCompressedSize\",\n+                                                                new Class[]{Long.TYPE} );\n+                }\n+                catch( NoSuchMethodException nse )\n+                {\n+                }\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Are we running JDK 1.2 or higher?\n+     *\n+     * @return Description of the Returned Value\n+     * @since 1.2\n+     */\n+    private static boolean haveSetCompressedSize()\n+    {\n+        checkSCS();\n+        return c_setCompressedSizeMethod != null;\n+    }\n+\n+    /**\n+     * Invoke setCompressedSize via reflection.\n+     *\n+     * @param entry Description of Parameter\n+     * @param size Description of Parameter\n+     * @since 1.2\n+     */\n+    private static void performSetCompressedSize( final ZipEntry entry,\n+                                                  final long size )\n+    {\n+        final Long[] s = {new Long( size )};\n+        try\n+        {\n+            c_setCompressedSizeMethod.invoke( entry, s );\n+        }\n+        catch( final InvocationTargetException ite )\n+        {\n+            final Throwable nested = ite.getTargetException();\n+            final String message = \"Exception setting the compressed size \" +\n+                \"of \" + entry + \": \" + nested.getMessage();\n+            throw new RuntimeException( message );\n+        }\n+        catch( final Throwable t )\n+        {\n+            final String message = \"Exception setting the compressed size \" +\n+                \"of \" + entry + \": \" + t.getMessage();\n+            throw new RuntimeException( message );\n+        }\n+    }\n+\n+    /**\n+     * Make this class work in JDK 1.1 like a 1.2 class. <p>\n+     *\n+     * This either stores the size for later usage or invokes setCompressedSize\n+     * via reflection.</p>\n+     *\n+     * @param size The new ComprSize value\n+     * @since 1.2\n+     */\n+    public void setComprSize( final long size )\n+    {\n+        if( haveSetCompressedSize() )\n+        {\n+            performSetCompressedSize( this, size );\n+        }\n+        else\n+        {\n+            m_compressedSize = new Long( size );\n+        }\n+    }\n+\n+    /**\n+     * Sets the external file attributes.\n+     *\n+     * @param externalAttributes The new ExternalAttributes value\n+     * @since 1.1\n+     */\n+    public void setExternalAttributes( final long externalAttributes )\n+    {\n+        m_externalAttributes = externalAttributes;\n+    }\n+\n+    /**\n+     * Throws an Exception if extra data cannot be parsed into extra fields.\n+     *\n+     * @param extra The new Extra value\n+     * @throws RuntimeException if fail to set extra data\n+     * @since 1.1\n+     */\n+    public void setExtra( final byte[] extra )\n+        throws RuntimeException\n+    {\n+        try\n+        {\n+            setExtraFields( ExtraFieldUtils.parse( extra ) );\n+        }\n+        catch( final Exception e )\n+        {\n+            throw new RuntimeException( e.getMessage() );\n+        }\n+    }\n+\n+    /**\n+     * Replaces all currently attached extra fields with the new array.\n+     *\n+     * @param fields The new ExtraFields value\n+     * @since 1.1\n+     */\n+    public void setExtraFields( final ZipExtraField[] fields )\n+    {\n+        m_extraFields.clear();\n+        for( int i = 0; i < fields.length; i++ )\n+        {\n+            m_extraFields.add( fields[ i ] );\n+        }\n+        setExtra();\n+    }\n+\n+    /**\n+     * Sets the internal file attributes.\n+     *\n+     * @param value The new InternalAttributes value\n+     * @since 1.1\n+     */\n+    public void setInternalAttributes( final int value )\n+    {\n+        m_internalAttributes = value;\n+    }\n+\n+    /**\n+     * Retrieves the extra data for the central directory.\n+     *\n+     * @return The CentralDirectoryExtra value\n+     * @since 1.1\n+     */\n+    public byte[] getCentralDirectoryExtra()\n+    {\n+        return ExtraFieldUtils.mergeCentralDirectoryData( getExtraFields() );\n+    }\n+\n+    /**\n+     * Override to make this class work in JDK 1.1 like a 1.2 class.\n+     *\n+     * @return The CompressedSize value\n+     * @since 1.2\n+     */\n+    public long getCompressedSize()\n+    {\n+        if( m_compressedSize != null )\n+        {\n+            // has been set explicitly and we are running in a 1.1 VM\n+            return m_compressedSize.longValue();\n+        }\n+        return super.getCompressedSize();\n+    }\n+\n+    /**\n+     * Retrieves the external file attributes.\n+     *\n+     * @return The ExternalAttributes value\n+     * @since 1.1\n+     */\n+    public long getExternalAttributes()\n+    {\n+        return m_externalAttributes;\n+    }\n+\n+    /**\n+     * Retrieves extra fields.\n+     *\n+     * @return The ExtraFields value\n+     * @since 1.1\n+     */\n+    public ZipExtraField[] getExtraFields()\n+    {\n+        final ZipExtraField[] result = new ZipExtraField[ m_extraFields.size() ];\n+        return (ZipExtraField[])m_extraFields.toArray( result );\n+    }\n+\n+    /**\n+     * Retrieves the internal file attributes.\n+     *\n+     * @return The InternalAttributes value\n+     * @since 1.1\n+     */\n+    public int getInternalAttributes()\n+    {\n+        return m_internalAttributes;\n+    }\n+\n+    /**\n+     * Retrieves the extra data for the local file data.\n+     *\n+     * @return The LocalFileDataExtra value\n+     * @since 1.1\n+     */\n+    public byte[] getLocalFileDataExtra()\n+    {\n+        byte[] extra = getExtra();\n+        return extra != null ? extra : new byte[ 0 ];\n+    }\n+\n+    /**\n+     * Adds an extra fields - replacing an already present extra field of the\n+     * same type.\n+     *\n+     * @param extraField The feature to be added to the ExtraField attribute\n+     * @since 1.1\n+     */\n+    public void addExtraField( final ZipExtraField extraField )\n+    {\n+        final ZipShort type = extraField.getHeaderID();\n+        boolean done = false;\n+        for( int i = 0; !done && i < m_extraFields.size(); i++ )\n+        {\n+            final ZipExtraField other = (ZipExtraField)m_extraFields.get( i );\n+            if( other.getHeaderID().equals( type ) )\n+            {\n+                m_extraFields.set( i, extraField );\n+                done = true;\n+            }\n+        }\n+        if( !done )\n+        {\n+            m_extraFields.add( extraField );\n+        }\n+        setExtra();\n+    }\n+\n+    /**\n+     * Overwrite clone\n+     *\n+     * @return Description of the Returned Value\n+     * @since 1.1\n+     */\n+    public Object clone()\n+    {\n+        ZipEntry entry = null;\n+        try\n+        {\n+            entry = new ZipEntry( (java.util.zip.ZipEntry)super.clone() );\n+        }\n+        catch( final Exception e )\n+        {\n+            // impossible as extra data is in correct format\n+            e.printStackTrace();\n+            return null;\n+        }\n+\n+        entry.setInternalAttributes( getInternalAttributes() );\n+        entry.setExternalAttributes( getExternalAttributes() );\n+        entry.setExtraFields( getExtraFields() );\n+        return entry;\n+    }\n+\n+    /**\n+     * Remove an extra fields.\n+     *\n+     * @param type Description of Parameter\n+     * @since 1.1\n+     */\n+    public void removeExtraField( final ZipShort type )\n+    {\n+        boolean done = false;\n+        for( int i = 0; !done && i < m_extraFields.size(); i++ )\n+        {\n+            if( ( (ZipExtraField)m_extraFields.get( i ) ).getHeaderID().equals( type ) )\n+            {\n+                m_extraFields.remove( i );\n+                done = true;\n+            }\n+        }\n+        if( !done )\n+        {\n+            throw new java.util.NoSuchElementException();\n+        }\n+        setExtra();\n+    }\n+\n+    /**\n+     * Unfortunately {@link java.util.zip.ZipOutputStream\n+     * java.util.zip.ZipOutputStream} seems to access the extra data directly,\n+     * so overriding getExtra doesn't help - we need to modify super's data\n+     * directly.\n+     *\n+     * @since 1.1\n+     */\n+    protected void setExtra()\n+    {\n+        super.setExtra( ExtraFieldUtils.mergeLocalFileDataData( getExtraFields() ) );\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipExtraField.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.zip;\n+\n+import java.util.zip.ZipException;\n+\n+/**\n+ * General format of extra field data. <p>\n+ *\n+ * Extra fields usually appear twice per file, once in the local file data and\n+ * once in the central directory. Usually they are the same, but they don't have\n+ * to be. {@link java.util.zip.ZipOutputStream java.util.zip.ZipOutputStream}\n+ * will only use the local file data in both places.</p>\n+ */\n+public interface ZipExtraField\n+{\n+    /**\n+     * The Header-ID.\n+     *\n+     * @return The HeaderId value\n+     * @since 1.1\n+     */\n+    ZipShort getHeaderID();\n+\n+    /**\n+     * Length of the extra field in the local file data - without Header-ID or\n+     * length specifier.\n+     *\n+     * @return The LocalFileDataLength value\n+     * @since 1.1\n+     */\n+    ZipShort getLocalFileDataLength();\n+\n+    /**\n+     * Length of the extra field in the central directory - without Header-ID or\n+     * length specifier.\n+     *\n+     * @return The CentralDirectoryLength value\n+     * @since 1.1\n+     */\n+    ZipShort getCentralDirectoryLength();\n+\n+    /**\n+     * The actual data to put into local file data - without Header-ID or length\n+     * specifier.\n+     *\n+     * @return The LocalFileDataData value\n+     * @since 1.1\n+     */\n+    byte[] getLocalFileDataData();\n+\n+    /**\n+     * The actual data to put central directory - without Header-ID or length\n+     * specifier.\n+     *\n+     * @return The CentralDirectoryData value\n+     * @since 1.1\n+     */\n+    byte[] getCentralDirectoryData();\n+\n+    /**\n+     * Populate data from this array as if it was in local file data.\n+     *\n+     * @param buffer the buffer to read data from\n+     * @param offset offset into buffer to read data\n+     * @param length the length of data\n+     * @exception ZipException on error\n+     * @since 1.1\n+     */\n+    void parseFromLocalFileData( byte[] buffer, int offset, int length )\n+        throws ZipException;\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipLong.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.zip;\n+\n+/**\n+ * Utility class that represents a four byte integer with conversion rules for\n+ * the big endian byte order of ZIP files.\n+ */\n+public final class ZipLong implements Cloneable\n+{\n+    private long m_value;\n+\n+    /**\n+     * Create instance from a number.\n+     *\n+     * @param value the value\n+     * @since 1.1\n+     */\n+    public ZipLong( final long value )\n+    {\n+        m_value = value;\n+    }\n+\n+    /**\n+     * Create instance from bytes.\n+     *\n+     * @param buffer the buffer to read data from\n+     * @since 1.1\n+     */\n+    public ZipLong( final byte[] buffer )\n+    {\n+        this( buffer, 0 );\n+    }\n+\n+    /**\n+     * Create instance from the four bytes starting at offset.\n+     *\n+     * @param buffer buffer to read data from\n+     * @param offset offset into buffer\n+     * @since 1.1\n+     */\n+    public ZipLong( final byte[] buffer, final int offset )\n+    {\n+        m_value = ( buffer[ offset + 3 ] << 24 ) & 0xFF000000l;\n+        m_value += ( buffer[ offset + 2 ] << 16 ) & 0xFF0000;\n+        m_value += ( buffer[ offset + 1 ] << 8 ) & 0xFF00;\n+        m_value += ( buffer[ offset ] & 0xFF );\n+    }\n+\n+    /**\n+     * Get value as two bytes in big endian byte order.\n+     *\n+     * @return The value as bytes\n+     * @since 1.1\n+     */\n+    public byte[] getBytes()\n+    {\n+        byte[] result = new byte[ 4 ];\n+        result[ 0 ] = (byte)( ( m_value & 0xFF ) );\n+        result[ 1 ] = (byte)( ( m_value & 0xFF00 ) >> 8 );\n+        result[ 2 ] = (byte)( ( m_value & 0xFF0000 ) >> 16 );\n+        result[ 3 ] = (byte)( ( m_value & 0xFF000000l ) >> 24 );\n+        return result;\n+    }\n+\n+    /**\n+     * Get value as Java int.\n+     *\n+     * @return The value\n+     * @since 1.1\n+     */\n+    public long getValue()\n+    {\n+        return m_value;\n+    }\n+\n+    /**\n+     * Override to make two instances with same value equal.\n+     *\n+     * @param o the object to compare against\n+     * @return true if equyal, false otherwise\n+     * @since 1.1\n+     */\n+    public boolean equals( final Object o )\n+    {\n+        if( o == null || !( o instanceof ZipLong ) )\n+        {\n+            return false;\n+        }\n+        return m_value == ( (ZipLong)o ).getValue();\n+    }\n+\n+    /**\n+     * Override to make two instances with same value equal.\n+     *\n+     * @return the hashcode\n+     * @since 1.1\n+     */\n+    public int hashCode()\n+    {\n+        return (int)m_value;\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipOutputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.zip;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.io.UnsupportedEncodingException;\n+import java.util.ArrayList;\n+import java.util.Calendar;\n+import java.util.Date;\n+import java.util.Hashtable;\n+import java.util.zip.CRC32;\n+import java.util.zip.Deflater;\n+import java.util.zip.DeflaterOutputStream;\n+import java.util.zip.ZipException;\n+\n+/**\n+ * Reimplementation of {@link java.util.zip.ZipOutputStream\n+ * java.util.zip.ZipOutputStream} that does handle the extended functionality of\n+ * this package, especially internal/external file attributes and extra fields\n+ * with different layouts for local file data and central directory entries. <p>\n+ *\n+ * This implementation will use a Data Descriptor to store size and CRC\n+ * information for DEFLATED entries, this means, you don't need to calculate\n+ * them yourself. Unfortunately this is not possible for the STORED method, here\n+ * setting the CRC and uncompressed size information is required before {@link\n+ * #putNextEntry putNextEntry} will be called.</p>\n+ */\n+public class ZipOutputStream\n+    extends DeflaterOutputStream\n+{\n+    /**\n+     * Helper, a 0 as ZipShort.\n+     *\n+     * @since 1.1\n+     */\n+    private static final byte[] ZERO = {0, 0};\n+\n+    /**\n+     * Helper, a 0 as ZipLong.\n+     *\n+     * @since 1.1\n+     */\n+    private static final byte[] LZERO = {0, 0, 0, 0};\n+\n+    /**\n+     * Compression method for deflated entries.\n+     *\n+     * @since 1.1\n+     */\n+    public static final int DEFLATED = ZipEntry.DEFLATED;\n+\n+    /**\n+     * Compression method for deflated entries.\n+     *\n+     * @since 1.1\n+     */\n+    public static final int STORED = ZipEntry.STORED;\n+\n+    /*\n+     * Various ZIP constants\n+     */\n+    /**\n+     * local file header signature\n+     *\n+     * @since 1.1\n+     */\n+    protected static final ZipLong LFH_SIG = new ZipLong( 0X04034B50L );\n+    /**\n+     * data descriptor signature\n+     *\n+     * @since 1.1\n+     */\n+    protected static final ZipLong DD_SIG = new ZipLong( 0X08074B50L );\n+    /**\n+     * central file header signature\n+     *\n+     * @since 1.1\n+     */\n+    protected static final ZipLong CFH_SIG = new ZipLong( 0X02014B50L );\n+    /**\n+     * end of central dir signature\n+     *\n+     * @since 1.1\n+     */\n+    protected static final ZipLong EOCD_SIG = new ZipLong( 0X06054B50L );\n+\n+    /**\n+     * Smallest date/time ZIP can handle.\n+     *\n+     * @since 1.1\n+     */\n+    private static final ZipLong DOS_TIME_MIN = new ZipLong( 0x00002100L );\n+\n+    /**\n+     * The file comment.\n+     *\n+     * @since 1.1\n+     */\n+    private String m_comment = \"\";\n+\n+    /**\n+     * Compression level for next entry.\n+     *\n+     * @since 1.1\n+     */\n+    private int m_level = Deflater.DEFAULT_COMPRESSION;\n+\n+    /**\n+     * Default compression method for next entry.\n+     *\n+     * @since 1.1\n+     */\n+    private int m_method = DEFLATED;\n+\n+    /**\n+     * List of ZipEntries written so far.\n+     *\n+     * @since 1.1\n+     */\n+    private final ArrayList m_entries = new ArrayList();\n+\n+    /**\n+     * CRC instance to avoid parsing DEFLATED data twice.\n+     *\n+     * @since 1.1\n+     */\n+    private final CRC32 m_crc = new CRC32();\n+\n+    /**\n+     * Count the bytes written to out.\n+     *\n+     * @since 1.1\n+     */\n+    private long m_written;\n+\n+    /**\n+     * Data for current entry started here.\n+     *\n+     * @since 1.1\n+     */\n+    private long m_dataStart;\n+\n+    /**\n+     * Start of central directory.\n+     *\n+     * @since 1.1\n+     */\n+    private ZipLong m_cdOffset = new ZipLong( 0 );\n+\n+    /**\n+     * Length of central directory.\n+     *\n+     * @since 1.1\n+     */\n+    private ZipLong m_cdLength = new ZipLong( 0 );\n+\n+    /**\n+     * Holds the offsets of the LFH starts for each entry\n+     *\n+     * @since 1.1\n+     */\n+    private final Hashtable m_offsets = new Hashtable();\n+\n+    /**\n+     * The encoding to use for filenames and the file comment. <p>\n+     *\n+     * For a list of possible values see <a\n+     * href=\"http://java.sun.com/products/jdk/1.2/docs/guide/internat/encoding.doc.html\">\n+     * http://java.sun.com/products/jdk/1.2/docs/guide/internat/encoding.doc.html\n+     * </a>. Defaults to the platform's default character encoding.</p>\n+     *\n+     * @since 1.3\n+     */\n+    private String m_encoding;\n+\n+    /**\n+     * Current entry.\n+     *\n+     * @since 1.1\n+     */\n+    private ZipArchiveEntry m_entry;\n+\n+    /**\n+     * Creates a new ZIP OutputStream filtering the underlying stream.\n+     *\n+     * @param output the output stream to write to\n+     * @since 1.1\n+     */\n+    public ZipOutputStream( final OutputStream output )\n+    {\n+        super( output, new Deflater( Deflater.DEFAULT_COMPRESSION, true ) );\n+    }\n+\n+    /**\n+     * Convert a Date object to a DOS date/time field. <p>\n+     *\n+     * Stolen from InfoZip's <code>fileio.c</code></p>\n+     *\n+     * @param time Description of Parameter\n+     * @return Description of the Returned Value\n+     * @since 1.1\n+     */\n+    protected static ZipLong toDosTime( Date time )\n+    {\n+        Calendar cal = Calendar.getInstance();\n+        cal.setTime( time );\n+        int year = cal.get(Calendar.YEAR);\n+        int month = cal.get(Calendar.MONTH) + 1;\n+        if( year < 1980 )\n+        {\n+            return DOS_TIME_MIN;\n+        }\n+        long value = ( ( year - 1980 ) << 25 )\n+            | ( month << 21 )\n+            | ( cal.get(Calendar.DAY_OF_MONTH) << 16 )\n+            | ( cal.get(Calendar.HOUR_OF_DAY) << 11 )\n+            | ( cal.get(Calendar.MINUTE) << 5 )\n+            | ( cal.get(Calendar.SECOND) >> 1 );\n+\n+        byte[] result = new byte[ 4 ];\n+        result[ 0 ] = (byte)( ( value & 0xFF ) );\n+        result[ 1 ] = (byte)( ( value & 0xFF00 ) >> 8 );\n+        result[ 2 ] = (byte)( ( value & 0xFF0000 ) >> 16 );\n+        result[ 3 ] = (byte)( ( value & 0xFF000000l ) >> 24 );\n+        return new ZipLong( result );\n+    }\n+\n+    /**\n+     * Set the file comment.\n+     *\n+     * @param comment The new Comment value\n+     * @since 1.1\n+     */\n+    public void setComment( String comment )\n+    {\n+        m_comment = comment;\n+    }\n+\n+    /**\n+     * The encoding to use for filenames and the file comment. <p>\n+     *\n+     * For a list of possible values see <a\n+     * href=\"http://java.sun.com/products/jdk/1.2/docs/guide/internat/encoding.doc.html\">\n+     * http://java.sun.com/products/jdk/1.2/docs/guide/internat/encoding.doc.html\n+     * </a>. Defaults to the platform's default character encoding.</p>\n+     *\n+     * @param encoding The new Encoding value\n+     * @since 1.3\n+     */\n+    public void setEncoding( String encoding )\n+    {\n+        m_encoding = encoding;\n+    }\n+\n+    /**\n+     * Sets the compression level for subsequent entries. <p>\n+     *\n+     * Default is Deflater.DEFAULT_COMPRESSION.</p>\n+     *\n+     * @param level The new Level value\n+     * @since 1.1\n+     */\n+    public void setLevel( int level )\n+    {\n+        m_level = level;\n+    }\n+\n+    /**\n+     * Sets the default compression method for subsequent entries. <p>\n+     *\n+     * Default is DEFLATED.</p>\n+     *\n+     * @param method The new Method value\n+     * @since 1.1\n+     */\n+    public void setMethod( final int method )\n+    {\n+        m_method = method;\n+    }\n+\n+    /**\n+     * The encoding to use for filenames and the file comment.\n+     *\n+     * @return null if using the platform's default character encoding.\n+     * @since 1.3\n+     */\n+    public String getEncoding()\n+    {\n+        return m_encoding;\n+    }\n+\n+    /**\n+     * Writes all necessary data for this entry.\n+     *\n+     * @throws IOException if an IO failure causes operation to fail\n+     * @since 1.1\n+     */\n+    public void closeEntry()\n+        throws IOException\n+    {\n+        if( m_entry == null )\n+        {\n+            return;\n+        }\n+\n+        long realCrc = m_crc.getValue();\n+        m_crc.reset();\n+\n+        if( m_entry.getMethod() == DEFLATED )\n+        {\n+            def.finish();\n+            while( !def.finished() )\n+            {\n+                deflate();\n+            }\n+\n+            m_entry.setSize( def.getTotalIn() );\n+            m_entry.setComprSize( def.getTotalOut() );\n+            m_entry.setCrc( realCrc );\n+\n+            def.reset();\n+\n+            m_written += m_entry.getCompressedSize();\n+        }\n+        else\n+        {\n+            if( m_entry.getCrc() != realCrc )\n+            {\n+                throw new ZipException( \"bad CRC checksum for entry \"\n+                                        + m_entry.getName() + \": \"\n+                                        + Long.toHexString( m_entry.getCrc() )\n+                                        + \" instead of \"\n+                                        + Long.toHexString( realCrc ) );\n+            }\n+\n+            if( m_entry.getSize() != m_written - m_dataStart )\n+            {\n+                throw new ZipException( \"bad size for entry \"\n+                                        + m_entry.getName() + \": \"\n+                                        + m_entry.getSize()\n+                                        + \" instead of \"\n+                                        + ( m_written - m_dataStart ) );\n+            }\n+\n+        }\n+\n+        writeDataDescriptor( m_entry );\n+        m_entry = null;\n+    }\n+\n+    /*\n+     * Found out by experiment, that DeflaterOutputStream.close()\n+     * will call finish() - so we don't need to override close\n+     * ourselves.\n+     */\n+    /**\n+     * Finishs writing the contents and closes this as well as the underlying\n+     * stream.\n+     *\n+     * @throws IOException if an IO failure causes operation to fail\n+     * @since 1.1\n+     */\n+    public void finish()\n+        throws IOException\n+    {\n+        closeEntry();\n+        m_cdOffset = new ZipLong( m_written );\n+        final int size = m_entries.size();\n+        for( int i = 0; i < size; i++ )\n+        {\n+            final ZipArchiveEntry entry = (ZipArchiveEntry)m_entries.get( i );\n+            writeCentralFileHeader( entry );\n+        }\n+        m_cdLength = new ZipLong( m_written - m_cdOffset.getValue() );\n+        writeCentralDirectoryEnd();\n+        m_offsets.clear();\n+        m_entries.clear();\n+    }\n+\n+    /**\n+     * Begin writing next entry.\n+     *\n+     * @param entry the entry\n+     * @throws IOException if an IO failure causes operation to fail\n+     * @since 1.1\n+     */\n+    public void putNextEntry( final ZipArchiveEntry entry )\n+        throws IOException\n+    {\n+        closeEntry();\n+\n+        m_entry = entry;\n+        m_entries.add( m_entry );\n+\n+        if( m_entry.getMethod() == -1 )\n+        {// not specified\n+            m_entry.setMethod( m_method );\n+        }\n+\n+        if( m_entry.getTime() == -1 )\n+        {// not specified\n+            m_entry.setTime( System.currentTimeMillis() );\n+        }\n+\n+        if( m_entry.getMethod() == STORED )\n+        {\n+            if( m_entry.getSize() == -1 )\n+            {\n+                throw new ZipException( \"uncompressed size is required for STORED method\" );\n+            }\n+            if( m_entry.getCrc() == -1 )\n+            {\n+                throw new ZipException( \"crc checksum is required for STORED method\" );\n+            }\n+            m_entry.setComprSize( m_entry.getSize() );\n+        }\n+        else\n+        {\n+            def.setLevel( m_level );\n+        }\n+        writeLocalFileHeader( m_entry );\n+    }\n+\n+    /**\n+     * Writes bytes to ZIP entry. <p>\n+     *\n+     * Override is necessary to support STORED entries, as well as calculationg\n+     * CRC automatically for DEFLATED entries.</p>\n+     *\n+     * @param buffer the buffer to write to\n+     * @param offset the offset to write to\n+     * @param length the length of data to write\n+     * @exception IOException if an IO error causes operation to fail\n+     */\n+    public void write( final byte[] buffer,\n+                       final int offset,\n+                       final int length )\n+        throws IOException\n+    {\n+        if( m_entry.getMethod() == DEFLATED )\n+        {\n+            super.write( buffer, offset, length );\n+        }\n+        else\n+        {\n+            out.write( buffer, offset, length );\n+            m_written += length;\n+        }\n+        m_crc.update( buffer, offset, length );\n+    }\n+\n+    /**\n+     * Retrieve the bytes for the given String in the encoding set for this\n+     * Stream.\n+     *\n+     * @param name the name to decode\n+     * @return the bytes for string\n+     * @exception ZipException if fail to retrieve bytes for specified string\n+     * @since 1.3\n+     */\n+    protected byte[] getBytes( String name )\n+        throws ZipException\n+    {\n+        if( m_encoding == null )\n+        {\n+            return name.getBytes();\n+        }\n+        else\n+        {\n+            try\n+            {\n+                return name.getBytes( m_encoding );\n+            }\n+            catch( UnsupportedEncodingException uee )\n+            {\n+                throw new ZipException( uee.getMessage() );\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Writes the &quot;End of central dir record&quot;\n+     *\n+     * @exception IOException when an IO erro causes operation to fail\n+     * @since 1.1\n+     */\n+    protected void writeCentralDirectoryEnd()\n+        throws IOException\n+    {\n+        out.write( EOCD_SIG.getBytes() );\n+\n+        // disk numbers\n+        out.write( ZERO );\n+        out.write( ZERO );\n+\n+        // number of entries\n+        byte[] num = ( new ZipShort( m_entries.size() ) ).getBytes();\n+        out.write( num );\n+        out.write( num );\n+\n+        // length and location of CD\n+        out.write( m_cdLength.getBytes() );\n+        out.write( m_cdOffset.getBytes() );\n+\n+        // ZIP file comment\n+        byte[] data = getBytes( m_comment );\n+        out.write( ( new ZipShort( data.length ) ).getBytes() );\n+        out.write( data );\n+    }\n+\n+    /**\n+     * Writes the central file header entry\n+     *\n+     * @param entry the zip entry\n+     * @throws IOException when an IO error causes operation to fail\n+     * @since 1.1\n+     */\n+    protected void writeCentralFileHeader( final ZipArchiveEntry entry )\n+        throws IOException\n+    {\n+        out.write( CFH_SIG.getBytes() );\n+        m_written += 4;\n+\n+        // version made by\n+        out.write( ( new ZipShort( 20 ) ).getBytes() );\n+        m_written += 2;\n+\n+        // version needed to extract\n+        // general purpose bit flag\n+        if( entry.getMethod() == DEFLATED )\n+        {\n+            // requires version 2 as we are going to store length info\n+            // in the data descriptor\n+            out.write( ( new ZipShort( 20 ) ).getBytes() );\n+\n+            // bit3 set to signal, we use a data descriptor\n+            out.write( ( new ZipShort( 8 ) ).getBytes() );\n+        }\n+        else\n+        {\n+            out.write( ( new ZipShort( 10 ) ).getBytes() );\n+            out.write( ZERO );\n+        }\n+        m_written += 4;\n+\n+        // compression method\n+        out.write( ( new ZipShort( entry.getMethod() ) ).getBytes() );\n+        m_written += 2;\n+\n+        // last mod. time and date\n+        out.write( toDosTime( new Date( entry.getTime() ) ).getBytes() );\n+        m_written += 4;\n+\n+        // CRC\n+        // compressed length\n+        // uncompressed length\n+        out.write( ( new ZipLong( entry.getCrc() ) ).getBytes() );\n+        out.write( ( new ZipLong( entry.getCompressedSize() ) ).getBytes() );\n+        out.write( ( new ZipLong( entry.getSize() ) ).getBytes() );\n+        m_written += 12;\n+\n+        // file name length\n+        byte[] name = getBytes( entry.getName() );\n+        out.write( ( new ZipShort( name.length ) ).getBytes() );\n+        m_written += 2;\n+\n+        // extra field length\n+        byte[] extra = entry.getCentralDirectoryExtra();\n+        out.write( ( new ZipShort( extra.length ) ).getBytes() );\n+        m_written += 2;\n+\n+        // file comment length\n+        String comm = entry.getComment();\n+        if( comm == null )\n+        {\n+            comm = \"\";\n+        }\n+        byte[] comment = getBytes( comm );\n+        out.write( ( new ZipShort( comment.length ) ).getBytes() );\n+        m_written += 2;\n+\n+        // disk number start\n+        out.write( ZERO );\n+        m_written += 2;\n+\n+        // internal file attributes\n+        out.write( ( new ZipShort( entry.getInternalAttributes() ) ).getBytes() );\n+        m_written += 2;\n+\n+        // external file attributes\n+        out.write( ( new ZipLong( entry.getExternalAttributes() ) ).getBytes() );\n+        m_written += 4;\n+\n+        // relative offset of LFH\n+        out.write( ( (ZipLong)m_offsets.get( entry ) ).getBytes() );\n+        m_written += 4;\n+\n+        // file name\n+        out.write( name );\n+        m_written += name.length;\n+\n+        // extra field\n+        out.write( extra );\n+        m_written += extra.length;\n+\n+        // file comment\n+        out.write( comment );\n+        m_written += comment.length;\n+    }\n+\n+    /**\n+     * Writes the data descriptor entry\n+     *\n+     * @param ze Description of Parameter\n+     * @throws IOException if an IO failure causes operation to fail\n+     * @since 1.1\n+     */\n+    protected void writeDataDescriptor( ZipArchiveEntry ze )\n+        throws IOException\n+    {\n+        if( ze.getMethod() != DEFLATED )\n+        {\n+            return;\n+        }\n+        out.write( DD_SIG.getBytes() );\n+        out.write( ( new ZipLong( m_entry.getCrc() ) ).getBytes() );\n+        out.write( ( new ZipLong( m_entry.getCompressedSize() ) ).getBytes() );\n+        out.write( ( new ZipLong( m_entry.getSize() ) ).getBytes() );\n+        m_written += 16;\n+    }\n+\n+    /**\n+     * Writes the local file header entry\n+     *\n+     * @param entry the zip entry\n+     * @exception IOException when an IO error causes operation to fail\n+     * @since 1.1\n+     */\n+    protected void writeLocalFileHeader( final ZipArchiveEntry entry )\n+        throws IOException\n+    {\n+        m_offsets.put( entry, new ZipLong( m_written ) );\n+\n+        out.write( LFH_SIG.getBytes() );\n+        m_written += 4;\n+\n+        // version needed to extract\n+        // general purpose bit flag\n+        if( entry.getMethod() == DEFLATED )\n+        {\n+            // requires version 2 as we are going to store length info\n+            // in the data descriptor\n+            out.write( ( new ZipShort( 20 ) ).getBytes() );\n+\n+            // bit3 set to signal, we use a data descriptor\n+            out.write( ( new ZipShort( 8 ) ).getBytes() );\n+        }\n+        else\n+        {\n+            out.write( ( new ZipShort( 10 ) ).getBytes() );\n+            out.write( ZERO );\n+        }\n+        m_written += 4;\n+\n+        // compression method\n+        out.write( ( new ZipShort( entry.getMethod() ) ).getBytes() );\n+        m_written += 2;\n+\n+        // last mod. time and date\n+        out.write( toDosTime( new Date( entry.getTime() ) ).getBytes() );\n+        m_written += 4;\n+\n+        // CRC\n+        // compressed length\n+        // uncompressed length\n+        if( entry.getMethod() == DEFLATED )\n+        {\n+            out.write( LZERO );\n+            out.write( LZERO );\n+            out.write( LZERO );\n+        }\n+        else\n+        {\n+            out.write( ( new ZipLong( entry.getCrc() ) ).getBytes() );\n+            out.write( ( new ZipLong( entry.getSize() ) ).getBytes() );\n+            out.write( ( new ZipLong( entry.getSize() ) ).getBytes() );\n+        }\n+        m_written += 12;\n+\n+        // file name length\n+        byte[] name = getBytes( entry.getName() );\n+        out.write( ( new ZipShort( name.length ) ).getBytes() );\n+        m_written += 2;\n+\n+        // extra field length\n+        byte[] extra = entry.getLocalFileDataExtra();\n+        out.write( ( new ZipShort( extra.length ) ).getBytes() );\n+        m_written += 2;\n+\n+        // file name\n+        out.write( name );\n+        m_written += name.length;\n+\n+        // extra field\n+        out.write( extra );\n+        m_written += extra.length;\n+\n+        m_dataStart = m_written;\n+    }\n+\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipShort.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.zip;\n+\n+/**\n+ * Utility class that represents a two byte integer with conversion rules for\n+ * the big endian byte order of ZIP files.\n+ */\n+public final class ZipShort implements Cloneable\n+{\n+    private int m_value;\n+\n+    /**\n+     * Create instance from a number.\n+     *\n+     * @param value Description of Parameter\n+     * @since 1.1\n+     */\n+    public ZipShort( int value )\n+    {\n+        this.m_value = value;\n+    }\n+\n+    /**\n+     * Create instance from bytes.\n+     *\n+     * @param bytes Description of Parameter\n+     * @since 1.1\n+     */\n+    public ZipShort( byte[] bytes )\n+    {\n+        this( bytes, 0 );\n+    }\n+\n+    /**\n+     * Create instance from the two bytes starting at offset.\n+     *\n+     * @param bytes Description of Parameter\n+     * @param offset Description of Parameter\n+     * @since 1.1\n+     */\n+    public ZipShort( byte[] bytes, int offset )\n+    {\n+        m_value = ( bytes[ offset + 1 ] << 8 ) & 0xFF00;\n+        m_value += ( bytes[ offset ] & 0xFF );\n+    }\n+\n+    /**\n+     * Get value as two bytes in big endian byte order.\n+     *\n+     * @return The Bytes value\n+     * @since 1.1\n+     */\n+    public byte[] getBytes()\n+    {\n+        byte[] result = new byte[ 2 ];\n+        result[ 0 ] = (byte)( m_value & 0xFF );\n+        result[ 1 ] = (byte)( ( m_value & 0xFF00 ) >> 8 );\n+        return result;\n+    }\n+\n+    /**\n+     * Get value as Java int.\n+     *\n+     * @return The Value value\n+     * @since 1.1\n+     */\n+    public int getValue()\n+    {\n+        return m_value;\n+    }\n+\n+    /**\n+     * Override to make two instances with same value equal.\n+     *\n+     * @param o Description of Parameter\n+     * @return Description of the Returned Value\n+     * @since 1.1\n+     */\n+    public boolean equals( Object o )\n+    {\n+        if( o == null || !( o instanceof ZipShort ) )\n+        {\n+            return false;\n+        }\n+        return m_value == ( (ZipShort)o ).getValue();\n+    }\n+\n+    /**\n+     * Override to make two instances with same value equal.\n+     *\n+     * @return Description of the Returned Value\n+     * @since 1.1\n+     */\n+    public int hashCode()\n+    {\n+        return m_value;\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/changes/Change.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.changes;\n+\n+\n+interface Change {\n+\t// public void perform(ArchiveInputStream input);\n+\tpublic int type();\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/changes/ChangeSet.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.changes;\n+\n+import java.io.InputStream;\n+import java.util.LinkedHashSet;\n+import java.util.Set;\n+\n+import org.apache.commons.compress.archivers.ArchiveEntry;\n+\n+\n+public final class ChangeSet {\n+\n+\tprivate final Set changes = new LinkedHashSet();\n+\t\n+\tpublic static final int CHANGE_TYPE_DELETE = 1;\n+\tpublic static final int CHANGE_TYPE_ADD = 2;\n+\t\n+\n+\tpublic void delete( final String pFilename ) {\n+\t\tchanges.add(new DeleteChange(pFilename));\n+\t}\n+\n+\tpublic void move( final String pFrom, final String pTo ) {\n+\t}\n+\t\n+\tpublic void add( final ArchiveEntry pEntry, final InputStream pInput) {\n+\t}\n+\t\n+\tpublic Set asSet() {\n+\t\treturn changes;\n+\t}\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/changes/ChangeWorker.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.changes;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Iterator;\n+\n+import org.apache.commons.compress.archivers.ArchiveEntry;\n+import org.apache.commons.compress.archivers.ArchiveInputStream;\n+import org.apache.commons.compress.archivers.ArchiveOutputStream;\n+import org.apache.commons.compress.utils.IOUtils;\n+\n+/**\n+ * Performs the operations of a change set\n+ */\n+public class ChangeWorker {\n+\tprivate ChangeWorker() {\n+\t\t// nothing to do\n+\t}\n+\t\n+\t/**\n+\t * TODO\n+\t * @param changes\n+\t * @param in\n+\t * @param out\n+\t * @throws IOException \n+\t */\n+\tpublic static void perform(ChangeSet changes, ArchiveInputStream in, ArchiveOutputStream out) throws IOException {\n+\t\tArchiveEntry entry = null;\t\n+\t\twhile((entry = in.getNextEntry()) != null) {\n+\t\t\tSystem.out.println(entry.getName());\n+\t\t\tboolean copy = true; \n+\t\t\t\n+\t\t\tfor (Iterator it = changes.asSet().iterator(); it.hasNext();) {\n+\t\t\t\tChange change = (Change)it.next();\n+\t\t\t\t\n+\t\t\t\tif(change.type() == ChangeSet.CHANGE_TYPE_DELETE) {\n+\t\t\t\t\tDeleteChange delete = ((DeleteChange)change);\n+\t\t\t\t\tif(entry.getName() != null &&\n+\t\t\t\t\t   entry.getName().equals(delete.targetFile())) {\n+\t\t\t\t\t\tcopy = false;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\t\n+\t\t\tif(copy) {\n+\t\t\t\t// copy archive\n+\t\t\t\t// TODO: unsafe long to int \n+\t\t\t\tSystem.out.println(\"Copy: \" + entry.getName());\n+\t\t\t\tlong size = entry.getSize();\n+\t\t\t\tout.putArchiveEntry(entry);\n+\t\t\t\tIOUtils.copy((InputStream)in, out, (int)size);\n+\t\t\t\tout.closeArchiveEntry();\n+\t\t\t}\n+\t\t\t\n+\t\t\t\n+\t\t\tSystem.out.println(\"---\");\n+\t\t}\n+\t\t// add operation stuff\n+\t\tout.close();\n+\t}\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/changes/DeleteChange.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.changes;\n+\n+import org.apache.commons.compress.archivers.ArchiveInputStream;\n+\n+/**\n+ * Implementation for a delete operation\n+ */\n+class DeleteChange implements Change {\n+\tprivate String filename = null;\n+\t\n+\t/**\n+\t * Constructor. Takes the filename of the file to be deleted\n+\t * from the stream as argument.\n+\t * @param pFilename the filename of the file to delete\n+\t */\n+\tpublic DeleteChange(final String pFilename) {\n+\t\tif(pFilename == null) {\n+\t\t\tthrow new NullPointerException();\n+\t\t}\n+\t\tfilename = pFilename;\n+\t}\n+\t\n+\tpublic void perform(ArchiveInputStream input) {\n+\t\tSystem.out.println(\"PERFORMING DELETE\");\n+\t}\n+\n+\tpublic String targetFile() {\n+\t\treturn filename;\n+\t}\n+\t\n+\tpublic int type() {\n+\t\treturn ChangeSet.CHANGE_TYPE_DELETE;\n+\t}\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/compressors/CompressorException.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.compressors;\n+\n+public class CompressorException extends Exception {\n+\n+\tprivate static final long serialVersionUID = -2770299103090672278L;\n+\n+\tpublic CompressorException() {\n+\t\tsuper();\n+\t}\n+\n+\tpublic CompressorException(String arg0, Throwable arg1) {\n+\t\tsuper(arg0, arg1);\n+\t}\n+\n+\tpublic CompressorException(String arg0) {\n+\t\tsuper(arg0);\n+\t}\n+\n+\tpublic CompressorException(Throwable arg0) {\n+\t\tsuper(arg0);\n+\t}\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/compressors/CompressorInputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.compressors;\n+\n+import java.io.InputStream;\n+\n+public abstract class CompressorInputStream extends InputStream {\n+\t// TODO \n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/compressors/CompressorOutputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.compressors;\n+\n+import java.io.OutputStream;\n+\n+public abstract class CompressorOutputStream extends OutputStream {\n+\t// TODO\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/compressors/CompressorStreamFactory.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.compressors;\n+\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.lang.reflect.Constructor;\n+import java.lang.reflect.InvocationTargetException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import org.apache.commons.compress.archivers.ArchiveException;\n+import org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;\n+import org.apache.commons.compress.compressors.bzip2.BZip2CompressorOutputStream;\n+import org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream;\n+import org.apache.commons.compress.compressors.gzip.GzipCompressorOutputStream;\n+\n+public class CompressorStreamFactory {\n+\tfinal Map inputStreamClasses = new HashMap();\n+\tfinal Map outputStreamClasses = new HashMap();\n+\t\n+\tpublic CompressorStreamFactory() throws CompressorException {\n+\t\tregisterInputStream(\"gz\", GzipCompressorInputStream.class);\n+\t\tregisterOutputStream(\"gz\", GzipCompressorOutputStream.class);\n+\t\tregisterInputStream(\"bzip2\", BZip2CompressorInputStream.class);\n+\t\tregisterOutputStream(\"bzip2\", BZip2CompressorOutputStream.class);\n+\t\t\n+\t}\n+\t\n+\tpublic void registerInputStream( final String name, final Class stream ) throws CompressorException {\n+\t\tif (CompressorInputStream.class.isAssignableFrom(stream) && !(stream.isInterface())) {\n+\t\t\tinputStreamClasses.put(name, stream);\n+        } else {\n+            throw new CompressorException(\"Compressor does not implement the CompressorInputStream interface.\");\n+        }\t\n+\t}\n+\n+\tpublic void registerOutputStream( final String name, final Class stream ) throws CompressorException {\n+\t\tif (CompressorOutputStream.class.isAssignableFrom(stream) && !(stream.isInterface())) {\n+\t\t\toutputStreamClasses.put(name, stream);\n+        } else {\n+            throw new CompressorException(\"Compressor does not implement the CompressorOutputStream interface.\");\n+        }\n+\t}\n+\t\n+\tpublic CompressorInputStream createCompressorInputStream( final String name, final InputStream out ) throws CompressorException {\n+        try {\n+            final Class clazz = (Class) inputStreamClasses.get(name);\n+\n+            if (clazz == null) {\n+            \tthrow new CompressorException(\"CompressorFactory could not create instance\");\n+            }\n+\n+            final Class[] params = { InputStream.class };\n+            final Constructor constructor = clazz.getConstructor(params);\n+            final Object[] initargs = { out };\n+            return (CompressorInputStream) constructor.newInstance(initargs);\n+        } catch (InstantiationException e) {\n+            throw new CompressorException(\"CompressorFactory could not create instance\", e);\n+        } catch (IllegalAccessException e) {\n+            throw new CompressorException(\"CompressorFactory could not create instance\", e);\n+        } catch (SecurityException e) {\n+            throw new CompressorException(\"CompressorFactory could not create instance\", e);\n+        } catch (NoSuchMethodException e) {\n+            throw new CompressorException(\"CompressorFactory could not create instance\", e);\n+        } catch (IllegalArgumentException e) {\n+            throw new CompressorException(\"CompressorFactory could not create instance\", e);\n+        } catch (InvocationTargetException e) {\n+            throw new CompressorException(\"CompressorFactory could not create instance\", e);\n+        }\n+    }\n+\n+    public CompressorOutputStream createCompressorOutputStream( final String name, final OutputStream out ) throws ArchiveException {\n+        try {\n+            final Class clazz = (Class) outputStreamClasses.get(name);\n+            \n+            if (clazz == null) {\n+            \tthrow new ArchiveException(\"CompressorFactory could not create instance\");\n+            }\n+            \n+            final Class[] params = { OutputStream.class };\n+            final Constructor constructor = clazz.getConstructor(params);\n+            final Object[] initargs = { out };\n+            return (CompressorOutputStream) constructor.newInstance(initargs);\n+        } catch (InstantiationException e) {\n+            throw new ArchiveException(\"CompressorFactory could not create instance\", e);\n+        } catch (IllegalAccessException e) {\n+            throw new ArchiveException(\"CompressorFactory could not create instance\", e);\n+        } catch (SecurityException e) {\n+            throw new ArchiveException(\"CompressorFactory could not create instance\", e);\n+        } catch (NoSuchMethodException e) {\n+            throw new ArchiveException(\"CompressorFactory could not create instance\", e);\n+        } catch (IllegalArgumentException e) {\n+            throw new ArchiveException(\"CompressorFactory could not create instance\", e);\n+        } catch (InvocationTargetException e) {\n+            throw new ArchiveException(\"CompressorFactory could not create instance\", e);\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/compressors/bzip2/BZip2CompressorInputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.compressors.bzip2;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import org.apache.commons.compress.compressors.CompressorInputStream;\n+\n+/**\n+ * An input stream that decompresses from the BZip2 format (without the file\n+ * header chars) to be read as any other stream.\n+ */\n+public class BZip2CompressorInputStream extends CompressorInputStream implements BZip2Constants {\n+\n+    private static void cadvise() {\n+        System.out.println(\"CRC Error\");\n+        //throw new CCoruptionError();\n+    }\n+\n+    /*\n+    private static void badBGLengths() {\n+        cadvise();\n+    }\n+\n+    private static void bitStreamEOF() {\n+        cadvise();\n+    }\n+    */\n+\n+    private static void compressedStreamEOF() {\n+        cadvise();\n+    }\n+\n+    private void makeMaps() {\n+        int i;\n+        nInUse = 0;\n+        for (i = 0; i < 256; i++) {\n+            if (inUse[i]) {\n+                seqToUnseq[nInUse] = (char) i;\n+                unseqToSeq[i] = (char) nInUse;\n+                nInUse++;\n+            }\n+        }\n+    }\n+\n+    /*\n+      index of the last char in the block, so\n+      the block size == last + 1.\n+    */\n+    private int  last;\n+\n+    /*\n+      index in zptr[] of original string after sorting.\n+    */\n+    private int  origPtr;\n+\n+    /*\n+      always: in the range 0 .. 9.\n+      The current block size is 100000 * this number.\n+    */\n+    private int blockSize100k;\n+\n+    private boolean blockRandomised;\n+\n+    private int bsBuff;\n+    private int bsLive;\n+    private CRC mCrc = new CRC();\n+\n+    private boolean[] inUse = new boolean[256];\n+    private int nInUse;\n+\n+    private char[] seqToUnseq = new char[256];\n+    private char[] unseqToSeq = new char[256];\n+\n+    private char[] selector = new char[MAX_SELECTORS];\n+    private char[] selectorMtf = new char[MAX_SELECTORS];\n+\n+    private int[] tt;\n+    private char[] ll8;\n+\n+    /*\n+      freq table collected to save a pass over the data\n+      during decompression.\n+    */\n+    private int[] unzftab = new int[256];\n+\n+    private int[][] limit = new int[N_GROUPS][MAX_ALPHA_SIZE];\n+    private int[][] base = new int[N_GROUPS][MAX_ALPHA_SIZE];\n+    private int[][] perm = new int[N_GROUPS][MAX_ALPHA_SIZE];\n+    private int[] minLens = new int[N_GROUPS];\n+\n+    private InputStream bsStream;\n+\n+    private boolean streamEnd = false;\n+\n+    private int currentChar = -1;\n+\n+    private static final int START_BLOCK_STATE = 1;\n+    private static final int RAND_PART_A_STATE = 2;\n+    private static final int RAND_PART_B_STATE = 3;\n+    private static final int RAND_PART_C_STATE = 4;\n+    private static final int NO_RAND_PART_A_STATE = 5;\n+    private static final int NO_RAND_PART_B_STATE = 6;\n+    private static final int NO_RAND_PART_C_STATE = 7;\n+\n+    private int currentState = START_BLOCK_STATE;\n+\n+    private int storedBlockCRC, storedCombinedCRC;\n+    private int computedBlockCRC, computedCombinedCRC;\n+\n+    int i2, count, chPrev, ch2;\n+    int i, tPos;\n+    int rNToGo = 0;\n+    int rTPos  = 0;\n+    int j2;\n+    char z;\n+\n+    public BZip2CompressorInputStream(InputStream zStream) {\n+        ll8 = null;\n+        tt = null;\n+        bsSetStream(zStream);\n+        initialize();\n+        initBlock();\n+        setupBlock();\n+    }\n+\n+    public int read() {\n+        if (streamEnd) {\n+            return -1;\n+        } else {\n+            int retChar = currentChar;\n+            switch(currentState) {\n+            case START_BLOCK_STATE:\n+                break;\n+            case RAND_PART_A_STATE:\n+                break;\n+            case RAND_PART_B_STATE:\n+                setupRandPartB();\n+                break;\n+            case RAND_PART_C_STATE:\n+                setupRandPartC();\n+                break;\n+            case NO_RAND_PART_A_STATE:\n+                break;\n+            case NO_RAND_PART_B_STATE:\n+                setupNoRandPartB();\n+                break;\n+            case NO_RAND_PART_C_STATE:\n+                setupNoRandPartC();\n+                break;\n+            default:\n+                break;\n+            }\n+            return retChar;\n+        }\n+    }\n+\n+    private void initialize() {\n+        char magic3, magic4;\n+        magic3 = bsGetUChar();\n+        magic4 = bsGetUChar();\n+        if (magic3 != 'h' || magic4 < '1' || magic4 > '9') {\n+            bsFinishedWithStream();\n+            streamEnd = true;\n+            return;\n+        }\n+\n+        setDecompressStructureSizes(magic4 - '0');\n+        computedCombinedCRC = 0;\n+    }\n+\n+    private void initBlock() {\n+        char magic1, magic2, magic3, magic4;\n+        char magic5, magic6;\n+        magic1 = bsGetUChar();\n+        magic2 = bsGetUChar();\n+        magic3 = bsGetUChar();\n+        magic4 = bsGetUChar();\n+        magic5 = bsGetUChar();\n+        magic6 = bsGetUChar();\n+        if (magic1 == 0x17 && magic2 == 0x72 && magic3 == 0x45\n+            && magic4 == 0x38 && magic5 == 0x50 && magic6 == 0x90) {\n+            complete();\n+            return;\n+        }\n+\n+        if (magic1 != 0x31 || magic2 != 0x41 || magic3 != 0x59\n+            || magic4 != 0x26 || magic5 != 0x53 || magic6 != 0x59) {\n+            badBlockHeader();\n+            streamEnd = true;\n+            return;\n+        }\n+\n+        storedBlockCRC = bsGetInt32();\n+\n+        if (bsR(1) == 1) {\n+            blockRandomised = true;\n+        } else {\n+            blockRandomised = false;\n+        }\n+\n+        //        currBlockNo++;\n+        getAndMoveToFrontDecode();\n+\n+        mCrc.initialiseCRC();\n+        currentState = START_BLOCK_STATE;\n+    }\n+\n+    private void endBlock() {\n+        computedBlockCRC = mCrc.getFinalCRC();\n+        /* A bad CRC is considered a fatal error. */\n+        if (storedBlockCRC != computedBlockCRC) {\n+            crcError();\n+        }\n+\n+        computedCombinedCRC = (computedCombinedCRC << 1)\n+            | (computedCombinedCRC >>> 31);\n+        computedCombinedCRC ^= computedBlockCRC;\n+    }\n+\n+    private void complete() {\n+        storedCombinedCRC = bsGetInt32();\n+        if (storedCombinedCRC != computedCombinedCRC) {\n+            crcError();\n+        }\n+\n+        bsFinishedWithStream();\n+        streamEnd = true;\n+    }\n+\n+    private static void blockOverrun() {\n+        cadvise();\n+    }\n+\n+    private static void badBlockHeader() {\n+        cadvise();\n+    }\n+\n+    private static void crcError() {\n+        cadvise();\n+    }\n+\n+    private void bsFinishedWithStream() {\n+        try {\n+            if (this.bsStream != null) {\n+                if (this.bsStream != System.in) {\n+                    this.bsStream.close();\n+                    this.bsStream = null;\n+                }\n+            }\n+        } catch (IOException ioe) {\n+            //ignore\n+        }\n+    }\n+\n+    private void bsSetStream(InputStream f) {\n+        bsStream = f;\n+        bsLive = 0;\n+        bsBuff = 0;\n+    }\n+\n+    private int bsR(int n) {\n+        int v;\n+        while (bsLive < n) {\n+            int zzi;\n+            char thech = 0;\n+            try {\n+                thech = (char) bsStream.read();\n+            } catch (IOException e) {\n+                compressedStreamEOF();\n+            }\n+            if (thech == -1) {\n+                compressedStreamEOF();\n+            }\n+            zzi = thech;\n+            bsBuff = (bsBuff << 8) | (zzi & 0xff);\n+            bsLive += 8;\n+        }\n+\n+        v = (bsBuff >> (bsLive - n)) & ((1 << n) - 1);\n+        bsLive -= n;\n+        return v;\n+    }\n+\n+    private char bsGetUChar() {\n+        return (char) bsR(8);\n+    }\n+\n+    private int bsGetint() {\n+        int u = 0;\n+        u = (u << 8) | bsR(8);\n+        u = (u << 8) | bsR(8);\n+        u = (u << 8) | bsR(8);\n+        u = (u << 8) | bsR(8);\n+        return u;\n+    }\n+\n+    private int bsGetIntVS(int numBits) {\n+        return (int) bsR(numBits);\n+    }\n+\n+    private int bsGetInt32() {\n+        return (int) bsGetint();\n+    }\n+\n+    private void hbCreateDecodeTables(int[] limit, int[] base,\n+                                      int[] perm, char[] length,\n+                                      int minLen, int maxLen, int alphaSize) {\n+        int pp, i, j, vec;\n+\n+        pp = 0;\n+        for (i = minLen; i <= maxLen; i++) {\n+            for (j = 0; j < alphaSize; j++) {\n+                if (length[j] == i) {\n+                    perm[pp] = j;\n+                    pp++;\n+                }\n+            }\n+        }\n+\n+        for (i = 0; i < MAX_CODE_LEN; i++) {\n+            base[i] = 0;\n+        }\n+        for (i = 0; i < alphaSize; i++) {\n+            base[length[i] + 1]++;\n+        }\n+\n+        for (i = 1; i < MAX_CODE_LEN; i++) {\n+            base[i] += base[i - 1];\n+        }\n+\n+        for (i = 0; i < MAX_CODE_LEN; i++) {\n+            limit[i] = 0;\n+        }\n+        vec = 0;\n+\n+        for (i = minLen; i <= maxLen; i++) {\n+            vec += (base[i + 1] - base[i]);\n+            limit[i] = vec - 1;\n+            vec <<= 1;\n+        }\n+        for (i = minLen + 1; i <= maxLen; i++) {\n+            base[i] = ((limit[i - 1] + 1) << 1) - base[i];\n+        }\n+    }\n+\n+    private void recvDecodingTables() {\n+        char len[][] = new char[N_GROUPS][MAX_ALPHA_SIZE];\n+        int i, j, t, nGroups, nSelectors, alphaSize;\n+        int minLen, maxLen;\n+        boolean[] inUse16 = new boolean[16];\n+\n+        /* Receive the mapping table */\n+        for (i = 0; i < 16; i++) {\n+            if (bsR(1) == 1) {\n+                inUse16[i] = true;\n+            } else {\n+                inUse16[i] = false;\n+            }\n+        }\n+\n+        for (i = 0; i < 256; i++) {\n+            inUse[i] = false;\n+        }\n+\n+        for (i = 0; i < 16; i++) {\n+            if (inUse16[i]) {\n+                for (j = 0; j < 16; j++) {\n+                    if (bsR(1) == 1) {\n+                        inUse[i * 16 + j] = true;\n+                    }\n+                }\n+            }\n+        }\n+\n+        makeMaps();\n+        alphaSize = nInUse + 2;\n+\n+        /* Now the selectors */\n+        nGroups = bsR(3);\n+        nSelectors = bsR(15);\n+        for (i = 0; i < nSelectors; i++) {\n+            j = 0;\n+            while (bsR(1) == 1) {\n+                j++;\n+            }\n+            selectorMtf[i] = (char) j;\n+        }\n+\n+        /* Undo the MTF values for the selectors. */\n+        {\n+            char[] pos = new char[N_GROUPS];\n+            char tmp, v;\n+            for (v = 0; v < nGroups; v++) {\n+                pos[v] = v;\n+            }\n+\n+            for (i = 0; i < nSelectors; i++) {\n+                v = selectorMtf[i];\n+                tmp = pos[v];\n+                while (v > 0) {\n+                    pos[v] = pos[v - 1];\n+                    v--;\n+                }\n+                pos[0] = tmp;\n+                selector[i] = tmp;\n+            }\n+        }\n+\n+        /* Now the coding tables */\n+        for (t = 0; t < nGroups; t++) {\n+            int curr = bsR(5);\n+            for (i = 0; i < alphaSize; i++) {\n+                while (bsR(1) == 1) {\n+                    if (bsR(1) == 0) {\n+                        curr++;\n+                    } else {\n+                        curr--;\n+                    }\n+                }\n+                len[t][i] = (char) curr;\n+            }\n+        }\n+\n+        /* Create the Huffman decoding tables */\n+        for (t = 0; t < nGroups; t++) {\n+            minLen = 32;\n+            maxLen = 0;\n+            for (i = 0; i < alphaSize; i++) {\n+                if (len[t][i] > maxLen) {\n+                    maxLen = len[t][i];\n+                }\n+                if (len[t][i] < minLen) {\n+                    minLen = len[t][i];\n+                }\n+            }\n+            hbCreateDecodeTables(limit[t], base[t], perm[t], len[t], minLen,\n+                                 maxLen, alphaSize);\n+            minLens[t] = minLen;\n+        }\n+    }\n+\n+    private void getAndMoveToFrontDecode() {\n+        char[] yy = new char[256];\n+        int i, j, nextSym, limitLast;\n+        int EOB, groupNo, groupPos;\n+\n+        limitLast = baseBlockSize * blockSize100k;\n+        origPtr = bsGetIntVS(24);\n+\n+        recvDecodingTables();\n+        EOB = nInUse + 1;\n+        groupNo = -1;\n+        groupPos = 0;\n+\n+        /*\n+          Setting up the unzftab entries here is not strictly\n+          necessary, but it does save having to do it later\n+          in a separate pass, and so saves a block's worth of\n+          cache misses.\n+        */\n+        for (i = 0; i <= 255; i++) {\n+            unzftab[i] = 0;\n+        }\n+\n+        for (i = 0; i <= 255; i++) {\n+            yy[i] = (char) i;\n+        }\n+\n+        last = -1;\n+\n+        {\n+            int zt, zn, zvec, zj;\n+            if (groupPos == 0) {\n+                groupNo++;\n+                groupPos = G_SIZE;\n+            }\n+            groupPos--;\n+            zt = selector[groupNo];\n+            zn = minLens[zt];\n+            zvec = bsR(zn);\n+            while (zvec > limit[zt][zn]) {\n+                zn++;\n+                {\n+                    {\n+                        while (bsLive < 1) {\n+                            int zzi;\n+                            char thech = 0;\n+                            try {\n+                                thech = (char) bsStream.read();\n+                            } catch (IOException e) {\n+                                compressedStreamEOF();\n+                            }\n+                            if (thech == -1) {\n+                                compressedStreamEOF();\n+                            }\n+                            zzi = thech;\n+                            bsBuff = (bsBuff << 8) | (zzi & 0xff);\n+                            bsLive += 8;\n+                        }\n+                    }\n+                    zj = (bsBuff >> (bsLive - 1)) & 1;\n+                    bsLive--;\n+                }\n+                zvec = (zvec << 1) | zj;\n+            }\n+            nextSym = perm[zt][zvec - base[zt][zn]];\n+        }\n+\n+        while (true) {\n+\n+            if (nextSym == EOB) {\n+                break;\n+            }\n+\n+            if (nextSym == RUNA || nextSym == RUNB) {\n+                char ch;\n+                int s = -1;\n+                int N = 1;\n+                do {\n+                    if (nextSym == RUNA) {\n+                        s = s + (0 + 1) * N;\n+                    } else if (nextSym == RUNB) {\n+                        s = s + (1 + 1) * N;\n+                           }\n+                    N = N * 2;\n+                    {\n+                        int zt, zn, zvec, zj;\n+                        if (groupPos == 0) {\n+                            groupNo++;\n+                            groupPos = G_SIZE;\n+                        }\n+                        groupPos--;\n+                        zt = selector[groupNo];\n+                        zn = minLens[zt];\n+                        zvec = bsR(zn);\n+                        while (zvec > limit[zt][zn]) {\n+                            zn++;\n+                            {\n+                                {\n+                                    while (bsLive < 1) {\n+                                        int zzi;\n+                                        char thech = 0;\n+                                        try {\n+                                            thech = (char) bsStream.read();\n+                                        } catch (IOException e) {\n+                                            compressedStreamEOF();\n+                                        }\n+                                        if (thech == -1) {\n+                                            compressedStreamEOF();\n+                                        }\n+                                        zzi = thech;\n+                                        bsBuff = (bsBuff << 8) | (zzi & 0xff);\n+                                        bsLive += 8;\n+                                    }\n+                                }\n+                                zj = (bsBuff >> (bsLive - 1)) & 1;\n+                                bsLive--;\n+                            }\n+                            zvec = (zvec << 1) | zj;\n+                        }\n+                        nextSym = perm[zt][zvec - base[zt][zn]];\n+                    }\n+                } while (nextSym == RUNA || nextSym == RUNB);\n+\n+                s++;\n+                ch = seqToUnseq[yy[0]];\n+                unzftab[ch] += s;\n+\n+                while (s > 0) {\n+                    last++;\n+                    ll8[last] = ch;\n+                    s--;\n+                }\n+\n+                if (last >= limitLast) {\n+                    blockOverrun();\n+                }\n+                continue;\n+            } else {\n+                char tmp;\n+                last++;\n+                if (last >= limitLast) {\n+                    blockOverrun();\n+                }\n+\n+                tmp = yy[nextSym - 1];\n+                unzftab[seqToUnseq[tmp]]++;\n+                ll8[last] = seqToUnseq[tmp];\n+\n+                /*\n+                  This loop is hammered during decompression,\n+                  hence the unrolling.\n+\n+                  for (j = nextSym-1; j > 0; j--) yy[j] = yy[j-1];\n+                */\n+\n+                j = nextSym - 1;\n+                for (; j > 3; j -= 4) {\n+                    yy[j]     = yy[j - 1];\n+                    yy[j - 1] = yy[j - 2];\n+                    yy[j - 2] = yy[j - 3];\n+                    yy[j - 3] = yy[j - 4];\n+                }\n+                for (; j > 0; j--) {\n+                    yy[j] = yy[j - 1];\n+                }\n+\n+                yy[0] = tmp;\n+                {\n+                    int zt, zn, zvec, zj;\n+                    if (groupPos == 0) {\n+                        groupNo++;\n+                        groupPos = G_SIZE;\n+                    }\n+                    groupPos--;\n+                    zt = selector[groupNo];\n+                    zn = minLens[zt];\n+                    zvec = bsR(zn);\n+                    while (zvec > limit[zt][zn]) {\n+                        zn++;\n+                        {\n+                            {\n+                                while (bsLive < 1) {\n+                                    int zzi;\n+                                    char thech = 0;\n+                                    try {\n+                                        thech = (char) bsStream.read();\n+                                    } catch (IOException e) {\n+                                        compressedStreamEOF();\n+                                    }\n+                                    zzi = thech;\n+                                    bsBuff = (bsBuff << 8) | (zzi & 0xff);\n+                                    bsLive += 8;\n+                                }\n+                            }\n+                            zj = (bsBuff >> (bsLive - 1)) & 1;\n+                            bsLive--;\n+                        }\n+                        zvec = (zvec << 1) | zj;\n+                    }\n+                    nextSym = perm[zt][zvec - base[zt][zn]];\n+                }\n+                continue;\n+            }\n+        }\n+    }\n+\n+    private void setupBlock() {\n+        int[] cftab = new int[257];\n+        char ch;\n+\n+        cftab[0] = 0;\n+        for (i = 1; i <= 256; i++) {\n+            cftab[i] = unzftab[i - 1];\n+        }\n+        for (i = 1; i <= 256; i++) {\n+            cftab[i] += cftab[i - 1];\n+        }\n+\n+        for (i = 0; i <= last; i++) {\n+            ch = (char) ll8[i];\n+            tt[cftab[ch]] = i;\n+            cftab[ch]++;\n+        }\n+        cftab = null;\n+\n+        tPos = tt[origPtr];\n+\n+        count = 0;\n+        i2 = 0;\n+        ch2 = 256;   /* not a char and not EOF */\n+\n+        if (blockRandomised) {\n+            rNToGo = 0;\n+            rTPos = 0;\n+            setupRandPartA();\n+        } else {\n+            setupNoRandPartA();\n+        }\n+    }\n+\n+    private void setupRandPartA() {\n+        if (i2 <= last) {\n+            chPrev = ch2;\n+            ch2 = ll8[tPos];\n+            tPos = tt[tPos];\n+            if (rNToGo == 0) {\n+                rNToGo = rNums[rTPos];\n+                rTPos++;\n+                if (rTPos == 512) {\n+                    rTPos = 0;\n+                }\n+            }\n+            rNToGo--;\n+            ch2 ^= (int) ((rNToGo == 1) ? 1 : 0);\n+            i2++;\n+\n+            currentChar = ch2;\n+            currentState = RAND_PART_B_STATE;\n+            mCrc.updateCRC(ch2);\n+        } else {\n+            endBlock();\n+            initBlock();\n+            setupBlock();\n+        }\n+    }\n+\n+    private void setupNoRandPartA() {\n+        if (i2 <= last) {\n+            chPrev = ch2;\n+            ch2 = ll8[tPos];\n+            tPos = tt[tPos];\n+            i2++;\n+\n+            currentChar = ch2;\n+            currentState = NO_RAND_PART_B_STATE;\n+            mCrc.updateCRC(ch2);\n+        } else {\n+            endBlock();\n+            initBlock();\n+            setupBlock();\n+        }\n+    }\n+\n+    private void setupRandPartB() {\n+        if (ch2 != chPrev) {\n+            currentState = RAND_PART_A_STATE;\n+            count = 1;\n+            setupRandPartA();\n+        } else {\n+            count++;\n+            if (count >= 4) {\n+                z = ll8[tPos];\n+                tPos = tt[tPos];\n+                if (rNToGo == 0) {\n+                    rNToGo = rNums[rTPos];\n+                    rTPos++;\n+                    if (rTPos == 512) {\n+                        rTPos = 0;\n+                    }\n+                }\n+                rNToGo--;\n+                z ^= ((rNToGo == 1) ? 1 : 0);\n+                j2 = 0;\n+                currentState = RAND_PART_C_STATE;\n+                setupRandPartC();\n+            } else {\n+                currentState = RAND_PART_A_STATE;\n+                setupRandPartA();\n+            }\n+        }\n+    }\n+\n+    private void setupRandPartC() {\n+        if (j2 < (int) z) {\n+            currentChar = ch2;\n+            mCrc.updateCRC(ch2);\n+            j2++;\n+        } else {\n+            currentState = RAND_PART_A_STATE;\n+            i2++;\n+            count = 0;\n+            setupRandPartA();\n+        }\n+    }\n+\n+    private void setupNoRandPartB() {\n+        if (ch2 != chPrev) {\n+            currentState = NO_RAND_PART_A_STATE;\n+            count = 1;\n+            setupNoRandPartA();\n+        } else {\n+            count++;\n+            if (count >= 4) {\n+                z = ll8[tPos];\n+                tPos = tt[tPos];\n+                currentState = NO_RAND_PART_C_STATE;\n+                j2 = 0;\n+                setupNoRandPartC();\n+            } else {\n+                currentState = NO_RAND_PART_A_STATE;\n+                setupNoRandPartA();\n+            }\n+        }\n+    }\n+\n+    private void setupNoRandPartC() {\n+        if (j2 < (int) z) {\n+            currentChar = ch2;\n+            mCrc.updateCRC(ch2);\n+            j2++;\n+        } else {\n+            currentState = NO_RAND_PART_A_STATE;\n+            i2++;\n+            count = 0;\n+            setupNoRandPartA();\n+        }\n+    }\n+\n+    private void setDecompressStructureSizes(int newSize100k) {\n+        if (!(0 <= newSize100k && newSize100k <= 9 && 0 <= blockSize100k\n+               && blockSize100k <= 9)) {\n+            // throw new IOException(\"Invalid block size\");\n+        }\n+\n+        blockSize100k = newSize100k;\n+\n+        if (newSize100k == 0) {\n+            return;\n+        }\n+\n+        int n = baseBlockSize * newSize100k;\n+        ll8 = new char[n];\n+        tt = new int[n];\n+    }\n+}\n+\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/compressors/bzip2/BZip2CompressorOutputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.compressors.bzip2;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+\n+import org.apache.commons.compress.compressors.CompressorOutputStream;\n+\n+/**\n+ * An output stream that compresses into the BZip2 format (without the file\n+ * header chars) into another stream. TODO: Update to BZip2 1.0.1\n+ */\n+public class BZip2CompressorOutputStream extends CompressorOutputStream implements BZip2Constants {\n+\tprotected static final int SETMASK = (1 << 21);\n+    protected static final int CLEARMASK = (~SETMASK);\n+    protected static final int GREATER_ICOST = 15;\n+    protected static final int LESSER_ICOST = 0;\n+    protected static final int SMALL_THRESH = 20;\n+    protected static final int DEPTH_THRESH = 10;\n+\n+    /*\n+      If you are ever unlucky/improbable enough\n+      to get a stack overflow whilst sorting,\n+      increase the following constant and try\n+      again.  In practice I have never seen the\n+      stack go above 27 elems, so the following\n+      limit seems very generous.\n+    */\n+    protected static final int QSORT_STACK_SIZE = 1000;\n+\n+    private static void panic() {\n+        System.out.println(\"panic\");\n+        //throw new CError();\n+    }\n+\n+    private void makeMaps() {\n+        int i;\n+        nInUse = 0;\n+        for (i = 0; i < 256; i++) {\n+            if (inUse[i]) {\n+                seqToUnseq[nInUse] = (char) i;\n+                unseqToSeq[i] = (char) nInUse;\n+                nInUse++;\n+            }\n+        }\n+    }\n+\n+    protected static void hbMakeCodeLengths(char[] len, int[] freq,\n+                                            int alphaSize, int maxLen) {\n+        /*\n+          Nodes and heap entries run from 1.  Entry 0\n+          for both the heap and nodes is a sentinel.\n+        */\n+        int nNodes, nHeap, n1, n2, i, j, k;\n+        boolean  tooLong;\n+\n+        int[] heap = new int[MAX_ALPHA_SIZE + 2];\n+        int[] weight = new int[MAX_ALPHA_SIZE * 2];\n+        int[] parent = new int[MAX_ALPHA_SIZE * 2];\n+\n+        for (i = 0; i < alphaSize; i++) {\n+            weight[i + 1] = (freq[i] == 0 ? 1 : freq[i]) << 8;\n+        }\n+\n+        while (true) {\n+            nNodes = alphaSize;\n+            nHeap = 0;\n+\n+            heap[0] = 0;\n+            weight[0] = 0;\n+            parent[0] = -2;\n+\n+            for (i = 1; i <= alphaSize; i++) {\n+                parent[i] = -1;\n+                nHeap++;\n+                heap[nHeap] = i;\n+                {\n+                    int zz, tmp;\n+                    zz = nHeap;\n+                    tmp = heap[zz];\n+                    while (weight[tmp] < weight[heap[zz >> 1]]) {\n+                        heap[zz] = heap[zz >> 1];\n+                        zz >>= 1;\n+                    }\n+                    heap[zz] = tmp;\n+                }\n+            }\n+            if (!(nHeap < (MAX_ALPHA_SIZE + 2))) {\n+                panic();\n+            }\n+\n+            while (nHeap > 1) {\n+                n1 = heap[1];\n+                heap[1] = heap[nHeap];\n+                nHeap--;\n+                {\n+                    int zz = 0, yy = 0, tmp = 0;\n+                    zz = 1;\n+                    tmp = heap[zz];\n+                    while (true) {\n+                        yy = zz << 1;\n+                        if (yy > nHeap) {\n+                            break;\n+                        }\n+                        if (yy < nHeap\n+                            && weight[heap[yy + 1]] < weight[heap[yy]]) {\n+                            yy++;\n+                        }\n+                        if (weight[tmp] < weight[heap[yy]]) {\n+                            break;\n+                        }\n+                        heap[zz] = heap[yy];\n+                        zz = yy;\n+                    }\n+                    heap[zz] = tmp;\n+                }\n+                n2 = heap[1];\n+                heap[1] = heap[nHeap];\n+                nHeap--;\n+                {\n+                    int zz = 0, yy = 0, tmp = 0;\n+                    zz = 1;\n+                    tmp = heap[zz];\n+                    while (true) {\n+                        yy = zz << 1;\n+                        if (yy > nHeap) {\n+                            break;\n+                        }\n+                        if (yy < nHeap\n+                            && weight[heap[yy + 1]] < weight[heap[yy]]) {\n+                            yy++;\n+                        }\n+                        if (weight[tmp] < weight[heap[yy]]) {\n+                            break;\n+                        }\n+                        heap[zz] = heap[yy];\n+                        zz = yy;\n+                    }\n+                    heap[zz] = tmp;\n+                }\n+                nNodes++;\n+                parent[n1] = parent[n2] = nNodes;\n+\n+                weight[nNodes] = ((weight[n1] & 0xffffff00)\n+                                  + (weight[n2] & 0xffffff00))\n+                    | (1 + (((weight[n1] & 0x000000ff) >\n+                             (weight[n2] & 0x000000ff)) ?\n+                            (weight[n1] & 0x000000ff) :\n+                            (weight[n2] & 0x000000ff)));\n+\n+                parent[nNodes] = -1;\n+                nHeap++;\n+                heap[nHeap] = nNodes;\n+                {\n+                    int zz = 0, tmp = 0;\n+                    zz = nHeap;\n+                    tmp = heap[zz];\n+                    while (weight[tmp] < weight[heap[zz >> 1]]) {\n+                        heap[zz] = heap[zz >> 1];\n+                        zz >>= 1;\n+                    }\n+                    heap[zz] = tmp;\n+                }\n+            }\n+            if (!(nNodes < (MAX_ALPHA_SIZE * 2))) {\n+                panic();\n+            }\n+\n+            tooLong = false;\n+            for (i = 1; i <= alphaSize; i++) {\n+                j = 0;\n+                k = i;\n+                while (parent[k] >= 0) {\n+                    k = parent[k];\n+                    j++;\n+                }\n+                len[i - 1] = (char) j;\n+                if (j > maxLen) {\n+                    tooLong = true;\n+                }\n+            }\n+\n+            if (!tooLong) {\n+                break;\n+            }\n+\n+            for (i = 1; i < alphaSize; i++) {\n+                j = weight[i] >> 8;\n+                j = 1 + (j / 2);\n+                weight[i] = j << 8;\n+            }\n+        }\n+    }\n+\n+    /*\n+      index of the last char in the block, so\n+      the block size == last + 1.\n+    */\n+    int last;\n+\n+    /*\n+      index in zptr[] of original string after sorting.\n+    */\n+    int origPtr;\n+\n+    /*\n+      always: in the range 0 .. 9.\n+      The current block size is 100000 * this number.\n+    */\n+    int blockSize100k;\n+\n+    boolean blockRandomised;\n+\n+    int bytesOut;\n+    int bsBuff;\n+    int bsLive;\n+    CRC mCrc = new CRC();\n+\n+    private boolean[] inUse = new boolean[256];\n+    private int nInUse;\n+\n+    private char[] seqToUnseq = new char[256];\n+    private char[] unseqToSeq = new char[256];\n+\n+    private char[] selector = new char[MAX_SELECTORS];\n+    private char[] selectorMtf = new char[MAX_SELECTORS];\n+\n+    private char[] block;\n+    private int[] quadrant;\n+    private int[] zptr;\n+    private short[] szptr;\n+    private int[] ftab;\n+\n+    private int nMTF;\n+\n+    private int[] mtfFreq = new int[MAX_ALPHA_SIZE];\n+\n+    /*\n+     * Used when sorting.  If too many long comparisons\n+     * happen, we stop sorting, randomise the block\n+     * slightly, and try again.\n+     */\n+    private int workFactor;\n+    private int workDone;\n+    private int workLimit;\n+    private boolean firstAttempt;\n+    private int nBlocksRandomised;\n+\n+    private int currentChar = -1;\n+    private int runLength = 0;\n+\n+    public BZip2CompressorOutputStream(OutputStream inStream) throws IOException {\n+        this(inStream, 9);\n+    }\n+\n+    public BZip2CompressorOutputStream(OutputStream inStream, int inBlockSize)\n+        throws IOException {\n+        block = null;\n+        quadrant = null;\n+        zptr = null;\n+        ftab = null;\n+\n+        bsSetStream(inStream);\n+\n+        workFactor = 50;\n+        if (inBlockSize > 9) {\n+            inBlockSize = 9;\n+        }\n+        if (inBlockSize < 1) {\n+            inBlockSize = 1;\n+        }\n+        blockSize100k = inBlockSize;\n+        allocateCompressStructures();\n+        initialize();\n+        initBlock();\n+    }\n+\n+    /**\n+     *\n+     * modified by Oliver Merkel, 010128\n+     *\n+     */\n+    public void write(int bv) throws IOException {\n+        int b = (256 + bv) % 256;\n+        if (currentChar != -1) {\n+            if (currentChar == b) {\n+                runLength++;\n+                if (runLength > 254) {\n+                    writeRun();\n+                    currentChar = -1;\n+                    runLength = 0;\n+                }\n+            } else {\n+                writeRun();\n+                runLength = 1;\n+                currentChar = b;\n+            }\n+        } else {\n+            currentChar = b;\n+            runLength++;\n+        }\n+    }\n+\n+    private void writeRun() throws IOException {\n+        if (last < allowableBlockSize) {\n+            inUse[currentChar] = true;\n+            for (int i = 0; i < runLength; i++) {\n+                mCrc.updateCRC((char) currentChar);\n+            }\n+            switch (runLength) {\n+            case 1:\n+                last++;\n+                block[last + 1] = (char) currentChar;\n+                break;\n+            case 2:\n+                last++;\n+                block[last + 1] = (char) currentChar;\n+                last++;\n+                block[last + 1] = (char) currentChar;\n+                break;\n+            case 3:\n+                last++;\n+                block[last + 1] = (char) currentChar;\n+                last++;\n+                block[last + 1] = (char) currentChar;\n+                last++;\n+                block[last + 1] = (char) currentChar;\n+                break;\n+            default:\n+                inUse[runLength - 4] = true;\n+                last++;\n+                block[last + 1] = (char) currentChar;\n+                last++;\n+                block[last + 1] = (char) currentChar;\n+                last++;\n+                block[last + 1] = (char) currentChar;\n+                last++;\n+                block[last + 1] = (char) currentChar;\n+                last++;\n+                block[last + 1] = (char) (runLength - 4);\n+                break;\n+            }\n+        } else {\n+            endBlock();\n+            initBlock();\n+            writeRun();\n+        }\n+    }\n+\n+    boolean closed = false;\n+\n+    protected void finalize() throws Throwable {\n+        close();\n+        super.finalize();\n+    }\n+\n+    public void close() throws IOException {\n+        if (closed) {\n+            return;\n+        }\n+\n+        if (runLength > 0) {\n+            writeRun();\n+        }\n+        currentChar = -1;\n+        endBlock();\n+        endCompression();\n+        closed = true;\n+        super.close();\n+        bsStream.close();\n+    }\n+\n+    public void flush() throws IOException {\n+        super.flush();\n+        bsStream.flush();\n+    }\n+\n+    private int blockCRC, combinedCRC;\n+\n+    private void initialize() throws IOException {\n+        bytesOut = 0;\n+        nBlocksRandomised = 0;\n+\n+        /* Write `magic' bytes h indicating file-format == huffmanised,\n+           followed by a digit indicating blockSize100k.\n+        */\n+        bsPutUChar('h');\n+        bsPutUChar('0' + blockSize100k);\n+\n+        combinedCRC = 0;\n+    }\n+\n+    private int allowableBlockSize;\n+\n+    private void initBlock() {\n+        //        blockNo++;\n+        mCrc.initialiseCRC();\n+        last = -1;\n+        //        ch = 0;\n+\n+        for (int i = 0; i < 256; i++) {\n+            inUse[i] = false;\n+        }\n+\n+        /* 20 is just a paranoia constant */\n+        allowableBlockSize = baseBlockSize * blockSize100k - 20;\n+    }\n+\n+    private void endBlock() throws IOException {\n+        blockCRC = mCrc.getFinalCRC();\n+        combinedCRC = (combinedCRC << 1) | (combinedCRC >>> 31);\n+        combinedCRC ^= blockCRC;\n+\n+        /* sort the block and establish posn of original string */\n+        doReversibleTransformation();\n+\n+        /*\n+          A 6-byte block header, the value chosen arbitrarily\n+          as 0x314159265359 :-).  A 32 bit value does not really\n+          give a strong enough guarantee that the value will not\n+          appear by chance in the compressed datastream.  Worst-case\n+          probability of this event, for a 900k block, is about\n+          2.0e-3 for 32 bits, 1.0e-5 for 40 bits and 4.0e-8 for 48 bits.\n+          For a compressed file of size 100Gb -- about 100000 blocks --\n+          only a 48-bit marker will do.  NB: normal compression/\n+          decompression do *not* rely on these statistical properties.\n+          They are only important when trying to recover blocks from\n+          damaged files.\n+        */\n+        bsPutUChar(0x31);\n+        bsPutUChar(0x41);\n+        bsPutUChar(0x59);\n+        bsPutUChar(0x26);\n+        bsPutUChar(0x53);\n+        bsPutUChar(0x59);\n+\n+        /* Now the block's CRC, so it is in a known place. */\n+        bsPutint(blockCRC);\n+\n+        /* Now a single bit indicating randomisation. */\n+        if (blockRandomised) {\n+            bsW(1, 1);\n+            nBlocksRandomised++;\n+        } else {\n+            bsW(1, 0);\n+        }\n+\n+        /* Finally, block's contents proper. */\n+        moveToFrontCodeAndSend();\n+    }\n+\n+    private void endCompression() throws IOException {\n+        /*\n+          Now another magic 48-bit number, 0x177245385090, to\n+          indicate the end of the last block.  (sqrt(pi), if\n+          you want to know.  I did want to use e, but it contains\n+          too much repetition -- 27 18 28 18 28 46 -- for me\n+          to feel statistically comfortable.  Call me paranoid.)\n+        */\n+        bsPutUChar(0x17);\n+        bsPutUChar(0x72);\n+        bsPutUChar(0x45);\n+        bsPutUChar(0x38);\n+        bsPutUChar(0x50);\n+        bsPutUChar(0x90);\n+\n+        bsPutint(combinedCRC);\n+\n+        bsFinishedWithStream();\n+    }\n+\n+    private void hbAssignCodes (int[] code, char[] length, int minLen,\n+                                int maxLen, int alphaSize) {\n+        int n, vec, i;\n+\n+        vec = 0;\n+        for (n = minLen; n <= maxLen; n++) {\n+            for (i = 0; i < alphaSize; i++) {\n+                if (length[i] == n) {\n+                    code[i] = vec;\n+                    vec++;\n+                }\n+            };\n+            vec <<= 1;\n+        }\n+    }\n+\n+    private void bsSetStream(OutputStream f) {\n+        bsStream = f;\n+        bsLive = 0;\n+        bsBuff = 0;\n+        bytesOut = 0;\n+    }\n+\n+    private void bsFinishedWithStream() throws IOException {\n+        while (bsLive > 0) {\n+            int ch = (bsBuff >> 24);\n+            try {\n+                bsStream.write(ch); // write 8-bit\n+            } catch (IOException e) {\n+                throw  e;\n+            }\n+            bsBuff <<= 8;\n+            bsLive -= 8;\n+            bytesOut++;\n+        }\n+    }\n+\n+    private void bsW(int n, int v) throws IOException {\n+        while (bsLive >= 8) {\n+            int ch = (bsBuff >> 24);\n+            try {\n+                bsStream.write(ch); // write 8-bit\n+            } catch (IOException e) {\n+                throw e;\n+            }\n+            bsBuff <<= 8;\n+            bsLive -= 8;\n+            bytesOut++;\n+        }\n+        bsBuff |= (v << (32 - bsLive - n));\n+        bsLive += n;\n+    }\n+\n+    private void bsPutUChar(int c) throws IOException {\n+        bsW(8, c);\n+    }\n+\n+    private void bsPutint(int u) throws IOException {\n+        bsW(8, (u >> 24) & 0xff);\n+        bsW(8, (u >> 16) & 0xff);\n+        bsW(8, (u >>  8) & 0xff);\n+        bsW(8,  u        & 0xff);\n+    }\n+\n+    private void bsPutIntVS(int numBits, int c) throws IOException {\n+        bsW(numBits, c);\n+    }\n+\n+    private void sendMTFValues() throws IOException {\n+        char len[][] = new char[N_GROUPS][MAX_ALPHA_SIZE];\n+\n+        int v, t, i, j, gs, ge, totc, bt, bc, iter;\n+        int nSelectors = 0, alphaSize, minLen, maxLen, selCtr;\n+        int nGroups;\n+        //int nBytes;\n+\n+        alphaSize = nInUse + 2;\n+        for (t = 0; t < N_GROUPS; t++) {\n+            for (v = 0; v < alphaSize; v++) {\n+                len[t][v] = (char) GREATER_ICOST;\n+            }\n+        }\n+\n+        /* Decide how many coding tables to use */\n+        if (nMTF <= 0) {\n+            panic();\n+        }\n+\n+        if (nMTF < 200) {\n+            nGroups = 2;\n+        } else if (nMTF < 600) {\n+            nGroups = 3;\n+        } else if (nMTF < 1200) {\n+            nGroups = 4;\n+        } else if (nMTF < 2400) {\n+            nGroups = 5;\n+        } else {\n+            nGroups = 6;\n+        }\n+\n+        /* Generate an initial set of coding tables */ {\n+            int nPart, remF, tFreq, aFreq;\n+\n+            nPart = nGroups;\n+            remF  = nMTF;\n+            gs = 0;\n+            while (nPart > 0) {\n+                tFreq = remF / nPart;\n+                ge = gs - 1;\n+                aFreq = 0;\n+                while (aFreq < tFreq && ge < alphaSize - 1) {\n+                    ge++;\n+                    aFreq += mtfFreq[ge];\n+                }\n+\n+                if (ge > gs && nPart != nGroups && nPart != 1\n+                    && ((nGroups - nPart) % 2 == 1)) {\n+                    aFreq -= mtfFreq[ge];\n+                    ge--;\n+                }\n+\n+                for (v = 0; v < alphaSize; v++) {\n+                    if (v >= gs && v <= ge) {\n+                        len[nPart - 1][v] = (char) LESSER_ICOST;\n+                    } else {\n+                        len[nPart - 1][v] = (char) GREATER_ICOST;\n+                    }\n+                }\n+\n+                nPart--;\n+                gs = ge + 1;\n+                remF -= aFreq;\n+            }\n+        }\n+\n+        int[][] rfreq = new int[N_GROUPS][MAX_ALPHA_SIZE];\n+        int[] fave = new int[N_GROUPS];\n+        short[] cost = new short[N_GROUPS];\n+        /*\n+          Iterate up to N_ITERS times to improve the tables.\n+        */\n+        for (iter = 0; iter < N_ITERS; iter++) {\n+            for (t = 0; t < nGroups; t++) {\n+                fave[t] = 0;\n+            }\n+\n+            for (t = 0; t < nGroups; t++) {\n+                for (v = 0; v < alphaSize; v++) {\n+                    rfreq[t][v] = 0;\n+                }\n+            }\n+\n+            nSelectors = 0;\n+            totc = 0;\n+            gs = 0;\n+            while (true) {\n+\n+                /* Set group start & end marks. */\n+                if (gs >= nMTF) {\n+                    break;\n+                }\n+                ge = gs + G_SIZE - 1;\n+                if (ge >= nMTF) {\n+                    ge = nMTF - 1;\n+                }\n+\n+                /*\n+                  Calculate the cost of this group as coded\n+                  by each of the coding tables.\n+                */\n+                for (t = 0; t < nGroups; t++) {\n+                    cost[t] = 0;\n+                }\n+\n+                if (nGroups == 6) {\n+                    short cost0, cost1, cost2, cost3, cost4, cost5;\n+                    cost0 = cost1 = cost2 = cost3 = cost4 = cost5 = 0;\n+                    for (i = gs; i <= ge; i++) {\n+                        short icv = szptr[i];\n+                        cost0 += len[0][icv];\n+                        cost1 += len[1][icv];\n+                        cost2 += len[2][icv];\n+                        cost3 += len[3][icv];\n+                        cost4 += len[4][icv];\n+                        cost5 += len[5][icv];\n+                    }\n+                    cost[0] = cost0;\n+                    cost[1] = cost1;\n+                    cost[2] = cost2;\n+                    cost[3] = cost3;\n+                    cost[4] = cost4;\n+                    cost[5] = cost5;\n+                } else {\n+                    for (i = gs; i <= ge; i++) {\n+                        short icv = szptr[i];\n+                        for (t = 0; t < nGroups; t++) {\n+                            cost[t] += len[t][icv];\n+                        }\n+                    }\n+                }\n+\n+                /*\n+                  Find the coding table which is best for this group,\n+                  and record its identity in the selector table.\n+                */\n+                bc = 999999999;\n+                bt = -1;\n+                for (t = 0; t < nGroups; t++) {\n+                    if (cost[t] < bc) {\n+                        bc = cost[t];\n+                        bt = t;\n+                    }\n+                };\n+                totc += bc;\n+                fave[bt]++;\n+                selector[nSelectors] = (char) bt;\n+                nSelectors++;\n+\n+                /*\n+                  Increment the symbol frequencies for the selected table.\n+                */\n+                for (i = gs; i <= ge; i++) {\n+                    rfreq[bt][szptr[i]]++;\n+                }\n+\n+                gs = ge + 1;\n+            }\n+\n+            /*\n+              Recompute the tables based on the accumulated frequencies.\n+            */\n+            for (t = 0; t < nGroups; t++) {\n+                hbMakeCodeLengths(len[t], rfreq[t], alphaSize, 20);\n+            }\n+        }\n+\n+        rfreq = null;\n+        fave = null;\n+        cost = null;\n+\n+        if (!(nGroups < 8)) {\n+            panic();\n+        }\n+        if (!(nSelectors < 32768 && nSelectors <= (2 + (900000 / G_SIZE)))) {\n+            panic();\n+        }\n+\n+\n+        /* Compute MTF values for the selectors. */\n+        {\n+            char[] pos = new char[N_GROUPS];\n+            char ll_i, tmp2, tmp;\n+            for (i = 0; i < nGroups; i++) {\n+                pos[i] = (char) i;\n+            }\n+            for (i = 0; i < nSelectors; i++) {\n+                ll_i = selector[i];\n+                j = 0;\n+                tmp = pos[j];\n+                while (ll_i != tmp) {\n+                    j++;\n+                    tmp2 = tmp;\n+                    tmp = pos[j];\n+                    pos[j] = tmp2;\n+                }\n+                pos[0] = tmp;\n+                selectorMtf[i] = (char) j;\n+            }\n+        }\n+\n+        int[][] code = new int[N_GROUPS][MAX_ALPHA_SIZE];\n+\n+        /* Assign actual codes for the tables. */\n+        for (t = 0; t < nGroups; t++) {\n+            minLen = 32;\n+            maxLen = 0;\n+            for (i = 0; i < alphaSize; i++) {\n+                if (len[t][i] > maxLen) {\n+                    maxLen = len[t][i];\n+                }\n+                if (len[t][i] < minLen) {\n+                    minLen = len[t][i];\n+                }\n+            }\n+            if (maxLen > 20) {\n+                panic();\n+            }\n+            if (minLen < 1) {\n+                panic();\n+            }\n+            hbAssignCodes(code[t], len[t], minLen, maxLen, alphaSize);\n+        }\n+\n+        /* Transmit the mapping table. */\n+        {\n+            boolean[] inUse16 = new boolean[16];\n+            for (i = 0; i < 16; i++) {\n+                inUse16[i] = false;\n+                for (j = 0; j < 16; j++) {\n+                    if (inUse[i * 16 + j]) {\n+                        inUse16[i] = true;\n+                    }\n+                }\n+            }\n+\n+            //nBytes = bytesOut;\n+            for (i = 0; i < 16; i++) {\n+                if (inUse16[i]) {\n+                    bsW(1, 1);\n+                } else {\n+                    bsW(1, 0);\n+                }\n+            }\n+\n+            for (i = 0; i < 16; i++) {\n+                if (inUse16[i]) {\n+                    for (j = 0; j < 16; j++) {\n+                        if (inUse[i * 16 + j]) {\n+                            bsW(1, 1);\n+                        } else {\n+                            bsW(1, 0);\n+                        }\n+                    }\n+                }\n+            }\n+\n+        }\n+\n+        /* Now the selectors. */\n+        //nBytes = bytesOut;\n+        bsW (3, nGroups);\n+        bsW (15, nSelectors);\n+        for (i = 0; i < nSelectors; i++) {\n+            for (j = 0; j < selectorMtf[i]; j++) {\n+                bsW(1, 1);\n+            }\n+            bsW(1, 0);\n+        }\n+\n+        /* Now the coding tables. */\n+        //nBytes = bytesOut;\n+\n+        for (t = 0; t < nGroups; t++) {\n+            int curr = len[t][0];\n+            bsW(5, curr);\n+            for (i = 0; i < alphaSize; i++) {\n+                while (curr < len[t][i]) {\n+                    bsW(2, 2);\n+                    curr++; /* 10 */\n+                }\n+                while (curr > len[t][i]) {\n+                    bsW(2, 3);\n+                    curr--; /* 11 */\n+                }\n+                bsW (1, 0);\n+            }\n+        }\n+\n+        /* And finally, the block data proper */\n+        //nBytes = bytesOut;\n+        selCtr = 0;\n+        gs = 0;\n+        while (true) {\n+            if (gs >= nMTF) {\n+                break;\n+            }\n+            ge = gs + G_SIZE - 1;\n+            if (ge >= nMTF) {\n+                ge = nMTF - 1;\n+            }\n+            for (i = gs; i <= ge; i++) {\n+                bsW(len[selector[selCtr]][szptr[i]],\n+                    code[selector[selCtr]][szptr[i]]);\n+            }\n+\n+            gs = ge + 1;\n+            selCtr++;\n+        }\n+        if (!(selCtr == nSelectors)) {\n+            panic();\n+        }\n+    }\n+\n+    private void moveToFrontCodeAndSend () throws IOException {\n+        bsPutIntVS(24, origPtr);\n+        generateMTFValues();\n+        sendMTFValues();\n+    }\n+\n+    private OutputStream bsStream;\n+\n+    private void simpleSort(int lo, int hi, int d) {\n+        int i, j, h, bigN, hp;\n+        int v;\n+\n+        bigN = hi - lo + 1;\n+        if (bigN < 2) {\n+            return;\n+        }\n+\n+        hp = 0;\n+        while (incs[hp] < bigN) {\n+            hp++;\n+        }\n+        hp--;\n+\n+        for (; hp >= 0; hp--) {\n+            h = incs[hp];\n+\n+            i = lo + h;\n+            while (true) {\n+                /* copy 1 */\n+                if (i > hi) {\n+                    break;\n+                }\n+                v = zptr[i];\n+                j = i;\n+                while (fullGtU(zptr[j - h] + d, v + d)) {\n+                    zptr[j] = zptr[j - h];\n+                    j = j - h;\n+                    if (j <= (lo + h - 1)) {\n+                        break;\n+                    }\n+                }\n+                zptr[j] = v;\n+                i++;\n+\n+                /* copy 2 */\n+                if (i > hi) {\n+                    break;\n+                }\n+                v = zptr[i];\n+                j = i;\n+                while (fullGtU(zptr[j - h] + d, v + d)) {\n+                    zptr[j] = zptr[j - h];\n+                    j = j - h;\n+                    if (j <= (lo + h - 1)) {\n+                        break;\n+                    }\n+                }\n+                zptr[j] = v;\n+                i++;\n+\n+                /* copy 3 */\n+                if (i > hi) {\n+                    break;\n+                }\n+                v = zptr[i];\n+                j = i;\n+                while (fullGtU(zptr[j - h] + d, v + d)) {\n+                    zptr[j] = zptr[j - h];\n+                    j = j - h;\n+                    if (j <= (lo + h - 1)) {\n+                        break;\n+                    }\n+                }\n+                zptr[j] = v;\n+                i++;\n+\n+                if (workDone > workLimit && firstAttempt) {\n+                    return;\n+                }\n+            }\n+        }\n+    }\n+\n+    private void vswap(int p1, int p2, int n) {\n+        int temp = 0;\n+        while (n > 0) {\n+            temp = zptr[p1];\n+            zptr[p1] = zptr[p2];\n+            zptr[p2] = temp;\n+            p1++;\n+            p2++;\n+            n--;\n+        }\n+    }\n+\n+    private char med3(char a, char b, char c) {\n+        char t;\n+        if (a > b) {\n+            t = a;\n+            a = b;\n+            b = t;\n+        }\n+        if (b > c) {\n+            t = b;\n+            b = c;\n+            c = t;\n+        }\n+        if (a > b) {\n+            b = a;\n+        }\n+        return b;\n+    }\n+\n+    private static class StackElem {\n+        int ll;\n+        int hh;\n+        int dd;\n+    }\n+\n+    private void qSort3(int loSt, int hiSt, int dSt) {\n+        int unLo, unHi, ltLo, gtHi, med, n, m;\n+        int sp, lo, hi, d;\n+        StackElem[] stack = new StackElem[QSORT_STACK_SIZE];\n+        for (int count = 0; count < QSORT_STACK_SIZE; count++) {\n+            stack[count] = new StackElem();\n+        }\n+\n+        sp = 0;\n+\n+        stack[sp].ll = loSt;\n+        stack[sp].hh = hiSt;\n+        stack[sp].dd = dSt;\n+        sp++;\n+\n+        while (sp > 0) {\n+            if (sp >= QSORT_STACK_SIZE) {\n+                panic();\n+            }\n+\n+            sp--;\n+            lo = stack[sp].ll;\n+            hi = stack[sp].hh;\n+            d = stack[sp].dd;\n+\n+            if (hi - lo < SMALL_THRESH || d > DEPTH_THRESH) {\n+                simpleSort(lo, hi, d);\n+                if (workDone > workLimit && firstAttempt) {\n+                    return;\n+                }\n+                continue;\n+            }\n+\n+            med = med3(block[zptr[lo] + d + 1],\n+                       block[zptr[hi            ] + d  + 1],\n+                       block[zptr[(lo + hi) >> 1] + d + 1]);\n+\n+            unLo = ltLo = lo;\n+            unHi = gtHi = hi;\n+\n+            while (true) {\n+                while (true) {\n+                    if (unLo > unHi) {\n+                        break;\n+                    }\n+                    n = ((int) block[zptr[unLo] + d + 1]) - med;\n+                    if (n == 0) {\n+                        int temp = 0;\n+                        temp = zptr[unLo];\n+                        zptr[unLo] = zptr[ltLo];\n+                        zptr[ltLo] = temp;\n+                        ltLo++;\n+                        unLo++;\n+                        continue;\n+                    };\n+                    if (n >  0) {\n+                        break;\n+                    }\n+                    unLo++;\n+                }\n+                while (true) {\n+                    if (unLo > unHi) {\n+                        break;\n+                    }\n+                    n = ((int) block[zptr[unHi] + d + 1]) - med;\n+                    if (n == 0) {\n+                        int temp = 0;\n+                        temp = zptr[unHi];\n+                        zptr[unHi] = zptr[gtHi];\n+                        zptr[gtHi] = temp;\n+                        gtHi--;\n+                        unHi--;\n+                        continue;\n+                    };\n+                    if (n <  0) {\n+                        break;\n+                    }\n+                    unHi--;\n+                }\n+                if (unLo > unHi) {\n+                    break;\n+                }\n+                int temp = 0;\n+                temp = zptr[unLo];\n+                zptr[unLo] = zptr[unHi];\n+                zptr[unHi] = temp;\n+                unLo++;\n+                unHi--;\n+            }\n+\n+            if (gtHi < ltLo) {\n+                stack[sp].ll = lo;\n+                stack[sp].hh = hi;\n+                stack[sp].dd = d + 1;\n+                sp++;\n+                continue;\n+            }\n+\n+            n = ((ltLo - lo) < (unLo - ltLo)) ? (ltLo - lo) : (unLo - ltLo);\n+            vswap(lo, unLo - n, n);\n+            m = ((hi - gtHi) < (gtHi - unHi)) ? (hi - gtHi) : (gtHi - unHi);\n+            vswap(unLo, hi - m + 1, m);\n+\n+            n = lo + unLo - ltLo - 1;\n+            m = hi - (gtHi - unHi) + 1;\n+\n+            stack[sp].ll = lo;\n+            stack[sp].hh = n;\n+            stack[sp].dd = d;\n+            sp++;\n+\n+            stack[sp].ll = n + 1;\n+            stack[sp].hh = m - 1;\n+            stack[sp].dd = d + 1;\n+            sp++;\n+\n+            stack[sp].ll = m;\n+            stack[sp].hh = hi;\n+            stack[sp].dd = d;\n+            sp++;\n+        }\n+    }\n+\n+    private void mainSort() {\n+        int i, j, ss, sb;\n+        int[] runningOrder = new int[256];\n+        int[] copy = new int[256];\n+        boolean[] bigDone = new boolean[256];\n+        int c1, c2;\n+        int numQSorted;\n+\n+        /*\n+          In the various block-sized structures, live data runs\n+          from 0 to last+NUM_OVERSHOOT_BYTES inclusive.  First,\n+          set up the overshoot area for block.\n+        */\n+\n+        //   if (verbosity >= 4) fprintf ( stderr, \"   sort initialise ...\\n\" );\n+        for (i = 0; i < NUM_OVERSHOOT_BYTES; i++) {\n+            block[last + i + 2] = block[(i % (last + 1)) + 1];\n+        }\n+        for (i = 0; i <= last + NUM_OVERSHOOT_BYTES; i++) {\n+            quadrant[i] = 0;\n+        }\n+\n+        block[0] = (char) (block[last + 1]);\n+\n+        if (last < 4000) {\n+            /*\n+              Use simpleSort(), since the full sorting mechanism\n+              has quite a large constant overhead.\n+            */\n+            for (i = 0; i <= last; i++) {\n+                zptr[i] = i;\n+            }\n+            firstAttempt = false;\n+            workDone = workLimit = 0;\n+            simpleSort(0, last, 0);\n+        } else {\n+            numQSorted = 0;\n+            for (i = 0; i <= 255; i++) {\n+                bigDone[i] = false;\n+            }\n+\n+            for (i = 0; i <= 65536; i++) {\n+                ftab[i] = 0;\n+            }\n+\n+            c1 = block[0];\n+            for (i = 0; i <= last; i++) {\n+                c2 = block[i + 1];\n+                ftab[(c1 << 8) + c2]++;\n+                c1 = c2;\n+            }\n+\n+            for (i = 1; i <= 65536; i++) {\n+                ftab[i] += ftab[i - 1];\n+            }\n+\n+            c1 = block[1];\n+            for (i = 0; i < last; i++) {\n+                c2 = block[i + 2];\n+                j = (c1 << 8) + c2;\n+                c1 = c2;\n+                ftab[j]--;\n+                zptr[ftab[j]] = i;\n+            }\n+\n+            j = ((block[last + 1]) << 8) + (block[1]);\n+            ftab[j]--;\n+            zptr[ftab[j]] = last;\n+\n+            /*\n+              Now ftab contains the first loc of every small bucket.\n+              Calculate the running order, from smallest to largest\n+              big bucket.\n+            */\n+\n+            for (i = 0; i <= 255; i++) {\n+                runningOrder[i] = i;\n+            }\n+\n+            {\n+                int vv;\n+                int h = 1;\n+                do {\n+                    h = 3 * h + 1;\n+                }\n+                while (h <= 256);\n+                do {\n+                    h = h / 3;\n+                    for (i = h; i <= 255; i++) {\n+                        vv = runningOrder[i];\n+                        j = i;\n+                        while ((ftab[((runningOrder[j - h]) + 1) << 8]\n+                                - ftab[(runningOrder[j - h]) << 8]) >\n+                               (ftab[((vv) + 1) << 8] - ftab[(vv) << 8])) {\n+                            runningOrder[j] = runningOrder[j - h];\n+                            j = j - h;\n+                            if (j <= (h - 1)) {\n+                                break;\n+                            }\n+                        }\n+                        runningOrder[j] = vv;\n+                    }\n+                } while (h != 1);\n+            }\n+\n+            /*\n+              The main sorting loop.\n+            */\n+            for (i = 0; i <= 255; i++) {\n+\n+                /*\n+                  Process big buckets, starting with the least full.\n+                */\n+                ss = runningOrder[i];\n+\n+                /*\n+                  Complete the big bucket [ss] by quicksorting\n+                  any unsorted small buckets [ss, j].  Hopefully\n+                  previous pointer-scanning phases have already\n+                  completed many of the small buckets [ss, j], so\n+                  we don't have to sort them at all.\n+                */\n+                for (j = 0; j <= 255; j++) {\n+                    sb = (ss << 8) + j;\n+                    if (!((ftab[sb] & SETMASK) == SETMASK)) {\n+                        int lo = ftab[sb] & CLEARMASK;\n+                        int hi = (ftab[sb + 1] & CLEARMASK) - 1;\n+                        if (hi > lo) {\n+                            qSort3(lo, hi, 2);\n+                            numQSorted += (hi - lo + 1);\n+                            if (workDone > workLimit && firstAttempt) {\n+                                return;\n+                            }\n+                        }\n+                        ftab[sb] |= SETMASK;\n+                    }\n+                }\n+\n+                /*\n+                  The ss big bucket is now done.  Record this fact,\n+                  and update the quadrant descriptors.  Remember to\n+                  update quadrants in the overshoot area too, if\n+                  necessary.  The \"if (i < 255)\" test merely skips\n+                  this updating for the last bucket processed, since\n+                  updating for the last bucket is pointless.\n+                */\n+                bigDone[ss] = true;\n+\n+                if (i < 255) {\n+                    int bbStart  = ftab[ss << 8] & CLEARMASK;\n+                    int bbSize   = (ftab[(ss + 1) << 8] & CLEARMASK) - bbStart;\n+                    int shifts   = 0;\n+\n+                    while ((bbSize >> shifts) > 65534) {\n+                        shifts++;\n+                    }\n+\n+                    for (j = 0; j < bbSize; j++) {\n+                        int a2update = zptr[bbStart + j];\n+                        int qVal = (j >> shifts);\n+                        quadrant[a2update] = qVal;\n+                        if (a2update < NUM_OVERSHOOT_BYTES) {\n+                            quadrant[a2update + last + 1] = qVal;\n+                        }\n+                    }\n+\n+                    if (!(((bbSize - 1) >> shifts) <= 65535)) {\n+                        panic();\n+                    }\n+                }\n+\n+                /*\n+                  Now scan this big bucket so as to synthesise the\n+                  sorted order for small buckets [t, ss] for all t != ss.\n+                */\n+                for (j = 0; j <= 255; j++) {\n+                    copy[j] = ftab[(j << 8) + ss] & CLEARMASK;\n+                }\n+\n+                for (j = ftab[ss << 8] & CLEARMASK;\n+                     j < (ftab[(ss + 1) << 8] & CLEARMASK); j++) {\n+                    c1 = block[zptr[j]];\n+                    if (!bigDone[c1]) {\n+                        zptr[copy[c1]] = zptr[j] == 0 ? last : zptr[j] - 1;\n+                        copy[c1]++;\n+                    }\n+                }\n+\n+                for (j = 0; j <= 255; j++) {\n+                    ftab[(j << 8) + ss] |= SETMASK;\n+                }\n+            }\n+        }\n+    }\n+\n+    private void randomiseBlock() {\n+        int i;\n+        int rNToGo = 0;\n+        int rTPos  = 0;\n+        for (i = 0; i < 256; i++) {\n+            inUse[i] = false;\n+        }\n+\n+        for (i = 0; i <= last; i++) {\n+            if (rNToGo == 0) {\n+                rNToGo = (char) rNums[rTPos];\n+                rTPos++;\n+                if (rTPos == 512) {\n+                    rTPos = 0;\n+                }\n+            }\n+            rNToGo--;\n+            block[i + 1] ^= ((rNToGo == 1) ? 1 : 0);\n+            // handle 16 bit signed numbers\n+            block[i + 1] &= 0xFF;\n+\n+            inUse[block[i + 1]] = true;\n+        }\n+    }\n+\n+    private void doReversibleTransformation() {\n+        int i;\n+\n+        workLimit = workFactor * last;\n+        workDone = 0;\n+        blockRandomised = false;\n+        firstAttempt = true;\n+\n+        mainSort();\n+\n+        if (workDone > workLimit && firstAttempt) {\n+            randomiseBlock();\n+            workLimit = workDone = 0;\n+            blockRandomised = true;\n+            firstAttempt = false;\n+            mainSort();\n+        }\n+\n+        origPtr = -1;\n+        for (i = 0; i <= last; i++) {\n+            if (zptr[i] == 0) {\n+                origPtr = i;\n+                break;\n+            }\n+        };\n+\n+        if (origPtr == -1) {\n+            panic();\n+        }\n+    }\n+\n+    private boolean fullGtU(int i1, int i2) {\n+        int k;\n+        char c1, c2;\n+        int s1, s2;\n+\n+        c1 = block[i1 + 1];\n+        c2 = block[i2 + 1];\n+        if (c1 != c2) {\n+            return (c1 > c2);\n+        }\n+        i1++;\n+        i2++;\n+\n+        c1 = block[i1 + 1];\n+        c2 = block[i2 + 1];\n+        if (c1 != c2) {\n+            return (c1 > c2);\n+        }\n+        i1++;\n+        i2++;\n+\n+        c1 = block[i1 + 1];\n+        c2 = block[i2 + 1];\n+        if (c1 != c2) {\n+            return (c1 > c2);\n+        }\n+        i1++;\n+        i2++;\n+\n+        c1 = block[i1 + 1];\n+        c2 = block[i2 + 1];\n+        if (c1 != c2) {\n+            return (c1 > c2);\n+        }\n+        i1++;\n+        i2++;\n+\n+        c1 = block[i1 + 1];\n+        c2 = block[i2 + 1];\n+        if (c1 != c2) {\n+            return (c1 > c2);\n+        }\n+        i1++;\n+        i2++;\n+\n+        c1 = block[i1 + 1];\n+        c2 = block[i2 + 1];\n+        if (c1 != c2) {\n+            return (c1 > c2);\n+        }\n+        i1++;\n+        i2++;\n+\n+        k = last + 1;\n+\n+        do {\n+            c1 = block[i1 + 1];\n+            c2 = block[i2 + 1];\n+            if (c1 != c2) {\n+                return (c1 > c2);\n+            }\n+            s1 = quadrant[i1];\n+            s2 = quadrant[i2];\n+            if (s1 != s2) {\n+                return (s1 > s2);\n+            }\n+            i1++;\n+            i2++;\n+\n+            c1 = block[i1 + 1];\n+            c2 = block[i2 + 1];\n+            if (c1 != c2) {\n+                return (c1 > c2);\n+            }\n+            s1 = quadrant[i1];\n+            s2 = quadrant[i2];\n+            if (s1 != s2) {\n+                return (s1 > s2);\n+            }\n+            i1++;\n+            i2++;\n+\n+            c1 = block[i1 + 1];\n+            c2 = block[i2 + 1];\n+            if (c1 != c2) {\n+                return (c1 > c2);\n+            }\n+            s1 = quadrant[i1];\n+            s2 = quadrant[i2];\n+            if (s1 != s2) {\n+                return (s1 > s2);\n+            }\n+            i1++;\n+            i2++;\n+\n+            c1 = block[i1 + 1];\n+            c2 = block[i2 + 1];\n+            if (c1 != c2) {\n+                return (c1 > c2);\n+            }\n+            s1 = quadrant[i1];\n+            s2 = quadrant[i2];\n+            if (s1 != s2) {\n+                return (s1 > s2);\n+            }\n+            i1++;\n+            i2++;\n+\n+            if (i1 > last) {\n+                i1 -= last;\n+                i1--;\n+            };\n+            if (i2 > last) {\n+                i2 -= last;\n+                i2--;\n+            };\n+\n+            k -= 4;\n+            workDone++;\n+        } while (k >= 0);\n+\n+        return false;\n+    }\n+\n+    /*\n+      Knuth's increments seem to work better\n+      than Incerpi-Sedgewick here.  Possibly\n+      because the number of elems to sort is\n+      usually small, typically <= 20.\n+    */\n+    private int[] incs = { 1, 4, 13, 40, 121, 364, 1093, 3280,\n+                           9841, 29524, 88573, 265720,\n+                           797161, 2391484 };\n+\n+    private void allocateCompressStructures () {\n+        int n = baseBlockSize * blockSize100k;\n+        block = new char[(n + 1 + NUM_OVERSHOOT_BYTES)];\n+        quadrant = new int[(n + NUM_OVERSHOOT_BYTES)];\n+        zptr = new int[n];\n+        ftab = new int[65537];\n+\n+        if (block == null || quadrant == null || zptr == null\n+            || ftab == null) {\n+            //int totalDraw = (n + 1 + NUM_OVERSHOOT_BYTES) + (n + NUM_OVERSHOOT_BYTES) + n + 65537;\n+            //compressOutOfMemory ( totalDraw, n );\n+        }\n+\n+        /*\n+          The back end needs a place to store the MTF values\n+          whilst it calculates the coding tables.  We could\n+          put them in the zptr array.  However, these values\n+          will fit in a short, so we overlay szptr at the\n+          start of zptr, in the hope of reducing the number\n+          of cache misses induced by the multiple traversals\n+          of the MTF values when calculating coding tables.\n+          Seems to improve compression speed by about 1%.\n+        */\n+        //    szptr = zptr;\n+\n+\n+        szptr = new short[2 * n];\n+    }\n+\n+    private void generateMTFValues() {\n+        char[] yy = new char[256];\n+        int  i, j;\n+        char tmp;\n+        char tmp2;\n+        int zPend;\n+        int wr;\n+        int EOB;\n+\n+        makeMaps();\n+        EOB = nInUse + 1;\n+\n+        for (i = 0; i <= EOB; i++) {\n+            mtfFreq[i] = 0;\n+        }\n+\n+        wr = 0;\n+        zPend = 0;\n+        for (i = 0; i < nInUse; i++) {\n+            yy[i] = (char) i;\n+        }\n+\n+\n+        for (i = 0; i <= last; i++) {\n+            char ll_i;\n+\n+            ll_i = unseqToSeq[block[zptr[i]]];\n+\n+            j = 0;\n+            tmp = yy[j];\n+            while (ll_i != tmp) {\n+                j++;\n+                tmp2 = tmp;\n+                tmp = yy[j];\n+                yy[j] = tmp2;\n+            };\n+            yy[0] = tmp;\n+\n+            if (j == 0) {\n+                zPend++;\n+            } else {\n+                if (zPend > 0) {\n+                    zPend--;\n+                    while (true) {\n+                        switch (zPend % 2) {\n+                        case 0:\n+                            szptr[wr] = (short) RUNA;\n+                            wr++;\n+                            mtfFreq[RUNA]++;\n+                            break;\n+                        case 1:\n+                            szptr[wr] = (short) RUNB;\n+                            wr++;\n+                            mtfFreq[RUNB]++;\n+                            break;\n+                        };\n+                        if (zPend < 2) {\n+                            break;\n+                        }\n+                        zPend = (zPend - 2) / 2;\n+                    };\n+                    zPend = 0;\n+                }\n+                szptr[wr] = (short) (j + 1);\n+                wr++;\n+                mtfFreq[j + 1]++;\n+            }\n+        }\n+\n+        if (zPend > 0) {\n+            zPend--;\n+            while (true) {\n+                switch (zPend % 2) {\n+                case 0:\n+                    szptr[wr] = (short) RUNA;\n+                    wr++;\n+                    mtfFreq[RUNA]++;\n+                    break;\n+                case 1:\n+                    szptr[wr] = (short) RUNB;\n+                    wr++;\n+                    mtfFreq[RUNB]++;\n+                    break;\n+                }\n+                if (zPend < 2) {\n+                    break;\n+                }\n+                zPend = (zPend - 2) / 2;\n+            }\n+        }\n+\n+        szptr[wr] = (short) EOB;\n+        wr++;\n+        mtfFreq[EOB]++;\n+\n+        nMTF = wr;\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/compressors/bzip2/BZip2Constants.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.commons.compress.compressors.bzip2;\n+\n+/**\n+ * Base class for both the compress and decompress classes. Holds common arrays,\n+ * and static data.\n+ */\n+interface BZip2Constants {\n+\n+    int baseBlockSize = 100000;\n+    int MAX_ALPHA_SIZE = 258;\n+    int MAX_CODE_LEN = 23;\n+    int RUNA = 0;\n+    int RUNB = 1;\n+    int N_GROUPS = 6;\n+    int G_SIZE = 50;\n+    int N_ITERS = 4;\n+    int MAX_SELECTORS = (2 + (900000 / G_SIZE));\n+    int NUM_OVERSHOOT_BYTES = 20;\n+\n+    int[] rNums = {\n+        619, 720, 127, 481, 931, 816, 813, 233, 566, 247,\n+        985, 724, 205, 454, 863, 491, 741, 242, 949, 214,\n+        733, 859, 335, 708, 621, 574, 73, 654, 730, 472,\n+        419, 436, 278, 496, 867, 210, 399, 680, 480, 51,\n+        878, 465, 811, 169, 869, 675, 611, 697, 867, 561,\n+        862, 687, 507, 283, 482, 129, 807, 591, 733, 623,\n+        150, 238, 59, 379, 684, 877, 625, 169, 643, 105,\n+        170, 607, 520, 932, 727, 476, 693, 425, 174, 647,\n+        73, 122, 335, 530, 442, 853, 695, 249, 445, 515,\n+        909, 545, 703, 919, 874, 474, 882, 500, 594, 612,\n+        641, 801, 220, 162, 819, 984, 589, 513, 495, 799,\n+        161, 604, 958, 533, 221, 400, 386, 867, 600, 782,\n+        382, 596, 414, 171, 516, 375, 682, 485, 911, 276,\n+        98, 553, 163, 354, 666, 933, 424, 341, 533, 870,\n+        227, 730, 475, 186, 263, 647, 537, 686, 600, 224,\n+        469, 68, 770, 919, 190, 373, 294, 822, 808, 206,\n+        184, 943, 795, 384, 383, 461, 404, 758, 839, 887,\n+        715, 67, 618, 276, 204, 918, 873, 777, 604, 560,\n+        951, 160, 578, 722, 79, 804, 96, 409, 713, 940,\n+        652, 934, 970, 447, 318, 353, 859, 672, 112, 785,\n+        645, 863, 803, 350, 139, 93, 354, 99, 820, 908,\n+        609, 772, 154, 274, 580, 184, 79, 626, 630, 742,\n+        653, 282, 762, 623, 680, 81, 927, 626, 789, 125,\n+        411, 521, 938, 300, 821, 78, 343, 175, 128, 250,\n+        170, 774, 972, 275, 999, 639, 495, 78, 352, 126,\n+        857, 956, 358, 619, 580, 124, 737, 594, 701, 612,\n+        669, 112, 134, 694, 363, 992, 809, 743, 168, 974,\n+        944, 375, 748, 52, 600, 747, 642, 182, 862, 81,\n+        344, 805, 988, 739, 511, 655, 814, 334, 249, 515,\n+        897, 955, 664, 981, 649, 113, 974, 459, 893, 228,\n+        433, 837, 553, 268, 926, 240, 102, 654, 459, 51,\n+        686, 754, 806, 760, 493, 403, 415, 394, 687, 700,\n+        946, 670, 656, 610, 738, 392, 760, 799, 887, 653,\n+        978, 321, 576, 617, 626, 502, 894, 679, 243, 440,\n+        680, 879, 194, 572, 640, 724, 926, 56, 204, 700,\n+        707, 151, 457, 449, 797, 195, 791, 558, 945, 679,\n+        297, 59, 87, 824, 713, 663, 412, 693, 342, 606,\n+        134, 108, 571, 364, 631, 212, 174, 643, 304, 329,\n+        343, 97, 430, 751, 497, 314, 983, 374, 822, 928,\n+        140, 206, 73, 263, 980, 736, 876, 478, 430, 305,\n+        170, 514, 364, 692, 829, 82, 855, 953, 676, 246,\n+        369, 970, 294, 750, 807, 827, 150, 790, 288, 923,\n+        804, 378, 215, 828, 592, 281, 565, 555, 710, 82,\n+        896, 831, 547, 261, 524, 462, 293, 465, 502, 56,\n+        661, 821, 976, 991, 658, 869, 905, 758, 745, 193,\n+        768, 550, 608, 933, 378, 286, 215, 979, 792, 961,\n+        61, 688, 793, 644, 986, 403, 106, 366, 905, 644,\n+        372, 567, 466, 434, 645, 210, 389, 550, 919, 135,\n+        780, 773, 635, 389, 707, 100, 626, 958, 165, 504,\n+        920, 176, 193, 713, 857, 265, 203, 50, 668, 108,\n+        645, 990, 626, 197, 510, 357, 358, 850, 858, 364,\n+        936, 638\n+    };\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/compressors/bzip2/CRC.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.compressors.bzip2;\n+\n+/**\n+ * A simple class the hold and calculate the CRC for sanity checking of the\n+ * data.\n+ */\n+class CRC {\n+\tprivate static int[] CRC32_TABLE = new int[] { 0x00000000, 0x04c11db7,\n+\t\t\t0x09823b6e, 0x0d4326d9, 0x130476dc, 0x17c56b6b, 0x1a864db2,\n+\t\t\t0x1e475005, 0x2608edb8, 0x22c9f00f, 0x2f8ad6d6, 0x2b4bcb61,\n+\t\t\t0x350c9b64, 0x31cd86d3, 0x3c8ea00a, 0x384fbdbd, 0x4c11db70,\n+\t\t\t0x48d0c6c7, 0x4593e01e, 0x4152fda9, 0x5f15adac, 0x5bd4b01b,\n+\t\t\t0x569796c2, 0x52568b75, 0x6a1936c8, 0x6ed82b7f, 0x639b0da6,\n+\t\t\t0x675a1011, 0x791d4014, 0x7ddc5da3, 0x709f7b7a, 0x745e66cd,\n+\t\t\t0x9823b6e0, 0x9ce2ab57, 0x91a18d8e, 0x95609039, 0x8b27c03c,\n+\t\t\t0x8fe6dd8b, 0x82a5fb52, 0x8664e6e5, 0xbe2b5b58, 0xbaea46ef,\n+\t\t\t0xb7a96036, 0xb3687d81, 0xad2f2d84, 0xa9ee3033, 0xa4ad16ea,\n+\t\t\t0xa06c0b5d, 0xd4326d90, 0xd0f37027, 0xddb056fe, 0xd9714b49,\n+\t\t\t0xc7361b4c, 0xc3f706fb, 0xceb42022, 0xca753d95, 0xf23a8028,\n+\t\t\t0xf6fb9d9f, 0xfbb8bb46, 0xff79a6f1, 0xe13ef6f4, 0xe5ffeb43,\n+\t\t\t0xe8bccd9a, 0xec7dd02d, 0x34867077, 0x30476dc0, 0x3d044b19,\n+\t\t\t0x39c556ae, 0x278206ab, 0x23431b1c, 0x2e003dc5, 0x2ac12072,\n+\t\t\t0x128e9dcf, 0x164f8078, 0x1b0ca6a1, 0x1fcdbb16, 0x018aeb13,\n+\t\t\t0x054bf6a4, 0x0808d07d, 0x0cc9cdca, 0x7897ab07, 0x7c56b6b0,\n+\t\t\t0x71159069, 0x75d48dde, 0x6b93dddb, 0x6f52c06c, 0x6211e6b5,\n+\t\t\t0x66d0fb02, 0x5e9f46bf, 0x5a5e5b08, 0x571d7dd1, 0x53dc6066,\n+\t\t\t0x4d9b3063, 0x495a2dd4, 0x44190b0d, 0x40d816ba, 0xaca5c697,\n+\t\t\t0xa864db20, 0xa527fdf9, 0xa1e6e04e, 0xbfa1b04b, 0xbb60adfc,\n+\t\t\t0xb6238b25, 0xb2e29692, 0x8aad2b2f, 0x8e6c3698, 0x832f1041,\n+\t\t\t0x87ee0df6, 0x99a95df3, 0x9d684044, 0x902b669d, 0x94ea7b2a,\n+\t\t\t0xe0b41de7, 0xe4750050, 0xe9362689, 0xedf73b3e, 0xf3b06b3b,\n+\t\t\t0xf771768c, 0xfa325055, 0xfef34de2, 0xc6bcf05f, 0xc27dede8,\n+\t\t\t0xcf3ecb31, 0xcbffd686, 0xd5b88683, 0xd1799b34, 0xdc3abded,\n+\t\t\t0xd8fba05a, 0x690ce0ee, 0x6dcdfd59, 0x608edb80, 0x644fc637,\n+\t\t\t0x7a089632, 0x7ec98b85, 0x738aad5c, 0x774bb0eb, 0x4f040d56,\n+\t\t\t0x4bc510e1, 0x46863638, 0x42472b8f, 0x5c007b8a, 0x58c1663d,\n+\t\t\t0x558240e4, 0x51435d53, 0x251d3b9e, 0x21dc2629, 0x2c9f00f0,\n+\t\t\t0x285e1d47, 0x36194d42, 0x32d850f5, 0x3f9b762c, 0x3b5a6b9b,\n+\t\t\t0x0315d626, 0x07d4cb91, 0x0a97ed48, 0x0e56f0ff, 0x1011a0fa,\n+\t\t\t0x14d0bd4d, 0x19939b94, 0x1d528623, 0xf12f560e, 0xf5ee4bb9,\n+\t\t\t0xf8ad6d60, 0xfc6c70d7, 0xe22b20d2, 0xe6ea3d65, 0xeba91bbc,\n+\t\t\t0xef68060b, 0xd727bbb6, 0xd3e6a601, 0xdea580d8, 0xda649d6f,\n+\t\t\t0xc423cd6a, 0xc0e2d0dd, 0xcda1f604, 0xc960ebb3, 0xbd3e8d7e,\n+\t\t\t0xb9ff90c9, 0xb4bcb610, 0xb07daba7, 0xae3afba2, 0xaafbe615,\n+\t\t\t0xa7b8c0cc, 0xa379dd7b, 0x9b3660c6, 0x9ff77d71, 0x92b45ba8,\n+\t\t\t0x9675461f, 0x8832161a, 0x8cf30bad, 0x81b02d74, 0x857130c3,\n+\t\t\t0x5d8a9099, 0x594b8d2e, 0x5408abf7, 0x50c9b640, 0x4e8ee645,\n+\t\t\t0x4a4ffbf2, 0x470cdd2b, 0x43cdc09c, 0x7b827d21, 0x7f436096,\n+\t\t\t0x7200464f, 0x76c15bf8, 0x68860bfd, 0x6c47164a, 0x61043093,\n+\t\t\t0x65c52d24, 0x119b4be9, 0x155a565e, 0x18197087, 0x1cd86d30,\n+\t\t\t0x029f3d35, 0x065e2082, 0x0b1d065b, 0x0fdc1bec, 0x3793a651,\n+\t\t\t0x3352bbe6, 0x3e119d3f, 0x3ad08088, 0x2497d08d, 0x2056cd3a,\n+\t\t\t0x2d15ebe3, 0x29d4f654, 0xc5a92679, 0xc1683bce, 0xcc2b1d17,\n+\t\t\t0xc8ea00a0, 0xd6ad50a5, 0xd26c4d12, 0xdf2f6bcb, 0xdbee767c,\n+\t\t\t0xe3a1cbc1, 0xe760d676, 0xea23f0af, 0xeee2ed18, 0xf0a5bd1d,\n+\t\t\t0xf464a0aa, 0xf9278673, 0xfde69bc4, 0x89b8fd09, 0x8d79e0be,\n+\t\t\t0x803ac667, 0x84fbdbd0, 0x9abc8bd5, 0x9e7d9662, 0x933eb0bb,\n+\t\t\t0x97ffad0c, 0xafb010b1, 0xab710d06, 0xa6322bdf, 0xa2f33668,\n+\t\t\t0xbcb4666d, 0xb8757bda, 0xb5365d03, 0xb1f740b4 };\n+\n+\tprivate int m_globalCrc;\n+\n+\tprotected CRC() {\n+\t\tinitialiseCRC();\n+\t}\n+\n+\tint getFinalCRC() {\n+\t\treturn ~m_globalCrc;\n+\t}\n+\n+\tvoid initialiseCRC() {\n+\t\tm_globalCrc = 0xffffffff;\n+\t}\n+\n+\tvoid updateCRC(final int inCh) {\n+\t\tint temp = (m_globalCrc >> 24) ^ inCh;\n+\t\tif (temp < 0) {\n+\t\t\ttemp = 256 + temp;\n+\t\t}\n+\t\tm_globalCrc = (m_globalCrc << 8) ^ CRC32_TABLE[temp];\n+\t}\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/compressors/gzip/GzipCompressorInputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.compressors.gzip;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.apache.commons.compress.compressors.CompressorInputStream;\n+\n+public class GzipCompressorInputStream extends CompressorInputStream {\n+\n+\tprivate final GZIPInputStream in;\n+\t\n+\tpublic GzipCompressorInputStream(InputStream inputStream) throws IOException {\n+\t\tin = new GZIPInputStream(inputStream);\n+\t}\n+\n+\tpublic int read() throws IOException {\n+\t\treturn in.read();\n+\t}\n+\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/compressors/gzip/GzipCompressorOutputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.compressors.gzip;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.util.zip.GZIPOutputStream;\n+\n+import org.apache.commons.compress.compressors.CompressorOutputStream;\n+\n+public class GzipCompressorOutputStream extends CompressorOutputStream {\n+\t\n+\tprivate final GZIPOutputStream out;\n+\t\n+\tpublic GzipCompressorOutputStream( final OutputStream outputStream ) throws IOException {\n+\t\tout = new GZIPOutputStream(outputStream);\n+\t}\n+\n+\tpublic void write(int b) throws IOException {\n+\t\tout.write(b);\n+\t}\n+\n+\tpublic void close() throws IOException {\n+\t\tout.close();\n+\t}\n+\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/utils/CompressUtils.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.utils;\n+\n+\n+public final class CompressUtils {\n+\n+    /**\n+     * Compares one byte array to another\n+     * @param source- the array to compare to \n+     * @param headerBytes - the bytearray match\n+     */\n+    public static boolean compareByteArrays(byte[] source, byte[] match) {\n+        int i = 0;\n+        while(source.length < i || i < match.length ) {\n+            if(source[i] != match[i]) {\n+                return false;\n+            }\n+            i++;\n+        }\n+        return true;\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/utils/IOUtils.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.utils;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+\n+public final class IOUtils {\n+\n+\t/**\n+     * Copies the content of a InputStream into an OutputStream\n+     * \n+     * @param input\n+     *            the InputStream to copy\n+     * @param output\n+     *            the target Stream\n+     * @throws IOException\n+     *             if the streams are interrupted\n+     */\n+    public static void copy(final InputStream input, final OutputStream output) throws IOException {\n+        final byte[] buffer = new byte[8024];\n+        int n = 0;\n+        while (-1 != (n = input.read(buffer))) {\n+            output.write(buffer, 0, n);\n+        }\n+    }\n+    \n+    public static void copy(final InputStream input, final OutputStream output, int buffersize) throws IOException {\n+        final byte[] buffer = new byte[buffersize];\n+        int n = 0;\n+        while (-1 != (n = input.read(buffer))) {\n+            output.write(buffer, 0, n);\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/utils/ReflectionUtils.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.utils;\n+\n+import java.util.Map;\n+\n+import org.apache.commons.compress.archivers.ArchiveException;\n+\n+public final class ReflectionUtils {\n+\n+\tpublic static void registerClazz(Map map, String name, Class type, Class clazz) throws ArchiveException {\n+        if (type.isAssignableFrom(clazz) && !(clazz.isInterface())) {\n+            map.put(name, clazz);\n+        } else {\n+            throw new ArchiveException(\"Archive does not implement the \" + type + \" interface.\");\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/compress/AbstractTestCase.java\n+package org.apache.commons.compress;\n+\n+import java.io.File;\n+\n+import junit.framework.TestCase;\n+\n+public abstract class AbstractTestCase extends TestCase {\n+\n+\tprotected File dir;\n+\t\n+\tprotected void setUp() throws Exception {\n+\t\tdir = File.createTempFile(\"dir\", \"\");\n+\t\tdir.delete();\n+\t\tdir.mkdir();\n+\t}\n+\n+\tprotected void tearDown() throws Exception {\n+\t\tdir.delete();\n+\t\tdir = null;\n+\t}\n+\n+\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/compress/DetectArchiverTestCase.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress;\n+\n+import java.io.BufferedInputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+\n+import junit.framework.TestCase;\n+\n+import org.apache.commons.compress.archivers.ArchiveInputStream;\n+import org.apache.commons.compress.archivers.ArchiveStreamFactory;\n+import org.apache.commons.compress.archivers.ar.ArArchiveInputStream;\n+import org.apache.commons.compress.archivers.jar.JarArchiveInputStream;\n+import org.apache.commons.compress.archivers.tar.TarArchiveInputStream;\n+import org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;\n+\n+public final class DetectArchiverTestCase extends TestCase {\n+\tpublic void testDetection() throws Exception {\n+\t\tfinal ArchiveStreamFactory factory = new ArchiveStreamFactory();\n+\n+\t\tfinal ArchiveInputStream ar = factory.createArchiveInputStream(\n+\t\t\t\tnew BufferedInputStream(new FileInputStream(\n+\t\t\t\t\t\tnew File(getClass().getClassLoader().getResource(\"bla.ar\").getFile())))); \n+\t\tassertTrue(ar instanceof ArArchiveInputStream);\n+\n+\t\tfinal ArchiveInputStream tar = factory.createArchiveInputStream(\n+\t\t\t\tnew BufferedInputStream(new FileInputStream(\n+\t\t\t\t\t\tnew File(getClass().getClassLoader().getResource(\"bla.tar\").getFile()))));\n+\t\tassertTrue(tar instanceof TarArchiveInputStream);\n+\n+\t\tfinal ArchiveInputStream zip = factory.createArchiveInputStream(\n+\t\t\t\tnew BufferedInputStream(new FileInputStream(\n+\t\t\t\t\t\tnew File(getClass().getClassLoader().getResource(\"bla.zip\").getFile()))));\n+\t\tassertTrue(zip instanceof ZipArchiveInputStream);\n+\n+\t\tfinal ArchiveInputStream jar = factory.createArchiveInputStream(\n+\t\t\t\tnew BufferedInputStream(new FileInputStream(\n+\t\t\t\t\t\tnew File(getClass().getClassLoader().getResource(\"bla.jar\").getFile()))));\n+\t\tassertTrue(jar instanceof JarArchiveInputStream);\n+\n+//\t\tfinal ArchiveInputStream tgz = factory.createArchiveInputStream(\n+//\t\t\t\tnew BufferedInputStream(new FileInputStream(\n+//\t\t\t\t\t\tnew File(getClass().getClassLoader().getResource(\"bla.tgz\").getFile()))));\n+//\t\tassertTrue(tgz instanceof TarArchiveInputStream);\n+\t\t\n+\t}\n+\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/compress/DetectCompressorTestCase.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress;\n+\n+import junit.framework.TestCase;\n+\n+public final class DetectCompressorTestCase extends TestCase {\n+\tpublic void testDetection() throws Exception {\n+\t}\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/compress/archivers/ArTestCase.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+\n+import org.apache.commons.compress.archivers.ar.ArArchiveEntry;\n+import org.apache.commons.compress.utils.IOUtils;\n+\n+import org.apache.commons.compress.AbstractTestCase;\n+\n+public final class ArTestCase extends AbstractTestCase {\n+\tpublic void testArArchiveCreation() throws Exception {\n+\t\tfinal File output = new File(dir, \"bla.ar\");\n+\t\t\n+\t\tfinal File file1 = new File(getClass().getClassLoader().getResource(\"test1.xml\").getFile());\n+\t\tfinal File file2 = new File(getClass().getClassLoader().getResource(\"test2.xml\").getFile());\n+\t\t\n+\t\tfinal OutputStream out = new FileOutputStream(output);\n+        final ArchiveOutputStream os = new ArchiveStreamFactory().createArchiveOutputStream(\"ar\", out);\n+\t\tos.putArchiveEntry(new ArArchiveEntry(\"test1.xml\", file1.length()));\n+\t\tIOUtils.copy(new FileInputStream(file1), os);\n+\t\tos.closeArchiveEntry();\n+\t\t\n+\t\tos.putArchiveEntry(new ArArchiveEntry(\"test2.xml\", file2.length()));\n+\t\tIOUtils.copy(new FileInputStream(file2), os);\n+\t\tos.closeArchiveEntry();\n+\t\t\n+\t\tos.close();\n+\t}\n+\n+\tpublic void testArUnarchive() throws Exception {\n+\t\tfinal File output = new File(dir, \"bla.ar\");\n+\t\t{\n+\t\t\tfinal File file1 = new File(getClass().getClassLoader().getResource(\"test1.xml\").getFile());\n+\t\t\tfinal File file2 = new File(getClass().getClassLoader().getResource(\"test2.xml\").getFile());\n+\t\t\t\n+\t\t\tfinal OutputStream out = new FileOutputStream(output);\n+\t        final ArchiveOutputStream os = new ArchiveStreamFactory().createArchiveOutputStream(\"ar\", out);\n+\t\t\tos.putArchiveEntry(new ArArchiveEntry(\"test1.xml\", file1.length()));\n+\t\t\tIOUtils.copy(new FileInputStream(file1), os);\n+\t\t\tos.closeArchiveEntry();\n+\t\t\t\n+\t\t\tos.putArchiveEntry(new ArArchiveEntry(\"test2.xml\", file2.length()));\n+\t\t\tIOUtils.copy(new FileInputStream(file2), os);\n+\t\t\tos.closeArchiveEntry();\n+\t\t\tos.close();\n+\t\t}\n+\t\t\n+\t\t// UnArArchive Operation\n+\t\tfinal File input = output;\n+\t\tfinal InputStream is = new FileInputStream(input);\n+\t\tfinal ArchiveInputStream in = new ArchiveStreamFactory().createArchiveInputStream(\"ar\", is);\n+\t\tfinal ArArchiveEntry entry = (ArArchiveEntry)in.getNextEntry();\n+\t\t\n+\t\tFile target = new File(dir, entry.getName());\n+        final OutputStream out = new FileOutputStream(target);\n+        \n+        IOUtils.copy(in, out);\n+    \n+        out.close();\n+        in.close();\n+\t}\n+\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/compress/archivers/JarTestCase.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+\n+import org.apache.commons.compress.archivers.zip.ZipArchiveEntry;\n+import org.apache.commons.compress.utils.IOUtils;\n+\n+import org.apache.commons.compress.AbstractTestCase;\n+\n+public final class JarTestCase extends AbstractTestCase {\n+\tpublic void testJarArchiveCreation() throws Exception {\n+\t\tfinal File output = new File(dir, \"bla.jar\");\n+\n+\t\tfinal File file1 = new File(getClass().getClassLoader().getResource(\"test1.xml\").getFile());\n+\t\tfinal File file2 = new File(getClass().getClassLoader().getResource(\"test2.xml\").getFile());\n+\t\t\n+        final OutputStream out = new FileOutputStream(output);\n+        \n+        final ArchiveOutputStream os = new ArchiveStreamFactory().createArchiveOutputStream(\"jar\", out);\n+\n+        os.putArchiveEntry(new ZipArchiveEntry(\"testdata/test1.xml\"));\n+        IOUtils.copy(new FileInputStream(file1), os);\n+        os.closeArchiveEntry();\n+        \n+        os.putArchiveEntry(new ZipArchiveEntry(\"testdata/test2.xml\"));\n+        IOUtils.copy(new FileInputStream(file2), os);\n+        os.closeArchiveEntry();\n+\n+        os.close();\n+    }\n+\n+\t\n+\tpublic void testJarUnarchive() throws Exception {\n+\t\tfinal File input = new File(getClass().getClassLoader().getResource(\"bla.jar\").getFile());\n+        final InputStream is = new FileInputStream(input);\n+        final ArchiveInputStream in = new ArchiveStreamFactory().createArchiveInputStream(\"jar\", is);\n+        \n+        ZipArchiveEntry entry = (ZipArchiveEntry)in.getNextEntry();\n+        File o = new File(dir, entry.getName());\n+        o.getParentFile().mkdirs();\n+        OutputStream out = new FileOutputStream(o);\n+        IOUtils.copy(in, out);\n+        out.close();\n+        \n+        entry = (ZipArchiveEntry)in.getNextEntry();\n+        o = new File(dir, entry.getName());\n+        o.getParentFile().mkdirs();\n+        out = new FileOutputStream(o);\n+        IOUtils.copy(in, out);\n+        out.close();\n+        \n+        entry = (ZipArchiveEntry)in.getNextEntry();\n+        o = new File(dir, entry.getName());\n+        o.getParentFile().mkdirs();\n+        out = new FileOutputStream(o);\n+        IOUtils.copy(in, out);\n+        out.close();\n+        \n+        in.close();\n+    }\n+\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/compress/archivers/TarTestCase.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+\n+import org.apache.commons.compress.AbstractTestCase;\n+import org.apache.commons.compress.archivers.tar.TarArchiveEntry;\n+import org.apache.commons.compress.utils.IOUtils;\n+\n+public final class TarTestCase extends AbstractTestCase {\n+    public void testTarArchiveCreation() throws Exception {\n+\n+\t\tfinal File output = new File(dir, \"bla.tar\");\n+\n+\t\tfinal File file1 = new File(getClass().getClassLoader().getResource(\"test1.xml\").getFile());\n+\n+    \tfinal OutputStream out = new FileOutputStream(output);\n+        \n+        final ArchiveOutputStream os = new ArchiveStreamFactory().createArchiveOutputStream(\"tar\", out);\n+        \n+        final TarArchiveEntry entry = new TarArchiveEntry(\"testdata/test1.xml\");\n+        entry.setModTime(0);\n+        entry.setSize(file1.length());\n+        entry.setUserID(0);\n+        entry.setGroupID(0);\n+        entry.setUserName(\"avalon\");\n+        entry.setGroupName(\"excalibur\");\n+        entry.setMode(0100000);\n+        \n+        os.putArchiveEntry(entry);\n+        IOUtils.copy(new FileInputStream(file1), os);\n+\n+        os.closeArchiveEntry();\n+        os.close();\n+    }\n+    public void testTarUnarchive() throws Exception {\n+\t\tfinal File input = new File(getClass().getClassLoader().getResource(\"bla.tar\").getFile());\n+\t\tfinal InputStream is = new FileInputStream(input);\n+        final ArchiveInputStream in = new ArchiveStreamFactory().createArchiveInputStream(\"tar\", is);\n+        final TarArchiveEntry entry = (TarArchiveEntry)in.getNextEntry();\n+        final OutputStream out = new FileOutputStream(new File(dir, entry.getName()));\n+        IOUtils.copy(in, out);\n+        out.close();\n+        in.close();\n+    }\n+\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/compress/archivers/ZipTestCase.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+\n+import org.apache.commons.compress.archivers.zip.ZipArchiveEntry;\n+import org.apache.commons.compress.utils.IOUtils;\n+\n+import org.apache.commons.compress.AbstractTestCase;\n+\n+public final class ZipTestCase extends AbstractTestCase {\n+\tpublic void testZipArchiveCreation() throws Exception {\n+\t\t\n+\t\tfinal File output = new File(dir, \"bla.zip\");\n+\t\t\n+\t\tfinal File file1 = new File(getClass().getClassLoader().getResource(\"test1.xml\").getFile());\n+\t\tfinal File file2 = new File(getClass().getClassLoader().getResource(\"test2.xml\").getFile());\n+\t\t\n+        final OutputStream out = new FileOutputStream(output);\n+        \n+        final ArchiveOutputStream os = new ArchiveStreamFactory().createArchiveOutputStream(\"zip\", out);\n+\n+        os.putArchiveEntry(new ZipArchiveEntry(\"testdata/test1.xml\"));\n+        IOUtils.copy(new FileInputStream(file1), os);\n+        os.closeArchiveEntry();\n+        \n+        os.putArchiveEntry(new ZipArchiveEntry(\"testdata/test2.xml\"));\n+        IOUtils.copy(new FileInputStream(file2), os);\n+        os.closeArchiveEntry();\n+        \n+        os.close();\n+    }\n+    public void testZipUnarchive() throws Exception {\n+\n+\t\tfinal File input = new File(getClass().getClassLoader().getResource(\"bla.zip\").getFile());\n+    \t\n+        final InputStream is = new FileInputStream(input);\n+        final ArchiveInputStream in = new ArchiveStreamFactory().createArchiveInputStream(\"zip\", is);\n+ \n+        final ZipArchiveEntry entry = (ZipArchiveEntry)in.getNextEntry();\n+        final OutputStream out = new FileOutputStream(new File(dir, entry.getName()));\n+        \n+        IOUtils.copy(in, out);\n+    \n+        out.close();\n+        in.close();\n+    }\n+\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/compress/archivers/memory/MemoryArchiveEntry.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.memory;\n+\n+import org.apache.commons.compress.archivers.ArchiveEntry;\n+\n+public final class MemoryArchiveEntry implements ArchiveEntry {\n+\n+\tprivate final String name;\n+\t\n+\tpublic MemoryArchiveEntry( final String pName ) {\n+\t\tname = pName;\n+\t}\n+\t\n+\tpublic String getName() {\n+\t\treturn name;\n+\t}\n+\n+\tpublic long getSize() {\n+\t\t// TODO Auto-generated method stub\n+\t\treturn 0;\n+\t}\n+\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/compress/archivers/memory/MemoryArchiveInputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.memory;\n+\n+import java.io.IOException;\n+\n+import org.apache.commons.compress.archivers.ArchiveEntry;\n+import org.apache.commons.compress.archivers.ArchiveInputStream;\n+\n+public final class MemoryArchiveInputStream extends ArchiveInputStream {\n+\n+\tprivate final String[] filenames;\n+\tprivate final String[] content;\n+\tprivate int p;\n+\t\n+\tpublic MemoryArchiveInputStream( final String[][] pFiles ) {\n+\t\tfilenames = new String[pFiles.length];\n+\t\tcontent = new String[pFiles.length];\n+\t\t\n+\t\tfor (int i = 0; i < pFiles.length; i++) {\n+\t\t\tString[] nameAndContent = pFiles[i];\n+\t\t\tfilenames[i] = nameAndContent[0];\n+\t\t\tcontent[i] = nameAndContent[1];\n+\t\t}\n+\t\tp = 0;\n+\t}\n+\t\n+\tpublic ArchiveEntry getNextEntry() throws IOException {\n+\t\tif (p >= filenames.length) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\treturn new MemoryArchiveEntry(filenames[p]);\n+\t}\n+\n+\tpublic String readString() {\n+\t\treturn content[p++];\n+\t}\n+\t\n+\tpublic int read() throws IOException {\n+\t\treturn 0;\n+\t}\n+\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/compress/archivers/memory/MemoryArchiveTestCase.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.archivers.memory;\n+\n+import java.io.IOException;\n+\n+import junit.framework.TestCase;\n+\n+import org.apache.commons.compress.archivers.ArchiveEntry;\n+\n+public final class MemoryArchiveTestCase extends TestCase {\n+\n+\tpublic void testReading() throws IOException {\n+\t\t\n+\t\tfinal MemoryArchiveInputStream is = new MemoryArchiveInputStream(new String[][] {\n+\t\t\t\t{ \"test1\",     \"content1\" },\n+\t\t\t\t{ \"test2\",     \"content2\" },\n+\t\t\t\t});\n+\n+\t\tfinal ArchiveEntry entry1 = is.getNextEntry();\n+\t\tassertNotNull(entry1);\n+\t\tassertEquals(\"test1\", entry1.getName());\n+\t\tfinal String content1 = is.readString();\n+\t\tassertEquals(\"content1\", content1);\n+\t\t\n+\t\tfinal ArchiveEntry entry2 = is.getNextEntry();\n+\t\tassertNotNull(entry2);\n+\t\tassertEquals(\"test2\", entry2.getName());\n+\t\tfinal String content2 = is.readString();\n+\t\tassertEquals(\"content2\", content2);\n+\t\t\n+\t\tfinal ArchiveEntry entry3 = is.getNextEntry();\n+\t\tassertNull(entry3);\n+\t\t\n+\t}\n+\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/compress/changes/ChangeSetTestCase.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.changes;\n+\n+import java.io.IOException;\n+\n+import junit.framework.TestCase;\n+\n+import org.apache.commons.compress.archivers.ArchiveEntry;\n+import org.apache.commons.compress.archivers.ArchiveInputStream;\n+import org.apache.commons.compress.archivers.memory.MemoryArchiveInputStream;\n+\n+public final class ChangeSetTestCase extends TestCase {\n+\n+\tprivate void apply( final ChangeSet cs ) throws IOException {\n+\t\t\n+\t\tfinal ArchiveInputStream is = new MemoryArchiveInputStream(new String[][] {\n+\t\t\t\t{ \"test1\",      \"\" },\n+\t\t\t\t{ \"test2\",      \"\" },\n+\t\t\t\t{ \"dir1/test1\", \"\" },\n+\t\t\t\t{ \"dir1/test2\", \"\" },\n+\t\t\t\t{ \"dir2/test1\", \"\" },\n+\t\t\t\t{ \"dir2/test2\", \"\" }\n+\t\t\t\t});\n+\t\t\n+\t\twhile(true) {\n+\t\t\tfinal ArchiveEntry entry = is.getNextEntry();\n+\t\t\t\n+\t\t\tif (entry == null) {\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t\t\n+\t\t\t// delete, new name, new content\n+\t\t}\n+\t}\n+\t\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/compress/changes/ChangeWorkerTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.changes;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.InputStream;\n+\n+import junit.framework.TestCase;\n+\n+import org.apache.commons.compress.archivers.ArchiveInputStream;\n+import org.apache.commons.compress.archivers.memory.MemoryArchiveInputStream;\n+import org.apache.commons.compress.archivers.*;\n+\n+public class ChangeWorkerTest extends TestCase {\n+\n+\tfinal ArchiveInputStream is = null;\n+\t\n+\tprotected void setUp() throws Exception {\n+\t\tsuper.setUp();\n+\t\tfinal ArchiveInputStream is = new MemoryArchiveInputStream(new String[][] {\n+\t\t\t\t{ \"test1\",      \"\" },\n+\t\t\t\t{ \"test2\",      \"\" },\n+\t\t\t\t{ \"dir1/test1\", \"\" },\n+\t\t\t\t{ \"dir1/test2\", \"\" },\n+\t\t\t\t{ \"dir2/test1\", \"\" },\n+\t\t\t\t{ \"dir2/test2\", \"\" }\n+\t\t\t\t});\n+\t}\n+\n+\tprotected void tearDown() throws Exception {\n+\t\tsuper.tearDown();\n+\t}\n+\n+\tpublic void testPerform() throws Exception {\n+\t\tChangeSet changes = new ChangeSet();\n+\t\tchanges.delete(\"test2.xml\");\n+\t\t\n+\t\tfinal File input = new File(getClass().getClassLoader().getResource(\"bla.zip\").getFile());\n+\t\tfinal InputStream is = new FileInputStream(input);\n+\t\tArchiveInputStream ais = new ArchiveStreamFactory().createArchiveInputStream(\"zip\", is);\n+\t\t\n+\t\tFile temp = File.createTempFile(\"test\", \".zip\");\n+\t\tArchiveOutputStream out = new ArchiveStreamFactory().createArchiveOutputStream(\"zip\", new FileOutputStream(temp));\n+\t\t\n+\t\tSystem.out.println(temp.getAbsolutePath());\n+\t\tChangeWorker.perform(changes, ais, out);\n+\t}\n+\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/compress/compressors/BZip2TestCase.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.compressors;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+\n+import org.apache.commons.compress.AbstractTestCase;\n+import org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;\n+import org.apache.commons.compress.utils.IOUtils;\n+\n+public final class BZip2TestCase extends AbstractTestCase {\n+\tpublic void testBzipCreation()  throws Exception {\n+\t\tfinal File output = new File(dir, \"bla.txt.bz2\");\n+\t\tSystem.out.println(dir);\n+\t\tfinal File file1 = new File(getClass().getClassLoader().getResource(\"test.txt\").getFile());\n+\t\tfinal OutputStream out = new FileOutputStream(output);\n+\t\tCompressorOutputStream cos = new CompressorStreamFactory().createCompressorOutputStream(\"bzip2\", out);\n+\t\tIOUtils.copy(new FileInputStream(file1), cos);\n+\t\tcos.close();\n+\t}\n+\t\n+\tpublic void testBzip2Unarchive() throws Exception {\n+\t\tfinal File output = new File(dir, \"test-entpackt.txt\");\n+\t\tSystem.out.println(dir);\n+\t\tfinal File input = new File(getClass().getClassLoader().getResource(\"bla.txt.bz2\").getFile());\n+        final InputStream is = new FileInputStream(input);\n+        //final CompressorInputStream in = new CompressorStreamFactory().createCompressorInputStream(\"bzip2\", is);\n+        final CompressorInputStream in = new BZip2CompressorInputStream(is);\n+        IOUtils.copy(in, new FileOutputStream(output));\n+\t\tin.close();\n+    }\n+\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/compress/compressors/GZipTestCase.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.compressors;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+\n+import org.apache.commons.compress.AbstractTestCase;\n+import org.apache.commons.compress.utils.IOUtils;\n+\n+public final class GZipTestCase extends AbstractTestCase {\n+\tpublic void testGzipCreation()  throws Exception {\n+\t\tfinal File output = new File(dir, \"bla.gz\");\n+\t\tfinal File file1 = new File(getClass().getClassLoader().getResource(\"test1.xml\").getFile());\n+\t\tfinal OutputStream out = new FileOutputStream(output);\n+\t\tCompressorOutputStream cos = new CompressorStreamFactory().createCompressorOutputStream(\"gz\", out);\n+\t\tIOUtils.copy(new FileInputStream(file1), cos);\n+\t\tcos.close();\n+\t}\n+\t\n+\tpublic void testGzipUnarchive() throws Exception {\n+\t\tfinal File output = new File(dir, \"bla-entpackt.tar\");\n+\t\tfinal File input = new File(getClass().getClassLoader().getResource(\"bla.tgz\").getFile());\n+        final InputStream is = new FileInputStream(input);\n+        final CompressorInputStream in = new CompressorStreamFactory().createCompressorInputStream(\"gz\", is);\n+        IOUtils.copy(in, new FileOutputStream(output));\n+\t\tin.close();\n+    }\n+\n+}", "timestamp": 1223329777, "metainfo": ""}