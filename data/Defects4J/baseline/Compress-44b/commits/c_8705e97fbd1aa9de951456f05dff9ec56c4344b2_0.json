{"sha": "8705e97fbd1aa9de951456f05dff9ec56c4344b2", "log": "trivial fixes of \"bugs\" reported by Sonar", "commit": "\n--- a/src/main/java/org/apache/commons/compress/archivers/cpio/CpioArchiveOutputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/cpio/CpioArchiveOutputStream.java\n         writeAsciiLong(devMin, 8, 16);\n         writeAsciiLong(entry.getRemoteDeviceMaj(), 8, 16);\n         writeAsciiLong(entry.getRemoteDeviceMin(), 8, 16);\n-        writeAsciiLong(entry.getName().length() + 1, 8, 16);\n+        writeAsciiLong(entry.getName().length() + 1l, 8, 16);\n         writeAsciiLong(entry.getChksum(), 8, 16);\n         writeCString(entry.getName());\n         pad(entry.getHeaderPadCount());\n         writeAsciiLong(entry.getNumberOfLinks(), 6, 8);\n         writeAsciiLong(entry.getRemoteDevice(), 6, 8);\n         writeAsciiLong(entry.getTime(), 11, 8);\n-        writeAsciiLong(entry.getName().length() + 1, 6, 8);\n+        writeAsciiLong(entry.getName().length() + 1l, 6, 8);\n         writeAsciiLong(entry.getSize(), 11, 8);\n         writeCString(entry.getName());\n     }\n         writeBinaryLong(entry.getNumberOfLinks(), 2, swapHalfWord);\n         writeBinaryLong(entry.getRemoteDevice(), 2, swapHalfWord);\n         writeBinaryLong(entry.getTime(), 4, swapHalfWord);\n-        writeBinaryLong(entry.getName().length() + 1, 2, swapHalfWord);\n+        writeBinaryLong(entry.getName().length() + 1l, 2, swapHalfWord);\n         writeBinaryLong(entry.getSize(), 4, swapHalfWord);\n         writeCString(entry.getName());\n         pad(entry.getHeaderPadCount());\n         }\n \n         if (tmp.length() <= length) {\n-            final long insertLength = length - tmp.length();\n+            final int insertLength = length - tmp.length();\n             for (int pos = 0; pos < insertLength; pos++) {\n                 tmp.insert(0, \"0\");\n             }\n--- a/src/main/java/org/apache/commons/compress/archivers/dump/DumpArchiveInputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/dump/DumpArchiveInputStream.java\n         }\n \n         // we don't do anything with this yet.\n-        if (raw.skip(DumpArchiveConstants.TP_SIZE * active.getHeaderCount())\n+        if (raw.skip((long) DumpArchiveConstants.TP_SIZE * active.getHeaderCount())\n             == -1) {\n             throw new EOFException();\n         }\n         }\n \n         // we don't do anything with this yet.\n-        if (raw.skip(DumpArchiveConstants.TP_SIZE * active.getHeaderCount())\n+        if (raw.skip((long) DumpArchiveConstants.TP_SIZE * active.getHeaderCount())\n             == -1) {\n             throw new EOFException();\n         }\n \n             // skip any remaining segments for prior file.\n             while (DumpArchiveConstants.SEGMENT_TYPE.ADDR == active.getHeaderType()) {\n-                if (raw.skip(DumpArchiveConstants.TP_SIZE\n+                if (raw.skip((long) DumpArchiveConstants.TP_SIZE\n                              * (active.getHeaderCount()\n                                 - active.getHeaderHoles())) == -1) {\n                     throw new EOFException();\n--- a/src/main/java/org/apache/commons/compress/archivers/dump/TapeInputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/dump/TapeInputStream.java\n \n             if ((readOffset + (len - bytes)) <= blockSize) {\n                 // we can read entirely from the buffer.\n-                n = len - bytes;\n+                n = (long) len - bytes;\n             } else {\n                 // copy what we can from the buffer.\n                 n = blockSize - readOffset;\n--- a/src/main/java/org/apache/commons/compress/archivers/sevenz/SevenZOutputFile.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/sevenz/SevenZOutputFile.java\n \n         writeUint64(header, numCoders);\n         header.write(bos.toByteArray());\n-        for (int i = 0; i < numCoders - 1; i++) {\n+        for (long i = 0; i < numCoders - 1; i++) {\n             writeUint64(header, i + 1);\n             writeUint64(header, i);\n         }\n--- a/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveOutputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveOutputStream.java\n                 // of which are the link's name\n                 final TarArchiveEntry longLinkEntry = new TarArchiveEntry(TarConstants.GNU_LONGLINK, linkType);\n \n-                longLinkEntry.setSize(len + 1); // +1 for NUL\n+                longLinkEntry.setSize(len + 1l); // +1 for NUL\n                 transferModTime(entry, longLinkEntry);\n                 putArchiveEntry(longLinkEntry);\n                 write(encodedName.array(), encodedName.arrayOffset(), len);\n--- a/src/main/java/org/apache/commons/compress/archivers/tar/TarUtils.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarUtils.java\n         if (negative) {\n             // 2's complement\n             val--;\n-            val ^= (long) Math.pow(2, (length - 1) * 8) - 1;\n+            val ^= (long) Math.pow(2.0, (length - 1) * 8) - 1;\n         }\n         return negative ? -val : val;\n     }\n--- a/src/main/java/org/apache/commons/compress/archivers/zip/ParallelScatterZipCreator.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ParallelScatterZipCreator.java\n         }\n \n         es.shutdown();\n-        es.awaitTermination(1000 * 60, TimeUnit.SECONDS);  // == Infinity. We really *must* wait for this to complete\n+        es.awaitTermination(1000 * 60l, TimeUnit.SECONDS);  // == Infinity. We really *must* wait for this to complete\n \n         // It is important that all threads terminate before we go on, ensure happens-before relationship\n         compressionDoneAt = System.currentTimeMillis();\n--- a/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveInputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveInputStream.java\n         // skip over central directory. One LFH has been read too much\n         // already.  The calculation discounts file names and extra\n         // data so it will be too short.\n-        realSkip(entriesRead * CFH_LEN - LFH_LEN);\n+        realSkip((long) entriesRead * CFH_LEN - LFH_LEN);\n         findEocdRecord();\n-        realSkip(ZipFile.MIN_EOCD_SIZE - WORD /* signature */ - SHORT /* comment len */);\n+        realSkip((long) ZipFile.MIN_EOCD_SIZE - WORD /* signature */ - SHORT /* comment len */);\n         readFully(SHORT_BUF);\n         // file comment\n         realSkip(ZipShort.getValue(SHORT_BUF));\n--- a/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveOutputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveOutputStream.java\n                            + DWORD /* number of entries in CD on this disk */\n                            + DWORD /* total number of entries */\n                            + DWORD /* size of CD */\n-                           + DWORD /* offset of CD */\n+                           + (long) DWORD /* offset of CD */\n                            ));\n \n         // version made by and version needed to extract\n--- a/src/main/java/org/apache/commons/compress/archivers/zip/ZipFile.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipFile.java\n         /* last mod file date              */ + SHORT\n         /* crc-32                          */ + WORD\n         /* compressed size                 */ + WORD\n-        /* uncompressed size               */ + WORD;\n+        /* uncompressed size               */ + (long) WORD;\n \n     /**\n      * Walks through all recorded entries and adds the data available\n--- a/src/main/java/org/apache/commons/compress/changes/ChangeSetPerformer.java\n+++ b/src/main/java/org/apache/commons/compress/changes/ChangeSetPerformer.java\n         }\n         @Override\n         public ArchiveEntry next() {\n-            return current = nestedEnum.nextElement();\n+            current = nestedEnum.nextElement();\n+            return current;\n         }\n         @Override\n         public InputStream getInputStream() throws IOException {\n--- a/src/main/java/org/apache/commons/compress/compressors/bzip2/BlockSort.java\n+++ b/src/main/java/org/apache/commons/compress/compressors/bzip2/BlockSort.java\n     private int[] eclass;\n \n     private int[] getEclass() {\n-        return eclass == null\n-            ? (eclass = new int[quadrant.length / 2]) : eclass;\n+        if (eclass == null) {\n+            eclass = new int[quadrant.length / 2];\n+        }\n+        return eclass;\n     }\n \n     /*\n--- a/src/main/java/org/apache/commons/compress/compressors/pack200/Pack200CompressorOutputStream.java\n+++ b/src/main/java/org/apache/commons/compress/compressors/pack200/Pack200CompressorOutputStream.java\n             JarInputStream ji = null;\n             boolean success = false;\n             try {\n-                p.pack(ji = new JarInputStream(streamBridge.getInput()),\n-                       originalOutput);\n+                ji = new JarInputStream(streamBridge.getInput());\n+                p.pack(ji, originalOutput);\n                 success = true;\n             } finally {\n                 if (!success) {\n--- a/src/main/java/org/apache/commons/compress/compressors/snappy/FramedSnappyCompressorInputStream.java\n+++ b/src/main/java/org/apache/commons/compress/compressors/snappy/FramedSnappyCompressorInputStream.java\n             expectedChecksum = unmask(readCrc());\n         } else if (type == COMPRESSED_CHUNK_TYPE) {\n             final boolean expectChecksum = dialect.usesChecksumWithCompressedChunks();\n-            final long size = readSize() - (expectChecksum ? 4 : 0);\n+            final long size = readSize() - (expectChecksum ? 4l : 0l);\n             if (expectChecksum) {\n                 expectedChecksum = unmask(readCrc());\n             } else {", "timestamp": 1482169331, "metainfo": ""}