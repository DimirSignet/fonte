{"sha": "eec10fcf0c795bdfacef4c9933585f65f953fd58", "log": "Writing central directory in chunks instead of one by one  Increased size of copybuf  ", "commit": "\n--- a/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveOutputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveOutputStream.java\n  */\n package org.apache.commons.compress.archivers.zip;\n \n+import java.io.ByteArrayOutputStream;\n import java.io.File;\n import java.io.FileOutputStream;\n import java.io.IOException;\n import java.io.RandomAccessFile;\n import java.nio.ByteBuffer;\n import java.util.HashMap;\n+import java.util.Iterator;\n import java.util.LinkedList;\n import java.util.List;\n import java.util.Map;\n         }\n \n         cdOffset = streamCompressor.getTotalBytesWritten();\n-        for (ZipArchiveEntry ze : entries) {\n-            writeCentralFileHeader(ze);\n-        }\n+        writeCentralDirectoryInChunks();\n+\n         cdLength = streamCompressor.getTotalBytesWritten() - cdOffset;\n         writeZip64CentralDirectory();\n         writeCentralDirectoryEnd();\n         entries.clear();\n         streamCompressor.close();\n         finished = true;\n+    }\n+\n+    private void writeCentralDirectoryInChunks() throws IOException {\n+        int NUM_PER_WRITE = 1000;\n+        ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(70 * NUM_PER_WRITE);\n+        Iterator<ZipArchiveEntry> iterator = entries.iterator();\n+        ZipArchiveEntry ze;\n+        int count = 0;\n+        while (iterator.hasNext()){\n+            ze = iterator.next();\n+            byteArrayOutputStream.write(createCentralFileHeader(ze));\n+            count++;\n+            if (count > NUM_PER_WRITE){\n+                writeCounted( byteArrayOutputStream.toByteArray());\n+                byteArrayOutputStream.reset();\n+                count = 0;\n+            }\n+        }\n+        writeCounted( byteArrayOutputStream.toByteArray());\n     }\n \n     /**\n \n \n \n-    final byte[] copyBuffer = new byte[16384];\n+    final byte[] copyBuffer = new byte[32768];\n \n     private void copyFromZipInputStream(InputStream src) throws IOException {\n         if (entry == null) {\n      * Zip64Mode#Never}.\n      */\n     protected void writeCentralFileHeader(ZipArchiveEntry ze) throws IOException {\n+        byte[] centralFileHeader = createCentralFileHeader(ze);\n+        writeCounted(centralFileHeader);\n+    }\n+\n+    private byte[] createCentralFileHeader(ZipArchiveEntry ze) throws IOException {\n \n         final long lfhOffset = offsets.get(ze).longValue();\n         final boolean needsZip64Extra = hasZip64Extra(ze)\n-            || ze.getCompressedSize() >= ZIP64_MAGIC\n-            || ze.getSize() >= ZIP64_MAGIC\n-            || lfhOffset >= ZIP64_MAGIC;\n+                || ze.getCompressedSize() >= ZIP64_MAGIC\n+                || ze.getSize() >= ZIP64_MAGIC\n+                || lfhOffset >= ZIP64_MAGIC;\n \n         if (needsZip64Extra && zip64Mode == Zip64Mode.Never) {\n             // must be the offset that is too big, otherwise an\n             // exception would have been throw in putArchiveEntry or\n             // closeArchiveEntry\n             throw new Zip64RequiredException(Zip64RequiredException\n-                                             .ARCHIVE_TOO_BIG_MESSAGE);\n+                    .ARCHIVE_TOO_BIG_MESSAGE);\n         }\n \n \n         handleZip64Extra(ze, lfhOffset, needsZip64Extra);\n \n-        byte[] centralFileHeader = createCentralFileHeader(ze, getName(ze), lfhOffset, needsZip64Extra);\n-        writeCounted(centralFileHeader);\n-    }\n+       return createCentralFileHeader(ze, getName(ze), lfhOffset, needsZip64Extra);\n+    };\n \n     /**\n      * Writes the central file header entry.\n         putShort(commentLen, buf, CFH_COMMENT_LENGTH_OFFSET);\n \n         // disk number start\n-        System.arraycopy(ZERO,  0, buf, CFH_DISK_NUMBER_OFFSET, SHORT);\n+        System.arraycopy(ZERO, 0, buf, CFH_DISK_NUMBER_OFFSET, SHORT);\n \n         // internal file attributes\n         putShort(ze.getInternalAttributes(), buf, CFH_INTERNAL_ATTRIBUTES_OFFSET);", "timestamp": 1420665268, "metainfo": ""}