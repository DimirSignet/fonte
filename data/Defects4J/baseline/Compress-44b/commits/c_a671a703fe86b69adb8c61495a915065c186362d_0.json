{"sha": "a671a703fe86b69adb8c61495a915065c186362d", "log": "COMPRESS-234 read/skip performance improvements to TarArchiveInputStream - patch by BELUGA BEHR  ", "commit": "\n--- a/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveInputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveInputStream.java\n import org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\n import org.apache.commons.compress.utils.ArchiveUtils;\n import org.apache.commons.compress.utils.CharsetNames;\n+import org.apache.commons.compress.utils.IOUtils;\n \n /**\n  * The TarInputStream reads a UNIX tar archive as an InputStream.\n  * @NotThreadSafe\n  */\n public class TarArchiveInputStream extends ArchiveInputStream {\n+\n     private static final int SMALL_BUFFER_SIZE = 256;\n-    private static final int BUFFER_SIZE = 8 * 1024;\n-\n-    private final byte[] SKIP_BUF = new byte[BUFFER_SIZE];\n+\n     private final byte[] SMALL_BUF = new byte[SMALL_BUFFER_SIZE];\n \n+    /** The size the TAR header */\n+    private final int recordSize;\n+\n+    /** The size of a block */\n+    private final int blockSize;\n+\n+    /** True if file has hit EOF */\n     private boolean hasHitEOF;\n+\n+    /** Size of the current entry */\n     private long entrySize;\n+\n+    /** How far into the entry the stream is at */\n     private long entryOffset;\n-    private byte[] readBuf;\n-    protected final TarBuffer buffer;\n+\n+    /** An input stream to read from */\n+    private final InputStream is;\n+\n+    /** The meta-data about the current entry */\n     private TarArchiveEntry currEntry;\n+\n+    /** The encoding of the file */\n     private final ZipEncoding encoding;\n \n     /**\n      * @param is the input stream to use\n      */\n     public TarArchiveInputStream(InputStream is) {\n-        this(is, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE);\n+        this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE);\n     }\n \n     /**\n      * @since 1.4\n      */\n     public TarArchiveInputStream(InputStream is, String encoding) {\n-        this(is, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE, encoding);\n+        this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE,\n+             encoding);\n     }\n \n     /**\n      * @param blockSize the block size to use\n      */\n     public TarArchiveInputStream(InputStream is, int blockSize) {\n-        this(is, blockSize, TarBuffer.DEFAULT_RCDSIZE);\n+        this(is, blockSize, TarConstants.DEFAULT_RCDSIZE);\n     }\n \n     /**\n      */\n     public TarArchiveInputStream(InputStream is, int blockSize,\n                                  String encoding) {\n-        this(is, blockSize, TarBuffer.DEFAULT_RCDSIZE, encoding);\n+        this(is, blockSize, TarConstants.DEFAULT_RCDSIZE, encoding);\n     }\n \n     /**\n      * @param recordSize the record size to use\n      */\n     public TarArchiveInputStream(InputStream is, int blockSize, int recordSize) {\n-        this(is, blockSize, recordSize, null);\n+        this(is, blockSize, recordSize, null);      \n     }\n \n     /**\n      */\n     public TarArchiveInputStream(InputStream is, int blockSize, int recordSize,\n                                  String encoding) {\n-        this.buffer = new TarBuffer(is, blockSize, recordSize);\n-        this.readBuf = null;\n+        this.is = is;\n         this.hasHitEOF = false;\n         this.encoding = ZipEncodingHelper.getZipEncoding(encoding);\n+        this.recordSize = recordSize;\n+        this.blockSize = blockSize;\n     }\n \n     /**\n      */\n     @Override\n     public void close() throws IOException {\n-        buffer.close();\n-    }\n-\n-    /**\n-     * Get the record size being used by this stream's TarBuffer.\n+        is.close();\n+    }\n+\n+    /**\n+     * Get the record size being used by this stream's buffer.\n      *\n      * @return The TarBuffer record size.\n      */\n     public int getRecordSize() {\n-        return buffer.getRecordSize();\n+        return recordSize;\n     }\n \n     /**\n      */\n     @Override\n     public long skip(long numToSkip) throws IOException {\n-        // REVIEW\n-        // This is horribly inefficient, but it ensures that we\n-        // properly skip over bytes via the TarBuffer...\n-        //\n-        long skip = numToSkip;\n-        while (skip > 0) {\n-            int realSkip = (int) (skip > SKIP_BUF.length\n-                                  ? SKIP_BUF.length : skip);\n-            int numRead = read(SKIP_BUF, 0, realSkip);\n-            if (numRead == -1) {\n-                break;\n-            }\n-            skip -= numRead;\n-        }\n-        return (numToSkip - skip);\n+\n+        long available = (entrySize - entryOffset);\n+        numToSkip = Math.min(numToSkip, available);\n+\n+        long skipped = IOUtils.skip(is, numToSkip); \n+        count(skipped);\n+        entryOffset += skipped;\n+        return skipped;\n     }\n \n     /**\n         }\n \n         if (currEntry != null) {\n-            long numToSkip = entrySize - entryOffset;\n-\n-            while (numToSkip > 0) {\n-                long skipped = skip(numToSkip);\n-                if (skipped <= 0) {\n-                    throw new RuntimeException(\"failed to skip current tar\"\n-                                               + \" entry\");\n-                }\n-                numToSkip -= skipped;\n-            }\n-\n-            readBuf = null;\n+            /* Skip will only go to the end of the current entry */\n+            skip(Long.MAX_VALUE);\n+\n+            /* skip to the end of the last record */\n+            skipRecordPadding();\n         }\n \n         byte[] headerBuf = getRecord();\n             ioe.initCause(e);\n             throw ioe;\n         }\n+\n         entryOffset = 0;\n         entrySize = currEntry.getSize();\n \n         // information, we update entrySize here so that it contains\n         // the correct value.\n         entrySize = currEntry.getSize();\n+\n         return currEntry;\n+    }\n+    \n+    /**\n+     * The last record block should be written at the full size, so skip any\n+     * additional space used to fill a record after an entry\n+     */\n+    private void skipRecordPadding() throws IOException {\n+        if (this.entrySize > 0 && this.entrySize % this.recordSize != 0) {\n+            long numRecords = (this.entrySize / this.recordSize) + 1;\n+            long padding = (numRecords * this.recordSize) - this.entrySize;\n+            long skipped = IOUtils.skip(is, padding);\n+            count(skipped);\n+        }\n     }\n \n     /**\n      * @throws IOException on error\n      */\n     private byte[] getRecord() throws IOException {\n-        byte[] headerBuf = null;\n-        if (!hasHitEOF) {\n-            headerBuf = buffer.readRecord();\n-            hasHitEOF = buffer.isEOFRecord(headerBuf);\n-            if (hasHitEOF && headerBuf != null) {\n-                buffer.tryToConsumeSecondEOFRecord();\n-                headerBuf = null;\n-            }\n-        }\n-\n+        byte[] headerBuf = readRecord();\n+        hasHitEOF = isEOFRecord(headerBuf);\n+        if (hasHitEOF && headerBuf != null) {\n+            tryToConsumeSecondEOFRecord();\n+            consumeRemainderOfLastBlock();\n+            headerBuf = null;\n+        }\n         return headerBuf;\n+    }\n+\n+    /**\n+     * Determine if an archive record indicate End of Archive. End of\n+     * archive is indicated by a record that consists entirely of null bytes.\n+     *\n+     * @param record The record data to check.\n+     * @return true if the record data is an End of Archive\n+     */\n+    protected boolean isEOFRecord(byte[] record) {\n+        return record == null || ArchiveUtils.isArrayZero(record, recordSize);\n+    }\n+    \n+    /**\n+     * Read a record from the input stream and return the data.\n+     *\n+     * @return The record data or null if EOF has been hit.\n+     * @throws IOException on error\n+     */\n+    protected byte[] readRecord() throws IOException {\n+\n+        byte[] record = new byte[recordSize];\n+\n+        int readNow = is.read(record);\n+        count(readNow);\n+        if (readNow != recordSize) {\n+            return null;\n+        }\n+\n+        return record;\n     }\n \n     private void paxHeaders() throws IOException{\n         }\n     }\n \n+    /**\n+     * Returns the next Archive Entry in this Stream.\n+     *\n+     * @return the next entry,\n+     *         or {@code null} if there are no more entries\n+     * @throws IOException if the next entry could not be read\n+     */\n     @Override\n     public ArchiveEntry getNextEntry() throws IOException {\n         return getNextTarEntry();\n+    }\n+    \n+    /**\n+     * Tries to read the next record rewinding the stream if it is not a EOF record.\n+     *\n+     * <p>This is meant to protect against cases where a tar\n+     * implementation has written only one EOF record when two are\n+     * expected.  Actually this won't help since a non-conforming\n+     * implementation likely won't fill full blocks consisting of - by\n+     * default - ten records either so we probably have already read\n+     * beyond the archive anyway.</p>\n+     */\n+    private void tryToConsumeSecondEOFRecord() throws IOException {\n+        boolean shouldReset = true;\n+        boolean marked = is.markSupported();\n+        if (marked) {\n+            is.mark(recordSize);\n+        }\n+        try {\n+            shouldReset = !isEOFRecord(readRecord());\n+        } finally {\n+            if (shouldReset && marked) {\n+                pushedBackBytes(recordSize);\n+            \tis.reset();\n+            }\n+        }\n     }\n \n     /**\n      */\n     @Override\n     public int read(byte[] buf, int offset, int numToRead) throws IOException {\n-        int totalRead = 0;\n-\n-        if (entryOffset >= entrySize) {\n+    \tint totalRead = 0;\n+\n+        if (hasHitEOF || entryOffset >= entrySize) {\n             return -1;\n         }\n \n-        if ((numToRead + entryOffset) > entrySize) {\n-            numToRead = (int) (entrySize - entryOffset);\n-        }\n-\n-        if (readBuf != null) {\n-            int sz = (numToRead > readBuf.length) ? readBuf.length\n-                : numToRead;\n-\n-            System.arraycopy(readBuf, 0, buf, offset, sz);\n-\n-            if (sz >= readBuf.length) {\n-                readBuf = null;\n-            } else {\n-                int newLen = readBuf.length - sz;\n-                byte[] newBuf = new byte[newLen];\n-\n-                System.arraycopy(readBuf, sz, newBuf, 0, newLen);\n-\n-                readBuf = newBuf;\n-            }\n-\n-            totalRead += sz;\n-            numToRead -= sz;\n-            offset += sz;\n-        }\n-\n-        while (numToRead > 0) {\n-            byte[] rec = buffer.readRecord();\n-\n-            if (rec == null) {\n-                // Unexpected EOF!\n-                throw new IOException(\"unexpected EOF with \" + numToRead\n-                                      + \" bytes unread. Occured at byte: \" + getBytesRead());\n-            }\n-            count(rec.length);\n-            int sz = numToRead;\n-            int recLen = rec.length;\n-\n-            if (recLen > sz) {\n-                System.arraycopy(rec, 0, buf, offset, sz);\n-\n-                readBuf = new byte[recLen - sz];\n-\n-                System.arraycopy(rec, sz, readBuf, 0, recLen - sz);\n-            } else {\n-                sz = recLen;\n-\n-                System.arraycopy(rec, 0, buf, offset, recLen);\n-            }\n-\n-            totalRead += sz;\n-            numToRead -= sz;\n-            offset += sz;\n-        }\n-\n-        entryOffset += totalRead;\n+        numToRead = Math.min(numToRead, available());\n+        \n+        totalRead = is.read(buf, offset, numToRead);\n+        count(totalRead);\n+        \n+        if (totalRead == -1) {\n+            hasHitEOF = true;\n+        } else {\n+            entryOffset += (long) totalRead;\n+        }\n \n         return totalRead;\n     }\n         return false;\n     }\n \n-    protected final TarArchiveEntry getCurrentEntry() {\n+    /**\n+     * Get the current TAR Archive Entry that this input stream is processing\n+     * \n+     * @return The current Archive Entry\n+     */\n+    public ArchiveEntry getCurrentEntry() {\n         return currEntry;\n     }\n \n \n     protected final void setAtEOF(boolean b) {\n         hasHitEOF = b;\n+    }\n+\n+    /**\n+     * This method is invoked once the end of the archive is hit, it\n+     * tries to consume the remaining bytes under the assumption that\n+     * the tool creating this archive has padded the last block.\n+     */\n+    private void consumeRemainderOfLastBlock() throws IOException {\n+        long bytesReadOfLastBlock = getBytesRead() % blockSize;\n+        if (bytesReadOfLastBlock > 0) {\n+            long skipped = IOUtils.skip(is, blockSize - bytesReadOfLastBlock);\n+            count(skipped);\n+        }\n     }\n \n     /**\n--- a/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveOutputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveOutputStream.java\n     private final byte[]    recordBuf;\n     private int       assemLen;\n     private final byte[]    assemBuf;\n-    protected final TarBuffer buffer;\n     private int       longFileMode = LONGFILE_ERROR;\n     private int       bigNumberMode = BIGNUMBER_ERROR;\n+    private int recordsWritten;\n+    private final int recordsPerBlock;\n+    private final int recordSize;\n \n     private boolean closed = false;\n \n      * @param os the output stream to use\n      */\n     public TarArchiveOutputStream(OutputStream os) {\n-        this(os, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE);\n+        this(os, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE);\n     }\n \n     /**\n      * @since 1.4\n      */\n     public TarArchiveOutputStream(OutputStream os, String encoding) {\n-        this(os, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE, encoding);\n+        this(os, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE, encoding);\n     }\n \n     /**\n      * @param blockSize the block size to use\n      */\n     public TarArchiveOutputStream(OutputStream os, int blockSize) {\n-        this(os, blockSize, TarBuffer.DEFAULT_RCDSIZE);\n+        this(os, blockSize, TarConstants.DEFAULT_RCDSIZE);\n     }\n \n     /**\n      */\n     public TarArchiveOutputStream(OutputStream os, int blockSize,\n                                   String encoding) {\n-        this(os, blockSize, TarBuffer.DEFAULT_RCDSIZE, encoding);\n+        this(os, blockSize, TarConstants.DEFAULT_RCDSIZE, encoding);\n     }\n \n     /**\n         out = new CountingOutputStream(os);\n         this.encoding = ZipEncodingHelper.getZipEncoding(encoding);\n \n-        this.buffer = new TarBuffer(out, blockSize, recordSize);\n         this.assemLen = 0;\n         this.assemBuf = new byte[recordSize];\n         this.recordBuf = new byte[recordSize];\n+        this.recordSize = recordSize;\n+        this.recordsPerBlock = blockSize / recordSize;\n     }\n \n     /**\n         }\n         writeEOFRecord();\n         writeEOFRecord();\n-        buffer.flushBlock();\n+        padAsNeeded();\n+        out.flush();\n         finished = true;\n     }\n \n      */\n     @Override\n     public void close() throws IOException {\n-        if(!finished) {\n+        if (!finished) {\n             finish();\n         }\n \n         if (!closed) {\n-            buffer.close();\n             out.close();\n             closed = true;\n         }\n      * @return The TarBuffer record size.\n      */\n     public int getRecordSize() {\n-        return buffer.getRecordSize();\n+        return this.recordSize;\n     }\n \n     /**\n \n         entry.writeEntryHeader(recordBuf, encoding,\n                                bigNumberMode == BIGNUMBER_STAR);\n-        buffer.writeRecord(recordBuf);\n+        writeRecord(recordBuf);\n \n         currBytes = 0;\n \n                 assemBuf[i] = 0;\n             }\n \n-            buffer.writeRecord(assemBuf);\n+            writeRecord(assemBuf);\n \n             currBytes += assemLen;\n             assemLen = 0;\n                                  assemLen);\n                 System.arraycopy(wBuf, wOffset, recordBuf,\n                                  assemLen, aLen);\n-                buffer.writeRecord(recordBuf);\n+                writeRecord(recordBuf);\n \n                 currBytes += recordBuf.length;\n                 wOffset += aLen;\n                 break;\n             }\n \n-            buffer.writeRecord(wBuf, wOffset);\n+            writeRecord(wBuf, wOffset);\n \n             int num = recordBuf.length;\n \n      */\n     private void writeEOFRecord() throws IOException {\n         Arrays.fill(recordBuf, (byte) 0);\n-        buffer.writeRecord(recordBuf);\n+        writeRecord(recordBuf);\n     }\n \n     @Override\n             throw new IOException(\"Stream has already been finished\");\n         }\n         return new TarArchiveEntry(inputFile, entryName);\n+    }\n+    \n+    /**\n+     * Write an archive record to the archive.\n+     *\n+     * @param record The record data to write to the archive.\n+     * @throws IOException on error\n+     */\n+    private void writeRecord(byte[] record) throws IOException {\n+        if (record.length != recordSize) {\n+            throw new IOException(\"record to write has length '\"\n+                                  + record.length\n+                                  + \"' which is not the record size of '\"\n+                                  + recordSize + \"'\");\n+        }\n+\n+        out.write(record);\n+        recordsWritten++;\n+    }\n+    \n+    /**\n+     * Write an archive record to the archive, where the record may be\n+     * inside of a larger array buffer. The buffer must be \"offset plus\n+     * record size\" long.\n+     *\n+     * @param buf The buffer containing the record data to write.\n+     * @param offset The offset of the record data within buf.\n+     * @throws IOException on error\n+     */\n+    private void writeRecord(byte[] buf, int offset) throws IOException {\n+ \n+        if ((offset + recordSize) > buf.length) {\n+            throw new IOException(\"record has length '\" + buf.length\n+                                  + \"' with offset '\" + offset\n+                                  + \"' which is less than the record size of '\"\n+                                  + recordSize + \"'\");\n+        }\n+\n+        out.write(buf, offset, recordSize);\n+        recordsWritten++;\n+    }\n+\n+    private void padAsNeeded() throws IOException {\n+        int start = recordsWritten % recordsPerBlock;\n+        if (start != 0) {\n+            for (int i = start; i < recordsPerBlock; i++) {\n+                writeEOFRecord();\n+            }\n+        }\n     }\n \n     private void addPaxHeadersForBigNumbers(Map<String, String> paxHeaders,\n--- a/src/main/java/org/apache/commons/compress/archivers/tar/TarConstants.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarConstants.java\n // CheckStyle:InterfaceIsTypeCheck OFF (bc)\n public interface TarConstants {\n \n+    /** Default record size */\n+    int DEFAULT_RCDSIZE = (512);\n+\n+    /** Default block size */\n+    int DEFAULT_BLKSIZE = (DEFAULT_RCDSIZE * 20);\n+\n     /**\n      * GNU format as per before tar 1.12.\n      */\n--- a/src/main/java/org/apache/commons/compress/utils/ArchiveUtils.java\n+++ b/src/main/java/org/apache/commons/compress/utils/ArchiveUtils.java\n             final byte[] buffer2, final int offset2, final int length2){\n         return isEqual(buffer1, offset1, length1, buffer2, offset2, length2, true);\n     }\n-\n+    \n+    /**\n+     * Returns true if the first N bytes of an array are all zero\n+     * \n+     * @param a\n+     *            The array to check\n+     * @param size\n+     *            The number of characters to check (not the size of the array)\n+     * @return true if the first N bytes are zero\n+     */\n+    public static boolean isArrayZero(byte[] a, int size) {\n+        for (int i = 0; i < size; i++) {\n+            if (a[i] != 0) {\n+                return false;\n+            }\n+        }\n+        return true;\n+    }\n }\n--- a/src/main/java/org/apache/commons/compress/utils/IOUtils.java\n+++ b/src/main/java/org/apache/commons/compress/utils/IOUtils.java\n         }\n         return count;\n     }\n+    \n+    /**\n+     * Skips the given number of bytes by repeatedly invoking skip on\n+     * the given input stream if necessary.\n+     *\n+     * <p>This method will only skip less than the requested number of\n+     * bytes if the end of the input stream has been reached.</p>\n \n+     * @param input stream to skip bytes in\n+     * @param numToSkip the number of bytes to skip\n+     * @return the number of bytes actually skipped\n+     * @throws IOException\n+     */\n+    public static long skip(InputStream input, long numToSkip) throws IOException {\n+        long available = numToSkip;\n+        while (numToSkip > 0) {\n+            long skipped = input.skip(numToSkip);\n+            if (skipped == 0) {\n+                break;\n+            }\n+            numToSkip -= skipped;\n+        }\n+        return (available - numToSkip);\n+    }\n \n     // toByteArray(InputStream) copied from:\n     // commons/proper/io/trunk/src/main/java/org/apache/commons/io/IOUtils.java?revision=1428941\n--- a/src/test/java/org/apache/commons/compress/archivers/tar/TarArchiveInputStreamTest.java\n+++ b/src/test/java/org/apache/commons/compress/archivers/tar/TarArchiveInputStreamTest.java\n import java.io.ByteArrayInputStream;\n import java.io.ByteArrayOutputStream;\n import java.io.FileInputStream;\n+import java.io.IOException;\n import java.io.InputStream;\n-import java.io.IOException;\n import java.util.Calendar;\n import java.util.Date;\n import java.util.Map;\n \n     @Test\n     public void readSimplePaxHeader() throws Exception {\n-        final TarArchiveInputStream tais = new TarArchiveInputStream(null);\n+        final InputStream is = new ByteArrayInputStream(new byte[1]);\n+        final TarArchiveInputStream tais = new TarArchiveInputStream(is);\n         Map<String, String> headers = tais\n             .parsePaxHeaders(new ByteArrayInputStream(\"30 atime=1321711775.972059463\\n\"\n                                                       .getBytes(CharsetNames.UTF_8)));\n \n     @Test\n     public void readPaxHeaderWithEmbeddedNewline() throws Exception {\n-        final TarArchiveInputStream tais = new TarArchiveInputStream(null);\n+        final InputStream is = new ByteArrayInputStream(new byte[1]);\n+        final TarArchiveInputStream tais = new TarArchiveInputStream(is);\n         Map<String, String> headers = tais\n             .parsePaxHeaders(new ByteArrayInputStream(\"28 comment=line1\\nline2\\nand3\\n\"\n                                                       .getBytes(CharsetNames.UTF_8)));\n         String ae = \"\\u00e4\";\n         String line = \"11 path=\"+ ae + \"\\n\";\n         assertEquals(11, line.getBytes(CharsetNames.UTF_8).length);\n-        final TarArchiveInputStream tais = new TarArchiveInputStream(null);\n+        final InputStream is = new ByteArrayInputStream(new byte[1]);\n+        final TarArchiveInputStream tais = new TarArchiveInputStream(is);\n         Map<String, String> headers = tais\n             .parsePaxHeaders(new ByteArrayInputStream(line.getBytes(CharsetNames.UTF_8)));\n         assertEquals(1, headers.size());\n--- a/src/test/java/org/apache/commons/compress/archivers/tar/TarArchiveOutputStreamTest.java\n+++ b/src/test/java/org/apache/commons/compress/archivers/tar/TarArchiveOutputStreamTest.java\n         tos.closeArchiveEntry();\n         tos.close();\n         // test1.xml is small enough to fit into the default blockv size\n-        assertEquals(TarBuffer.DEFAULT_BLKSIZE, f.length());\n+        assertEquals(TarConstants.DEFAULT_BLKSIZE, f.length());\n     }\n \n }", "timestamp": 1375977475, "metainfo": ""}