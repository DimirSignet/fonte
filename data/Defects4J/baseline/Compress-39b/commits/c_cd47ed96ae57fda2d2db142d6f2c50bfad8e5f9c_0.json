{"sha": "cd47ed96ae57fda2d2db142d6f2c50bfad8e5f9c", "log": "XZ for Java 1.4 has been released, merge the LZMA branch.  ", "commit": "\n--- a/src/main/java/org/apache/commons/compress/archivers/sevenz/Coders.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/sevenz/Coders.java\n import javax.crypto.spec.SecretKeySpec;\n \n import org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;\n+import org.tukaani.xz.LZMAInputStream;\n import org.tukaani.xz.LZMA2InputStream;\n \n class Coders {\n     \n     static CoderId[] coderTable = new CoderId[] {\n         new CoderId(new byte[] { (byte)0x00 }, new CopyDecoder()),\n+        new CoderId(new byte[] { (byte)0x03, (byte)0x01, (byte)0x01 }, new LZMADecoder()),\n         new CoderId(new byte[] { (byte)0x21 }, new LZMA2Decoder()),\n         // FIXME: gives corrupt output\n         //new CoderId(new byte[] { (byte)0x04, (byte)0x01, (byte)0x08 }, new DeflateDecoder()),\n                 dictionarySize = (2 | (dictionarySizeBits & 0x1)) << (dictionarySizeBits / 2 + 11);\n             }\n             return new LZMA2InputStream(in, dictionarySize);\n+        }\n+    }\n+    \n+    static class LZMADecoder extends CoderBase {\n+        @Override\n+        InputStream decode(final InputStream in, final Coder coder,\n+                String password) throws IOException {\n+            byte propsByte = coder.properties[0];\n+            long dictSize = coder.properties[1];\n+            for (int i = 1; i < 4; i++) {\n+                dictSize |= (coder.properties[i + 1] << (8 * i));\n+            }\n+            if (dictSize > LZMAInputStream.DICT_SIZE_MAX) {\n+                throw new IOException(\"Dictionary larger than 4GiB maximum size\");\n+            }\n+            return new LZMAInputStream(in, -1, propsByte, (int) dictSize);\n         }\n     }\n     \n--- a/src/main/java/org/apache/commons/compress/compressors/CompressorStreamFactory.java\n+++ b/src/main/java/org/apache/commons/compress/compressors/CompressorStreamFactory.java\n import org.apache.commons.compress.compressors.bzip2.BZip2CompressorOutputStream;\n import org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream;\n import org.apache.commons.compress.compressors.gzip.GzipCompressorOutputStream;\n+import org.apache.commons.compress.compressors.lzma.LZMACompressorInputStream;\n import org.apache.commons.compress.compressors.xz.XZCompressorInputStream;\n import org.apache.commons.compress.compressors.xz.XZCompressorOutputStream;\n import org.apache.commons.compress.compressors.xz.XZUtils;\n      * @since 1.4\n      */\n     public static final String XZ = \"xz\";\n+\n+    /**\n+     * Constant used to identify the LZMA compression method.\n+     * @since 1.6\n+     */\n+    public static final String LZMA = \"lzma\";\n \n     private boolean decompressConcatenated = false;\n \n     /**\n      * Create a compressor input stream from a compressor name and an input stream.\n      * \n-     * @param name of the compressor, i.e. \"gz\", \"bzip2\", \"xz\", or \"pack200\"\n+     * @param name of the compressor, i.e. \"gz\", \"bzip2\", \"xz\", \"lzma\", or \"pack200\"\n      * @param in the input stream\n      * @return compressor input stream\n      * @throws CompressorException if the compressor name is not known\n \n             if (XZ.equalsIgnoreCase(name)) {\n                 return new XZCompressorInputStream(in);\n+            }\n+\n+            if (LZMA.equalsIgnoreCase(name)) {\n+                return new LZMACompressorInputStream(in);\n             }\n \n             if (PACK200.equalsIgnoreCase(name)) {\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/compress/compressors/lzma/LZMACompressorInputStream.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.compressors.lzma;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import org.tukaani.xz.LZMAInputStream;\n+\n+import org.apache.commons.compress.compressors.CompressorInputStream;\n+\n+/**\n+ * LZMA decompressor.\n+ * @since 1.6\n+ */\n+public class LZMACompressorInputStream extends CompressorInputStream {\n+    private final InputStream in;\n+\n+    /**\n+     * Creates a new input stream that decompresses LZMA-compressed data\n+     * from the specified input stream.\n+     *\n+     * @param       inputStream where to read the compressed data\n+     *\n+     * @throws      IOException if the input is not in the .lzma format,\n+     *                          the input is corrupt or truncated, the .lzma\n+     *                          headers specify sizes that are not supported\n+     *                          by this implementation, or the underlying\n+     *                          <code>inputStream</code> throws an exception\n+     */\n+    public LZMACompressorInputStream(InputStream inputStream)\n+            throws IOException {\n+        in = new LZMAInputStream(inputStream);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    public int read() throws IOException {\n+        int ret = in.read();\n+        count(ret == -1 ? -1 : 1);\n+        return ret;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    public int read(byte[] buf, int off, int len) throws IOException {\n+        int ret = in.read(buf, off, len);\n+        count(ret);\n+        return ret;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    public long skip(long n) throws IOException {\n+        return in.skip(n);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    public int available() throws IOException {\n+        return in.available();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    public void close() throws IOException {\n+        in.close();\n+    }\n+}\n--- a/src/test/java/org/apache/commons/compress/archivers/sevenz/SevenZFileTest.java\n+++ b/src/test/java/org/apache/commons/compress/archivers/sevenz/SevenZFileTest.java\n import org.apache.commons.compress.AbstractTestCase;\n \n public class SevenZFileTest extends AbstractTestCase {\n+    private static String TEST2_CONTENT = \"<?xml version = '1.0'?>\\r\\n<!DOCTYPE\"\n+        + \" connections>\\r\\n<meinxml>\\r\\n\\t<leer />\\r\\n</meinxml>\\n\";\n+\n     public void testAllEmptyFilesArchive() throws Exception {\n         SevenZFile archive = new SevenZFile(getFile(\"7z-empty-mhc-off.7z\"));\n         try {\n \n     public void testHelloWorldHeaderCompressionOffLZMA2() throws Exception {\n         checkHelloWorld(\"7z-hello-mhc-off-lzma2.7z\");\n+    }\n+\n+    public void test7zUnarchive() throws Exception {\n+        SevenZFile sevenZFile = new SevenZFile(getFile(\"bla.7z\"));\n+        try {\n+            SevenZArchiveEntry entry = sevenZFile.getNextEntry();\n+            assertEquals(\"test1.xml\", entry.getName());\n+            entry = sevenZFile.getNextEntry();\n+            assertEquals(\"test2.xml\", entry.getName());\n+            byte[] contents = new byte[(int)entry.getSize()];\n+            int off = 0;\n+            while ((off < contents.length)) {\n+                int bytesRead = sevenZFile.read(contents, off, contents.length - off);\n+                assert(bytesRead >= 0);\n+                off += bytesRead;\n+            }\n+            assertEquals(TEST2_CONTENT, new String(contents, \"UTF-8\"));\n+            assertNull(sevenZFile.getNextEntry());\n+        } finally {\n+            sevenZFile.close();\n+        }\n     }\n \n     private void checkHelloWorld(final String filename) throws Exception {\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/compress/compressors/LZMATestCase.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.commons.compress.compressors;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.InputStream;\n+\n+import org.apache.commons.compress.AbstractTestCase;\n+import org.apache.commons.compress.compressors.lzma.LZMACompressorInputStream;\n+import org.apache.commons.compress.utils.IOUtils;\n+\n+public final class LZMATestCase extends AbstractTestCase {\n+\n+    public void testLZMAUnarchive() throws Exception {\n+        final File input = getFile(\"bla.tar.lzma\");\n+        final File output = new File(dir, \"bla.tar\");\n+        final InputStream is = new FileInputStream(input);\n+        try {\n+            final CompressorInputStream in = new LZMACompressorInputStream(is);\n+            FileOutputStream out = null;\n+            try {\n+                out = new FileOutputStream(output);\n+                IOUtils.copy(in, out);\n+            } finally {\n+                if (out != null) {\n+                    out.close();\n+                }\n+                in.close();\n+            }\n+        } finally {\n+            is.close();\n+        }\n+    }\n+}\n--- a/src/main/java/org/apache/commons/compress/archivers/ArchiveStreamFactory.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/ArchiveStreamFactory.java\n     private String entryEncoding = null;\n \n     /**\n-     * Returns the encoding to use for arj, zip and tar files,\n-     * or null for the default.\n+     * Returns the encoding to use for arj, zip, dump, cpio and tar\n+     * files, or null for the default.\n      *\n      * @return entry encoding, or null\n      * @since 1.5\n     }\n \n     /**\n-     * Sets the encoding to use for arj, zip and tar files.\n-     * Use null for the default.\n+     * Sets the encoding to use for arj, zip, dump, cpio and tar\n+     * files.  Use null for the default.\n      *\n      * @since 1.5\n      */\n             return new JarArchiveInputStream(in);\n         }\n         if (CPIO.equalsIgnoreCase(archiverName)) {\n-            return new CpioArchiveInputStream(in);\n+            if (entryEncoding != null) {\n+                return new CpioArchiveInputStream(in, entryEncoding);\n+            } else {\n+                return new CpioArchiveInputStream(in);\n+            }\n         }\n         if (DUMP.equalsIgnoreCase(archiverName)) {\n-            return new DumpArchiveInputStream(in);\n+            if (entryEncoding != null) {\n+                return new DumpArchiveInputStream(in, entryEncoding);\n+            } else {\n+                return new DumpArchiveInputStream(in);\n+            }\n         }\n \n         throw new ArchiveException(\"Archiver: \" + archiverName + \" not found.\");\n             return new JarArchiveOutputStream(out);\n         }\n         if (CPIO.equalsIgnoreCase(archiverName)) {\n-            return new CpioArchiveOutputStream(out);\n+            if (entryEncoding != null) {\n+                return new CpioArchiveOutputStream(out, entryEncoding);\n+            } else {\n+                return new CpioArchiveOutputStream(out);\n+            }\n         }\n         throw new ArchiveException(\"Archiver: \" + archiverName + \" not found.\");\n     }\n--- a/src/main/java/org/apache/commons/compress/archivers/ar/ArArchiveEntry.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/ar/ArArchiveEntry.java\n              0, 0, DEFAULT_MODE, inputFile.lastModified() / 1000);\n     }\n \n-    /** {@inheritDoc} */\n     public long getSize() {\n         return this.getLength();\n     }\n \n-    /** {@inheritDoc} */\n     public String getName() {\n         return name;\n     }\n         return lastModified;\n     }\n \n-    /** {@inheritDoc} */\n     public Date getLastModifiedDate() {\n         return new Date(1000 * getLastModified());\n     }\n         return length;\n     }\n \n-    /** {@inheritDoc} */\n     public boolean isDirectory() {\n         return false;\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public int hashCode() {\n         final int prime = 31;\n         return result;\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public boolean equals(Object obj) {\n         if (this == obj) {\n--- a/src/main/java/org/apache/commons/compress/archivers/ar/ArArchiveOutputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/ar/ArArchiveOutputStream.java\n         return header.length;\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public void closeArchiveEntry() throws IOException {\n         if(finished) {\n         haveUnclosedEntry = false;\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public void putArchiveEntry( final ArchiveEntry pEntry ) throws IOException {\n         if(finished) {\n         prevEntry = null;\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public ArchiveEntry createArchiveEntry(File inputFile, String entryName)\n             throws IOException {\n         return new ArArchiveEntry(inputFile, entryName);\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public void finish() throws IOException {\n         if(haveUnclosedEntry) {\n--- a/src/main/java/org/apache/commons/compress/archivers/arj/ArjArchiveEntry.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/arj/ArjArchiveEntry.java\n         return new Date(ZipUtil.dosToJavaTime(\n                 0xffffFFFFL & localFileHeader.dateTimeModified));\n     }\n+\n+    /**\n+     * File mode of this entry.\n+     *\n+     * <p>The format depends on the host os that created the entry.</p>\n+     */\n+    public int getMode() {\n+        return localFileHeader.fileAccessMode;\n+    }\n+\n+    /**\n+     * File mode of this entry as Unix stat value.\n+     *\n+     * <p>Will only be non-zero of the host os was UNIX.\n+     */\n+    public int getUnixMode() {\n+        return getHostOs() == HostOs.UNIX ? getMode() : 0;\n+    }\n+\n+    /**\n+     * The operating system the archive has been created on.\n+     * @see HostOs\n+     */\n+    public int getHostOs() {\n+        return localFileHeader.hostOS;\n+    }\n+\n+    /**\n+     * The known values for HostOs.\n+     */\n+    public static class HostOs {\n+        public static final int DOS = 0;\n+        public static final int PRIMOS = 1;\n+        public static final int UNIX = 2;\n+        public static final int AMIGA = 3;\n+        public static final int MAC_OS = 4;\n+        public static final int OS_2 = 5;\n+        public static final int APPLE_GS = 6;\n+        public static final int ATARI_ST = 7;\n+        public static final int NEXT = 8;\n+        public static final int VAX_VMS = 9;\n+        public static final int WIN95 = 10;\n+        public static final int WIN32 = 11;\n+    }\n+    \n }\n--- a/src/main/java/org/apache/commons/compress/archivers/arj/ArjArchiveInputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/arj/ArjArchiveInputStream.java\n         } catch (IOException ignored) {\n         }\n     }\n-    \n-    private static final void debug(final String message) {\n-        if (DEBUG) {\n-            System.out.println(message);\n-        }\n-    }\n-    \n-    private static final int read16(final DataInputStream in) throws IOException {\n+\n+    private static void debug(final String message) {\n+        System.out.println(message);\n+    }\n+\n+    private int read8(final DataInputStream in) throws IOException {\n+        int value = in.readUnsignedByte();\n+        count(1);\n+        return value;\n+    }\n+\n+    private int read16(final DataInputStream in) throws IOException {\n         final int value = in.readUnsignedShort();\n+        count(2);\n         return Integer.reverseBytes(value) >>> 16;\n     }\n-    \n-    private final String readString(final DataInputStream in) throws IOException {\n+\n+    private int read32(final DataInputStream in) throws IOException {\n+        final int value = in.readInt();\n+        count(4);\n+        return Integer.reverseBytes(value);\n+    }\n+    \n+    private String readString(final DataInputStream in) throws IOException {\n         final ByteArrayOutputStream buffer = new ByteArrayOutputStream();\n         int nextByte;\n         while ((nextByte = in.readUnsignedByte()) != 0) {\n             buffer.write(nextByte);\n         }\n-        return new String(buffer.toByteArray(), charset);\n+        if (charset != null) {\n+            return new String(buffer.toByteArray(), charset);\n+        } else {\n+            return new String(buffer.toByteArray());\n+        }\n+    }\n+    \n+    private void readFully(final DataInputStream in, byte[] b)\n+        throws IOException {\n+        in.readFully(b);\n+        count(b.length);\n     }\n     \n     private byte[] readHeader() throws IOException {\n         byte[] basicHeaderBytes = null;\n         do {\n             int first = 0;\n-            int second = in.readUnsignedByte();\n+            int second = read8(in);\n             do {\n                 first = second;\n-                second = in.readUnsignedByte();\n+                second = read8(in);\n             } while (first != ARJ_MAGIC_1 && second != ARJ_MAGIC_2);\n             final int basicHeaderSize = read16(in);\n             if (basicHeaderSize == 0) {\n             }\n             if (basicHeaderSize <= 2600) {\n                 basicHeaderBytes = new byte[basicHeaderSize];\n-                in.readFully(basicHeaderBytes);\n-                final int basicHeaderCrc32 = Integer.reverseBytes(in.readInt());\n+                readFully(in, basicHeaderBytes);\n+                final int basicHeaderCrc32 = read32(in);\n                 final CRC32 crc32 = new CRC32();\n                 crc32.update(basicHeaderBytes);\n                 if (basicHeaderCrc32 == (int)crc32.getValue()) {\n         mainHeader.securityVersion = firstHeader.readUnsignedByte();\n         mainHeader.fileType = firstHeader.readUnsignedByte();\n         mainHeader.reserved = firstHeader.readUnsignedByte();\n-        mainHeader.dateTimeCreated = Integer.reverseBytes(firstHeader.readInt());\n-        mainHeader.dateTimeModified = Integer.reverseBytes(firstHeader.readInt());\n-        mainHeader.archiveSize = 0xffffFFFFL & Integer.reverseBytes(firstHeader.readInt());\n-        mainHeader.securityEnvelopeFilePosition = Integer.reverseBytes(firstHeader.readInt());\n+        mainHeader.dateTimeCreated = read32(firstHeader);\n+        mainHeader.dateTimeModified = read32(firstHeader);\n+        mainHeader.archiveSize = 0xffffFFFFL & read32(firstHeader);\n+        mainHeader.securityEnvelopeFilePosition = read32(firstHeader);\n         mainHeader.fileSpecPosition = read16(firstHeader);\n         mainHeader.securityEnvelopeLength = read16(firstHeader);\n+        pushedBackBytes(20); // count has already counted them via readFully\n         mainHeader.encryptionVersion = firstHeader.readUnsignedByte();\n         mainHeader.lastChapter = firstHeader.readUnsignedByte();\n         \n         final  int extendedHeaderSize = read16(in);\n         if (extendedHeaderSize > 0) {\n             mainHeader.extendedHeaderBytes = new byte[extendedHeaderSize];\n-            in.readFully(mainHeader.extendedHeaderBytes);\n-            final int extendedHeaderCrc32 = Integer.reverseBytes(in.readInt());\n+            readFully(in, mainHeader.extendedHeaderBytes);\n+            final int extendedHeaderCrc32 = read32(in);\n             final CRC32 crc32 = new CRC32();\n             crc32.update(mainHeader.extendedHeaderBytes);\n             if (extendedHeaderCrc32 != (int)crc32.getValue()) {\n             }\n         }\n         \n-        debug(mainHeader.toString());\n+        if (DEBUG) {\n+            debug(mainHeader.toString());\n+        }\n         \n         return mainHeader;\n     }\n         localFileHeader.method = firstHeader.readUnsignedByte();\n         localFileHeader.fileType = firstHeader.readUnsignedByte();\n         localFileHeader.reserved = firstHeader.readUnsignedByte();\n-        localFileHeader.dateTimeModified = Integer.reverseBytes(firstHeader.readInt());\n-        localFileHeader.compressedSize = 0xffffFFFFL & Integer.reverseBytes(firstHeader.readInt());\n-        localFileHeader.originalSize = 0xffffFFFFL & Integer.reverseBytes(firstHeader.readInt());\n-        localFileHeader.originalCrc32 = Integer.reverseBytes(firstHeader.readInt());\n+        localFileHeader.dateTimeModified = read32(firstHeader);\n+        localFileHeader.compressedSize = 0xffffFFFFL & read32(firstHeader);\n+        localFileHeader.originalSize = 0xffffFFFFL & read32(firstHeader);\n+        localFileHeader.originalCrc32 = read32(firstHeader);\n         localFileHeader.fileSpecPosition = read16(firstHeader);\n         localFileHeader.fileAccessMode = read16(firstHeader);\n+        pushedBackBytes(20);\n         localFileHeader.firstChapter = firstHeader.readUnsignedByte();\n         localFileHeader.lastChapter = firstHeader.readUnsignedByte();\n         \n         try {\n-            localFileHeader.extendedFilePosition = Integer.reverseBytes(firstHeader.readInt());\n-            localFileHeader.dateTimeAccessed = Integer.reverseBytes(firstHeader.readInt());\n-            localFileHeader.dateTimeCreated = Integer.reverseBytes(firstHeader.readInt());\n-            localFileHeader.originalSizeEvenForVolumes = Integer.reverseBytes(firstHeader.readInt());\n+            localFileHeader.extendedFilePosition = read32(firstHeader);\n+            localFileHeader.dateTimeAccessed = read32(firstHeader);\n+            localFileHeader.dateTimeCreated = read32(firstHeader);\n+            localFileHeader.originalSizeEvenForVolumes = read32(firstHeader);\n+            pushedBackBytes(16);\n         } catch (EOFException eof) {\n         }\n         \n         int extendedHeaderSize;\n         while ((extendedHeaderSize = read16(in)) > 0) {\n             final byte[] extendedHeaderBytes = new byte[extendedHeaderSize];\n-            in.readFully(extendedHeaderBytes);\n-            final int extendedHeaderCrc32 = Integer.reverseBytes(in.readInt());\n+            readFully(in, extendedHeaderBytes);\n+            final int extendedHeaderCrc32 = read32(in);\n             final CRC32 crc32 = new CRC32();\n             crc32.update(extendedHeaderBytes);\n             if (extendedHeaderCrc32 != (int)crc32.getValue()) {\n         }\n         localFileHeader.extendedHeaders = extendedHeaders.toArray(new byte[extendedHeaders.size()][]);\n         \n-        debug(localFileHeader.toString());\n+        if (DEBUG) {\n+            debug(localFileHeader.toString());\n+        }\n         \n         return localFileHeader;\n     }\n     }\n     \n     @Override\n-    public int read() throws IOException {\n-        if (currentLocalFileHeader.method != LocalFileHeader.Methods.STORED) {\n-            throw new IOException(\"Unsupported compression method \" + currentLocalFileHeader.method);\n-        }\n-        return currentInputStream.read();\n-    }\n-    \n-    @Override\n     public int read(final byte[] b, final int off, final int len) throws IOException {\n         if (currentLocalFileHeader.method != LocalFileHeader.Methods.STORED) {\n             throw new IOException(\"Unsupported compression method \" + currentLocalFileHeader.method);\n--- a/src/main/java/org/apache/commons/compress/archivers/cpio/CpioArchiveEntry.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/cpio/CpioArchiveEntry.java\n         return this.mtime;\n     }\n \n-    /** {@inheritDoc} */\n     public Date getLastModifiedDate() {\n         return new Date(1000 * getTime());\n     }\n      * @return TRUE if this entry is a block device.\n      */\n     public boolean isBlockDevice() {\n-        return (this.mode & S_IFMT) == C_ISBLK;\n+        return CpioUtil.fileType(mode) == C_ISBLK;\n     }\n \n     /**\n      * @return TRUE if this entry is a character device.\n      */\n     public boolean isCharacterDevice() {\n-        return (this.mode & S_IFMT) == C_ISCHR;\n+        return CpioUtil.fileType(mode) == C_ISCHR;\n     }\n \n     /**\n      * @return TRUE if this entry is a directory.\n      */\n     public boolean isDirectory() {\n-        return (this.mode & S_IFMT) == C_ISDIR;\n+        return CpioUtil.fileType(mode) == C_ISDIR;\n     }\n \n     /**\n      * @return TRUE if this entry is a network device.\n      */\n     public boolean isNetwork() {\n-        return (this.mode & S_IFMT) == C_ISNWK;\n+        return CpioUtil.fileType(mode) == C_ISNWK;\n     }\n \n     /**\n      * @return TRUE if this entry is a pipe.\n      */\n     public boolean isPipe() {\n-        return (this.mode & S_IFMT) == C_ISFIFO;\n+        return CpioUtil.fileType(mode) == C_ISFIFO;\n     }\n \n     /**\n      * @return TRUE if this entry is a regular file.\n      */\n     public boolean isRegularFile() {\n-        return (this.mode & S_IFMT) == C_ISREG;\n+        return CpioUtil.fileType(mode) == C_ISREG;\n     }\n \n     /**\n      * @return TRUE if this entry is a socket.\n      */\n     public boolean isSocket() {\n-        return (this.mode & S_IFMT) == C_ISSOCK;\n+        return CpioUtil.fileType(mode) == C_ISSOCK;\n     }\n \n     /**\n      * @return TRUE if this entry is a symbolic link.\n      */\n     public boolean isSymbolicLink() {\n-        return (this.mode & S_IFMT) == C_ISLNK;\n+        return CpioUtil.fileType(mode) == C_ISLNK;\n     }\n \n     /**\n--- a/src/main/java/org/apache/commons/compress/archivers/cpio/CpioArchiveInputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/cpio/CpioArchiveInputStream.java\n \n import org.apache.commons.compress.archivers.ArchiveEntry;\n import org.apache.commons.compress.archivers.ArchiveInputStream;\n+import org.apache.commons.compress.archivers.zip.ZipEncoding;\n+import org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\n import org.apache.commons.compress.utils.ArchiveUtils;\n+import org.apache.commons.compress.utils.CharsetNames;\n \n /**\n  * CPIOArchiveInputStream is a stream for reading cpio streams. All formats of\n  * while ((cpioEntry = cpioIn.getNextEntry()) != null) {\n  *     System.out.println(cpioEntry.getName());\n  *     int tmp;\n- *     StringBuffer buf = new StringBuffer();\n+ *     StringBuilder buf = new StringBuilder();\n  *     while ((tmp = cpIn.read()) != -1) {\n  *         buf.append((char) tmp);\n  *     }\n     private final int blockSize;\n \n     /**\n+     * The encoding to use for filenames and labels.\n+     */\n+    private final ZipEncoding encoding;\n+\n+    /**\n+     * Construct the cpio input stream with a blocksize of {@link\n+     * CpioConstants#BLOCK_SIZE BLOCK_SIZE} and expecting ASCII file\n+     * names.\n+     * \n+     * @param in\n+     *            The cpio stream\n+     */\n+    public CpioArchiveInputStream(final InputStream in) {\n+        this(in, BLOCK_SIZE, CharsetNames.US_ASCII);\n+    }\n+\n+    /**\n      * Construct the cpio input stream with a blocksize of {@link\n      * CpioConstants#BLOCK_SIZE BLOCK_SIZE}.\n      * \n      * @param in\n      *            The cpio stream\n-     */\n-    public CpioArchiveInputStream(final InputStream in) {\n-        this(in, BLOCK_SIZE);\n-    }\n-\n-    /**\n-     * Construct the cpio input stream with a blocksize of {@link CpioConstants#BLOCK_SIZE BLOCK_SIZE}.\n-     * Construct the cpio input stream.\n+     * @param encoding\n+     *            The encoding of file names to expect - use null for\n+     *            the platform's default.\n+     * @since 1.6\n+     */\n+    public CpioArchiveInputStream(final InputStream in, String encoding) {\n+        this(in, BLOCK_SIZE, encoding);\n+    }\n+\n+    /**\n+     * Construct the cpio input stream with a blocksize of {@link\n+     * CpioConstants#BLOCK_SIZE BLOCK_SIZE} expecting ASCII file\n+     * names.\n      * \n      * @param in\n      *            The cpio stream\n      * @since 1.5\n      */\n     public CpioArchiveInputStream(final InputStream in, int blockSize) {\n+        this(in, blockSize, CharsetNames.US_ASCII);\n+    }\n+\n+    /**\n+     * Construct the cpio input stream with a blocksize of {@link CpioConstants#BLOCK_SIZE BLOCK_SIZE}.\n+     * \n+     * @param in\n+     *            The cpio stream\n+     * @param blockSize\n+     *            The block size of the archive.\n+     * @param encoding\n+     *            The encoding of file names to expect - use null for\n+     *            the platform's default.\n+     * @since 1.6\n+     */\n+    public CpioArchiveInputStream(final InputStream in, int blockSize, String encoding) {\n         this.in = in;\n         this.blockSize = blockSize;\n+        this.encoding = ZipEncodingHelper.getZipEncoding(encoding);\n     }\n \n     /**\n \n         ret.setInode(readAsciiLong(8, 16));\n         long mode = readAsciiLong(8, 16);\n-        if (mode != 0){ // mode is initialised to 0\n+        if (CpioUtil.fileType(mode) != 0){ // mode is initialised to 0\n             ret.setMode(mode);\n         }\n         ret.setUID(readAsciiLong(8, 16));\n         ret.setChksum(readAsciiLong(8, 16));\n         String name = readCString((int) namesize);\n         ret.setName(name);\n-        if (mode == 0 && !name.equals(CPIO_TRAILER)){\n+        if (CpioUtil.fileType(mode) == 0 && !name.equals(CPIO_TRAILER)){\n             throw new IOException(\"Mode 0 only allowed in the trailer. Found entry name: \"+name + \" Occured at byte: \" + getBytesRead());\n         }\n         skip(ret.getHeaderPadCount());\n         ret.setDevice(readAsciiLong(6, 8));\n         ret.setInode(readAsciiLong(6, 8));\n         final long mode = readAsciiLong(6, 8);\n-        if (mode != 0) {\n+        if (CpioUtil.fileType(mode) != 0) {\n             ret.setMode(mode);\n         }\n         ret.setUID(readAsciiLong(6, 8));\n         ret.setSize(readAsciiLong(11, 8));\n         final String name = readCString((int) namesize);\n         ret.setName(name);\n-        if (mode == 0 && !name.equals(CPIO_TRAILER)){\n+        if (CpioUtil.fileType(mode) == 0 && !name.equals(CPIO_TRAILER)){\n             throw new IOException(\"Mode 0 only allowed in the trailer. Found entry: \"+ name + \" Occured at byte: \" + getBytesRead());\n         }\n \n         ret.setDevice(readBinaryLong(2, swapHalfWord));\n         ret.setInode(readBinaryLong(2, swapHalfWord));\n         final long mode = readBinaryLong(2, swapHalfWord);\n-        if (mode != 0){\n+        if (CpioUtil.fileType(mode) != 0){\n             ret.setMode(mode);\n         }\n         ret.setUID(readBinaryLong(2, swapHalfWord));\n         ret.setSize(readBinaryLong(4, swapHalfWord));\n         final String name = readCString((int) namesize);\n         ret.setName(name);\n-        if (mode == 0 && !name.equals(CPIO_TRAILER)){\n+        if (CpioUtil.fileType(mode) == 0 && !name.equals(CPIO_TRAILER)){\n             throw new IOException(\"Mode 0 only allowed in the trailer. Found entry: \"+name + \"Occured at byte: \" + getBytesRead());\n         }\n         skip(ret.getHeaderPadCount());\n     }\n \n     private String readCString(final int length) throws IOException {\n-        byte tmpBuffer[] = new byte[length];\n+        // don't include trailing NUL in file name to decode\n+        byte tmpBuffer[] = new byte[length - 1];\n         readFully(tmpBuffer, 0, tmpBuffer.length);\n-        return new String(tmpBuffer, 0, tmpBuffer.length - 1); // TODO default charset?\n+        this.in.read();\n+        return encoding.decode(tmpBuffer);\n     }\n \n     /**\n         return total;\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n-    public ArchiveEntry getNextEntry() throws IOException {\n+    public CpioArchiveEntry getNextEntry() throws IOException {\n         return getNextCPIOEntry();\n     }\n \n--- a/src/main/java/org/apache/commons/compress/archivers/cpio/CpioArchiveOutputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/cpio/CpioArchiveOutputStream.java\n import java.io.File;\n import java.io.IOException;\n import java.io.OutputStream;\n+import java.nio.ByteBuffer;\n import java.util.HashMap;\n \n import org.apache.commons.compress.archivers.ArchiveEntry;\n import org.apache.commons.compress.archivers.ArchiveOutputStream;\n+import org.apache.commons.compress.archivers.zip.ZipEncoding;\n+import org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\n import org.apache.commons.compress.utils.ArchiveUtils;\n+import org.apache.commons.compress.utils.CharsetNames;\n \n /**\n  * CPIOArchiveOutputStream is a stream for writing CPIO streams. All formats of\n     private long nextArtificalDeviceAndInode = 1;\n \n     /**\n-     * Construct the cpio output stream with a specified format and a\n-     * blocksize of {@link CpioConstants#BLOCK_SIZE BLOCK_SIZE}.\n+     * The encoding to use for filenames and labels.\n+     */\n+    private final ZipEncoding encoding;\n+\n+    /**\n+     * Construct the cpio output stream with a specified format, a\n+     * blocksize of {@link CpioConstants#BLOCK_SIZE BLOCK_SIZE} and\n+     * using ASCII as the file name encoding.\n      * \n      * @param out\n      *            The cpio stream\n      *            The format of the stream\n      */\n     public CpioArchiveOutputStream(final OutputStream out, final short format) {\n-        this(out, format, BLOCK_SIZE);\n-    }\n-\n-    /**\n-     * Construct the cpio output stream with a specified format\n+        this(out, format, BLOCK_SIZE, CharsetNames.US_ASCII);\n+    }\n+\n+    /**\n+     * Construct the cpio output stream with a specified format using\n+     * ASCII as the file name encoding.\n      * \n      * @param out\n      *            The cpio stream\n      */\n     public CpioArchiveOutputStream(final OutputStream out, final short format,\n                                    final int blockSize) {\n+        this(out, format, blockSize, CharsetNames.US_ASCII);\n+    }        \n+\n+    /**\n+     * Construct the cpio output stream with a specified format using\n+     * ASCII as the file name encoding.\n+     * \n+     * @param out\n+     *            The cpio stream\n+     * @param format\n+     *            The format of the stream\n+     * @param blockSize\n+     *            The block size of the archive.\n+     * @param encoding\n+     *            The encoding of file names to write - use null for\n+     *            the platform's default.\n+     * \n+     * @since 1.6\n+     */\n+    public CpioArchiveOutputStream(final OutputStream out, final short format,\n+                                   final int blockSize, final String encoding) {\n         this.out = out;\n         switch (format) {\n         case FORMAT_NEW:\n         }\n         this.entryFormat = format;\n         this.blockSize = blockSize;\n+        this.encoding = ZipEncodingHelper.getZipEncoding(encoding);\n     }\n \n     /**\n      * Construct the cpio output stream. The format for this CPIO stream is the\n-     * \"new\" format\n+     * \"new\" format using ASCII encoding for file names\n      * \n      * @param out\n      *            The cpio stream\n      */\n     public CpioArchiveOutputStream(final OutputStream out) {\n         this(out, FORMAT_NEW);\n+    }\n+\n+    /**\n+     * Construct the cpio output stream. The format for this CPIO stream is the\n+     * \"new\" format.\n+     * \n+     * @param out\n+     *            The cpio stream\n+     * @param encoding\n+     *            The encoding of file names to write - use null for\n+     *            the platform's default.\n+     * @since 1.6\n+     */\n+    public CpioArchiveOutputStream(final OutputStream out, String encoding) {\n+        this(out, FORMAT_NEW, BLOCK_SIZE, encoding);\n     }\n \n     /**\n \n     private void writeAsciiLong(final long number, final int length,\n             final int radix) throws IOException {\n-        StringBuffer tmp = new StringBuffer();\n+        StringBuilder tmp = new StringBuilder();\n         String tmpStr;\n         if (radix == 16) {\n             tmp.append(Long.toHexString(number));\n      * @throws IOException if the string couldn't be written\n      */\n     private void writeCString(final String str) throws IOException {\n-        byte[] b = ArchiveUtils.toAsciiBytes(str);\n-        out.write(b);\n+        ByteBuffer buf = encoding.encode(str);\n+        final int len = buf.limit() - buf.position();\n+        out.write(buf.array(), buf.arrayOffset(), len);\n         out.write('\\0');\n-        count(b.length + 1);\n+        count(len + 1);\n     }\n \n     /**\n--- a/src/main/java/org/apache/commons/compress/archivers/cpio/CpioUtil.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/cpio/CpioUtil.java\n  * @Immutable\n  */\n class CpioUtil {\n+\n+    /**\n+     * Extracts the file type bits from a mode.\n+     */\n+    static long fileType(long mode) {\n+        return mode & CpioConstants.S_IFMT;\n+    }\n+\n     /**\n      * Converts a byte array to a long. Halfwords can be swapped by setting\n      * swapHalfWord=true.\n--- a/src/main/java/org/apache/commons/compress/archivers/dump/DumpArchiveEntry.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/dump/DumpArchiveEntry.java\n         this.name = name;\n     }\n \n-    /** {@inheritDoc} */\n     public Date getLastModifiedDate() {\n         return new Date(mtime);\n     }\n--- a/src/main/java/org/apache/commons/compress/archivers/dump/DumpArchiveException.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/dump/DumpArchiveException.java\n     }\n \n     public DumpArchiveException(Throwable cause) {\n-        super();\n         initCause(cause);\n     }\n \n--- a/src/main/java/org/apache/commons/compress/archivers/dump/DumpArchiveInputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/dump/DumpArchiveInputStream.java\n \n import org.apache.commons.compress.archivers.ArchiveException;\n import org.apache.commons.compress.archivers.ArchiveInputStream;\n+import org.apache.commons.compress.archivers.zip.ZipEncoding;\n+import org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\n \n import java.io.EOFException;\n import java.io.IOException;\n  * Methods are provided to position at each successive entry in\n  * the archive, and the read each entry as a normal input stream\n  * using read().\n+ *\n+ * There doesn't seem to exist a hint on the encoding of string values\n+ * in any piece documentation.  Given the main purpose of dump/restore\n+ * is backing up a system it seems very likely the format uses the\n+ * current default encoding of the system.\n  *\n  * @NotThreadSafe\n  */\n     private Queue<DumpArchiveEntry> queue;\n \n     /**\n+     * The encoding to use for filenames and labels.\n+     */\n+    private final ZipEncoding encoding;\n+\n+    /**\n+     * Constructor using the platform's default encoding for file\n+     * names.\n+     *\n+     * @param is\n+     * @throws ArchiveException\n+     */\n+    public DumpArchiveInputStream(InputStream is) throws ArchiveException {\n+        this(is, null);\n+    }\n+\n+    /**\n      * Constructor.\n      *\n      * @param is\n-     * @throws ArchiveException\n-     */\n-    public DumpArchiveInputStream(InputStream is) throws ArchiveException {\n+     * @param encoding the encoding to use for file names, use null\n+     * for the platform's default encoding\n+     * @since 1.6\n+     */\n+    public DumpArchiveInputStream(InputStream is, String encoding)\n+        throws ArchiveException {\n         this.raw = new TapeInputStream(is);\n         this.hasHitEOF = false;\n+        this.encoding = ZipEncodingHelper.getZipEncoding(encoding);\n \n         try {\n             // read header, verify it's a dump archive.\n             }\n \n             // get summary information\n-            summary = new DumpArchiveSummary(headerBytes);\n+            summary = new DumpArchiveSummary(headerBytes, this.encoding);\n \n             // reset buffer with actual block size.\n             raw.resetBlockSize(summary.getNTRec(), summary.isCompressed());\n \n                 byte type = blockBuffer[i + 6];\n \n-                String name = new String(blockBuffer, i + 8, blockBuffer[i + 7]); // TODO default charset?\n+                String name = DumpArchiveUtil.decode(encoding, blockBuffer, i + 8, blockBuffer[i + 7]);\n \n                 if (\".\".equals(name) || \"..\".equals(name)) {\n                     // do nothing...\n--- a/src/main/java/org/apache/commons/compress/archivers/dump/DumpArchiveSummary.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/dump/DumpArchiveSummary.java\n  */\n package org.apache.commons.compress.archivers.dump;\n \n+import java.io.IOException;\n import java.util.Date;\n \n+import org.apache.commons.compress.archivers.zip.ZipEncoding;\n \n /**\n  * This class represents identifying information about a Dump archive volume.\n     private int firstrec;\n     private int ntrec;\n \n-    DumpArchiveSummary(byte[] buffer) {\n+    DumpArchiveSummary(byte[] buffer, ZipEncoding encoding) throws IOException {\n         dumpDate = 1000L * DumpArchiveUtil.convert32(buffer, 4);\n         previousDumpDate = 1000L * DumpArchiveUtil.convert32(buffer, 8);\n         volume = DumpArchiveUtil.convert32(buffer, 12);\n-        label = new String(buffer, 676, DumpArchiveConstants.LBLSIZE).trim(); // TODO default charset?\n+        label = DumpArchiveUtil.decode(encoding, buffer, 676, DumpArchiveConstants.LBLSIZE).trim();\n         level = DumpArchiveUtil.convert32(buffer, 692);\n-        filesys = new String(buffer, 696, DumpArchiveConstants.NAMELEN).trim(); // TODO default charset?\n-        devname = new String(buffer, 760, DumpArchiveConstants.NAMELEN).trim(); // TODO default charset?\n-        hostname = new String(buffer, 824, DumpArchiveConstants.NAMELEN).trim(); // TODO default charset?\n+        filesys = DumpArchiveUtil.decode(encoding, buffer, 696, DumpArchiveConstants.NAMELEN).trim();\n+        devname = DumpArchiveUtil.decode(encoding, buffer, 760, DumpArchiveConstants.NAMELEN).trim();\n+        hostname = DumpArchiveUtil.decode(encoding, buffer, 824, DumpArchiveConstants.NAMELEN).trim();\n         flags = DumpArchiveUtil.convert32(buffer, 888);\n         firstrec = DumpArchiveUtil.convert32(buffer, 892);\n         ntrec = DumpArchiveUtil.convert32(buffer, 896);\n--- a/src/main/java/org/apache/commons/compress/archivers/dump/DumpArchiveUtil.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/dump/DumpArchiveUtil.java\n  */\n package org.apache.commons.compress.archivers.dump;\n \n+import java.io.IOException;\n+import org.apache.commons.compress.archivers.zip.ZipEncoding;\n \n /**\n  * Various utilities for dump archives.\n \n         return i;\n     }\n+\n+    /**\n+     * Decodes a byte array to a string.\n+     */\n+    static String decode(ZipEncoding encoding, byte[] b, int offset, int len)\n+        throws IOException {\n+        byte[] copy = new byte[len];\n+        System.arraycopy(b, offset, copy, 0, len);\n+        return encoding.decode(copy);\n+    }\n }\n--- a/src/main/java/org/apache/commons/compress/archivers/sevenz/SevenZFile.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/sevenz/SevenZFile.java\n \n import org.apache.commons.compress.utils.BoundedInputStream;\n import org.apache.commons.compress.utils.CRC32VerifyingInputStream;\n+import org.apache.commons.compress.utils.CharsetNames;\n \n /**\n  * Reads a 7z file, using RandomAccessFile under\n                         int nextName = 0;\n                         for (int i = 0; i < names.length; i += 2) {\n                             if (names[i] == 0 && names[i+1] == 0) {\n-                                files[nextFile++].setName(new String(names, nextName, i-nextName, \"UTF-16LE\"));\n+                                files[nextFile++].setName(new String(names, nextName, i-nextName, CharsetNames.UTF_16LE));\n                                 nextName = i + 2;\n                             }\n                         }\n--- a/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveEntry.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveEntry.java\n         return new Date(modTime * MILLIS_PER_SECOND);\n     }\n \n-    /** {@inheritDoc} */\n     public Date getLastModifiedDate() {\n         return getModTime();\n     }\n--- a/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveInputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveInputStream.java\n import org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\n import org.apache.commons.compress.utils.ArchiveUtils;\n import org.apache.commons.compress.utils.CharsetNames;\n+import org.apache.commons.compress.utils.IOUtils;\n \n /**\n  * The TarInputStream reads a UNIX tar archive as an InputStream.\n  * @NotThreadSafe\n  */\n public class TarArchiveInputStream extends ArchiveInputStream {\n+\n     private static final int SMALL_BUFFER_SIZE = 256;\n-    private static final int BUFFER_SIZE = 8 * 1024;\n-\n-    private final byte[] SKIP_BUF = new byte[BUFFER_SIZE];\n+\n     private final byte[] SMALL_BUF = new byte[SMALL_BUFFER_SIZE];\n \n+    /** The size the TAR header */\n+    private final int recordSize;\n+\n+    /** The size of a block */\n+    private final int blockSize;\n+\n+    /** True if file has hit EOF */\n     private boolean hasHitEOF;\n+\n+    /** Size of the current entry */\n     private long entrySize;\n+\n+    /** How far into the entry the stream is at */\n     private long entryOffset;\n-    private byte[] readBuf;\n-    protected final TarBuffer buffer;\n+\n+    /** An input stream to read from */\n+    private final InputStream is;\n+\n+    /** The meta-data about the current entry */\n     private TarArchiveEntry currEntry;\n+\n+    /** The encoding of the file */\n     private final ZipEncoding encoding;\n \n     /**\n      * @param is the input stream to use\n      */\n     public TarArchiveInputStream(InputStream is) {\n-        this(is, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE);\n+        this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE);\n     }\n \n     /**\n      * @since 1.4\n      */\n     public TarArchiveInputStream(InputStream is, String encoding) {\n-        this(is, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE, encoding);\n+        this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE,\n+             encoding);\n     }\n \n     /**\n      * @param blockSize the block size to use\n      */\n     public TarArchiveInputStream(InputStream is, int blockSize) {\n-        this(is, blockSize, TarBuffer.DEFAULT_RCDSIZE);\n+        this(is, blockSize, TarConstants.DEFAULT_RCDSIZE);\n     }\n \n     /**\n      */\n     public TarArchiveInputStream(InputStream is, int blockSize,\n                                  String encoding) {\n-        this(is, blockSize, TarBuffer.DEFAULT_RCDSIZE, encoding);\n+        this(is, blockSize, TarConstants.DEFAULT_RCDSIZE, encoding);\n     }\n \n     /**\n      * @param recordSize the record size to use\n      */\n     public TarArchiveInputStream(InputStream is, int blockSize, int recordSize) {\n-        this(is, blockSize, recordSize, null);\n+        this(is, blockSize, recordSize, null);      \n     }\n \n     /**\n      */\n     public TarArchiveInputStream(InputStream is, int blockSize, int recordSize,\n                                  String encoding) {\n-        this.buffer = new TarBuffer(is, blockSize, recordSize);\n-        this.readBuf = null;\n+        this.is = is;\n         this.hasHitEOF = false;\n         this.encoding = ZipEncodingHelper.getZipEncoding(encoding);\n+        this.recordSize = recordSize;\n+        this.blockSize = blockSize;\n     }\n \n     /**\n      */\n     @Override\n     public void close() throws IOException {\n-        buffer.close();\n-    }\n-\n-    /**\n-     * Get the record size being used by this stream's TarBuffer.\n+        is.close();\n+    }\n+\n+    /**\n+     * Get the record size being used by this stream's buffer.\n      *\n      * @return The TarBuffer record size.\n      */\n     public int getRecordSize() {\n-        return buffer.getRecordSize();\n+        return recordSize;\n     }\n \n     /**\n      */\n     @Override\n     public long skip(long numToSkip) throws IOException {\n-        // REVIEW\n-        // This is horribly inefficient, but it ensures that we\n-        // properly skip over bytes via the TarBuffer...\n-        //\n-        long skip = numToSkip;\n-        while (skip > 0) {\n-            int realSkip = (int) (skip > SKIP_BUF.length\n-                                  ? SKIP_BUF.length : skip);\n-            int numRead = read(SKIP_BUF, 0, realSkip);\n-            if (numRead == -1) {\n-                break;\n-            }\n-            skip -= numRead;\n-        }\n-        return (numToSkip - skip);\n+\n+        long available = (entrySize - entryOffset);\n+        numToSkip = Math.min(numToSkip, available);\n+\n+        long skipped = IOUtils.skip(is, numToSkip); \n+        count(skipped);\n+        entryOffset += skipped;\n+        return skipped;\n     }\n \n     /**\n         }\n \n         if (currEntry != null) {\n-            long numToSkip = entrySize - entryOffset;\n-\n-            while (numToSkip > 0) {\n-                long skipped = skip(numToSkip);\n-                if (skipped <= 0) {\n-                    throw new RuntimeException(\"failed to skip current tar\"\n-                                               + \" entry\");\n-                }\n-                numToSkip -= skipped;\n-            }\n-\n-            readBuf = null;\n+            /* Skip will only go to the end of the current entry */\n+            skip(Long.MAX_VALUE);\n+\n+            /* skip to the end of the last record */\n+            skipRecordPadding();\n         }\n \n         byte[] headerBuf = getRecord();\n             ioe.initCause(e);\n             throw ioe;\n         }\n+\n         entryOffset = 0;\n         entrySize = currEntry.getSize();\n \n         // information, we update entrySize here so that it contains\n         // the correct value.\n         entrySize = currEntry.getSize();\n+\n         return currEntry;\n+    }\n+    \n+    /**\n+     * The last record block should be written at the full size, so skip any\n+     * additional space used to fill a record after an entry\n+     */\n+    private void skipRecordPadding() throws IOException {\n+        if (this.entrySize > 0 && this.entrySize % this.recordSize != 0) {\n+            long numRecords = (this.entrySize / this.recordSize) + 1;\n+            long padding = (numRecords * this.recordSize) - this.entrySize;\n+            long skipped = IOUtils.skip(is, padding);\n+            count(skipped);\n+        }\n     }\n \n     /**\n      * @throws IOException on error\n      */\n     private byte[] getRecord() throws IOException {\n-        byte[] headerBuf = null;\n-        if (!hasHitEOF) {\n-            headerBuf = buffer.readRecord();\n-            hasHitEOF = buffer.isEOFRecord(headerBuf);\n-            if (hasHitEOF && headerBuf != null) {\n-                buffer.tryToConsumeSecondEOFRecord();\n-                headerBuf = null;\n-            }\n-        }\n-\n+        byte[] headerBuf = readRecord();\n+        hasHitEOF = isEOFRecord(headerBuf);\n+        if (hasHitEOF && headerBuf != null) {\n+            tryToConsumeSecondEOFRecord();\n+            consumeRemainderOfLastBlock();\n+            headerBuf = null;\n+        }\n         return headerBuf;\n+    }\n+\n+    /**\n+     * Determine if an archive record indicate End of Archive. End of\n+     * archive is indicated by a record that consists entirely of null bytes.\n+     *\n+     * @param record The record data to check.\n+     * @return true if the record data is an End of Archive\n+     */\n+    protected boolean isEOFRecord(byte[] record) {\n+        return record == null || ArchiveUtils.isArrayZero(record, recordSize);\n+    }\n+    \n+    /**\n+     * Read a record from the input stream and return the data.\n+     *\n+     * @return The record data or null if EOF has been hit.\n+     * @throws IOException on error\n+     */\n+    protected byte[] readRecord() throws IOException {\n+\n+        byte[] record = new byte[recordSize];\n+\n+        int readNow = is.read(record);\n+        count(readNow);\n+        if (readNow != recordSize) {\n+            return null;\n+        }\n+\n+        return record;\n     }\n \n     private void paxHeaders() throws IOException{\n         }\n     }\n \n+    /**\n+     * Returns the next Archive Entry in this Stream.\n+     *\n+     * @return the next entry,\n+     *         or {@code null} if there are no more entries\n+     * @throws IOException if the next entry could not be read\n+     */\n     @Override\n     public ArchiveEntry getNextEntry() throws IOException {\n         return getNextTarEntry();\n+    }\n+    \n+    /**\n+     * Tries to read the next record rewinding the stream if it is not a EOF record.\n+     *\n+     * <p>This is meant to protect against cases where a tar\n+     * implementation has written only one EOF record when two are\n+     * expected.  Actually this won't help since a non-conforming\n+     * implementation likely won't fill full blocks consisting of - by\n+     * default - ten records either so we probably have already read\n+     * beyond the archive anyway.</p>\n+     */\n+    private void tryToConsumeSecondEOFRecord() throws IOException {\n+        boolean shouldReset = true;\n+        boolean marked = is.markSupported();\n+        if (marked) {\n+            is.mark(recordSize);\n+        }\n+        try {\n+            shouldReset = !isEOFRecord(readRecord());\n+        } finally {\n+            if (shouldReset && marked) {\n+                pushedBackBytes(recordSize);\n+            \tis.reset();\n+            }\n+        }\n     }\n \n     /**\n      */\n     @Override\n     public int read(byte[] buf, int offset, int numToRead) throws IOException {\n-        int totalRead = 0;\n-\n-        if (entryOffset >= entrySize) {\n+    \tint totalRead = 0;\n+\n+        if (hasHitEOF || entryOffset >= entrySize) {\n             return -1;\n         }\n \n-        if ((numToRead + entryOffset) > entrySize) {\n-            numToRead = (int) (entrySize - entryOffset);\n-        }\n-\n-        if (readBuf != null) {\n-            int sz = (numToRead > readBuf.length) ? readBuf.length\n-                : numToRead;\n-\n-            System.arraycopy(readBuf, 0, buf, offset, sz);\n-\n-            if (sz >= readBuf.length) {\n-                readBuf = null;\n-            } else {\n-                int newLen = readBuf.length - sz;\n-                byte[] newBuf = new byte[newLen];\n-\n-                System.arraycopy(readBuf, sz, newBuf, 0, newLen);\n-\n-                readBuf = newBuf;\n-            }\n-\n-            totalRead += sz;\n-            numToRead -= sz;\n-            offset += sz;\n-        }\n-\n-        while (numToRead > 0) {\n-            byte[] rec = buffer.readRecord();\n-\n-            if (rec == null) {\n-                // Unexpected EOF!\n-                throw new IOException(\"unexpected EOF with \" + numToRead\n-                                      + \" bytes unread. Occured at byte: \" + getBytesRead());\n-            }\n-            count(rec.length);\n-            int sz = numToRead;\n-            int recLen = rec.length;\n-\n-            if (recLen > sz) {\n-                System.arraycopy(rec, 0, buf, offset, sz);\n-\n-                readBuf = new byte[recLen - sz];\n-\n-                System.arraycopy(rec, sz, readBuf, 0, recLen - sz);\n-            } else {\n-                sz = recLen;\n-\n-                System.arraycopy(rec, 0, buf, offset, recLen);\n-            }\n-\n-            totalRead += sz;\n-            numToRead -= sz;\n-            offset += sz;\n-        }\n-\n-        entryOffset += totalRead;\n+        numToRead = Math.min(numToRead, available());\n+        \n+        totalRead = is.read(buf, offset, numToRead);\n+        count(totalRead);\n+        \n+        if (totalRead == -1) {\n+            hasHitEOF = true;\n+        } else {\n+            entryOffset += (long) totalRead;\n+        }\n \n         return totalRead;\n     }\n         return false;\n     }\n \n-    protected final TarArchiveEntry getCurrentEntry() {\n+    /**\n+     * Get the current TAR Archive Entry that this input stream is processing\n+     * \n+     * @return The current Archive Entry\n+     */\n+    public ArchiveEntry getCurrentEntry() {\n         return currEntry;\n     }\n \n \n     protected final void setAtEOF(boolean b) {\n         hasHitEOF = b;\n+    }\n+\n+    /**\n+     * This method is invoked once the end of the archive is hit, it\n+     * tries to consume the remaining bytes under the assumption that\n+     * the tool creating this archive has padded the last block.\n+     */\n+    private void consumeRemainderOfLastBlock() throws IOException {\n+        long bytesReadOfLastBlock = getBytesRead() % blockSize;\n+        if (bytesReadOfLastBlock > 0) {\n+            long skipped = IOUtils.skip(is, blockSize - bytesReadOfLastBlock);\n+            count(skipped);\n+        }\n     }\n \n     /**\n--- a/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveOutputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveOutputStream.java\n     private final byte[]    recordBuf;\n     private int       assemLen;\n     private final byte[]    assemBuf;\n-    protected final TarBuffer buffer;\n     private int       longFileMode = LONGFILE_ERROR;\n     private int       bigNumberMode = BIGNUMBER_ERROR;\n+    private int recordsWritten;\n+    private final int recordsPerBlock;\n+    private final int recordSize;\n \n     private boolean closed = false;\n \n      * @param os the output stream to use\n      */\n     public TarArchiveOutputStream(OutputStream os) {\n-        this(os, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE);\n+        this(os, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE);\n     }\n \n     /**\n      * @since 1.4\n      */\n     public TarArchiveOutputStream(OutputStream os, String encoding) {\n-        this(os, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE, encoding);\n+        this(os, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE, encoding);\n     }\n \n     /**\n      * @param blockSize the block size to use\n      */\n     public TarArchiveOutputStream(OutputStream os, int blockSize) {\n-        this(os, blockSize, TarBuffer.DEFAULT_RCDSIZE);\n+        this(os, blockSize, TarConstants.DEFAULT_RCDSIZE);\n     }\n \n     /**\n      */\n     public TarArchiveOutputStream(OutputStream os, int blockSize,\n                                   String encoding) {\n-        this(os, blockSize, TarBuffer.DEFAULT_RCDSIZE, encoding);\n+        this(os, blockSize, TarConstants.DEFAULT_RCDSIZE, encoding);\n     }\n \n     /**\n         out = new CountingOutputStream(os);\n         this.encoding = ZipEncodingHelper.getZipEncoding(encoding);\n \n-        this.buffer = new TarBuffer(out, blockSize, recordSize);\n         this.assemLen = 0;\n         this.assemBuf = new byte[recordSize];\n         this.recordBuf = new byte[recordSize];\n+        this.recordSize = recordSize;\n+        this.recordsPerBlock = blockSize / recordSize;\n     }\n \n     /**\n         }\n         writeEOFRecord();\n         writeEOFRecord();\n-        buffer.flushBlock();\n+        padAsNeeded();\n+        out.flush();\n         finished = true;\n     }\n \n      */\n     @Override\n     public void close() throws IOException {\n-        if(!finished) {\n+        if (!finished) {\n             finish();\n         }\n \n         if (!closed) {\n-            buffer.close();\n             out.close();\n             closed = true;\n         }\n      * @return The TarBuffer record size.\n      */\n     public int getRecordSize() {\n-        return buffer.getRecordSize();\n+        return this.recordSize;\n     }\n \n     /**\n         TarArchiveEntry entry = (TarArchiveEntry) archiveEntry;\n         Map<String, String> paxHeaders = new HashMap<String, String>();\n         final String entryName = entry.getName();\n-        final ByteBuffer encodedName = encoding.encode(entryName);\n-        final int nameLen = encodedName.limit() - encodedName.position();\n-        boolean paxHeaderContainsPath = false;\n-        if (nameLen >= TarConstants.NAMELEN) {\n-\n-            if (longFileMode == LONGFILE_POSIX) {\n-                paxHeaders.put(\"path\", entryName);\n-                paxHeaderContainsPath = true;\n-            } else if (longFileMode == LONGFILE_GNU) {\n-                // create a TarEntry for the LongLink, the contents\n-                // of which are the entry's name\n-                TarArchiveEntry longLinkEntry = new TarArchiveEntry(TarConstants.GNU_LONGLINK,\n-                                                                    TarConstants.LF_GNUTYPE_LONGNAME);\n-\n-                longLinkEntry.setSize(nameLen + 1); // +1 for NUL\n-                putArchiveEntry(longLinkEntry);\n-                write(encodedName.array(), encodedName.arrayOffset(), nameLen);\n-                write(0); // NUL terminator\n-                closeArchiveEntry();\n-            } else if (longFileMode != LONGFILE_TRUNCATE) {\n-                throw new RuntimeException(\"file name '\" + entryName\n-                                           + \"' is too long ( > \"\n-                                           + TarConstants.NAMELEN + \" bytes)\");\n-            }\n-        }\n+        boolean paxHeaderContainsPath = handleLongName(entryName, paxHeaders, \"path\",\n+                                                       TarConstants.LF_GNUTYPE_LONGNAME, \"file name\");\n+\n+        final String linkName = entry.getLinkName();\n+        boolean paxHeaderContainsLinkPath = linkName != null && linkName.length() > 0\n+            && handleLongName(linkName, paxHeaders, \"linkpath\",\n+                              TarConstants.LF_GNUTYPE_LONGLINK, \"link name\");\n \n         if (bigNumberMode == BIGNUMBER_POSIX) {\n             addPaxHeadersForBigNumbers(paxHeaders, entry);\n             paxHeaders.put(\"path\", entryName);\n         }\n \n-        if (addPaxHeadersForNonAsciiNames\n+        if (addPaxHeadersForNonAsciiNames && !paxHeaderContainsLinkPath\n             && (entry.isLink() || entry.isSymbolicLink())\n-            && !ASCII.canEncode(entry.getLinkName())) {\n-            paxHeaders.put(\"linkpath\", entry.getLinkName());\n+            && !ASCII.canEncode(linkName)) {\n+            paxHeaders.put(\"linkpath\", linkName);\n         }\n \n         if (paxHeaders.size() > 0) {\n \n         entry.writeEntryHeader(recordBuf, encoding,\n                                bigNumberMode == BIGNUMBER_STAR);\n-        buffer.writeRecord(recordBuf);\n+        writeRecord(recordBuf);\n \n         currBytes = 0;\n \n                 assemBuf[i] = 0;\n             }\n \n-            buffer.writeRecord(assemBuf);\n+            writeRecord(assemBuf);\n \n             currBytes += assemLen;\n             assemLen = 0;\n                                  assemLen);\n                 System.arraycopy(wBuf, wOffset, recordBuf,\n                                  assemLen, aLen);\n-                buffer.writeRecord(recordBuf);\n+                writeRecord(recordBuf);\n \n                 currBytes += recordBuf.length;\n                 wOffset += aLen;\n                 break;\n             }\n \n-            buffer.writeRecord(wBuf, wOffset);\n+            writeRecord(wBuf, wOffset);\n \n             int num = recordBuf.length;\n \n \n     private String stripTo7Bits(String name) {\n         final int length = name.length();\n-        StringBuffer result = new StringBuffer(length);\n+        StringBuilder result = new StringBuilder(length);\n         for (int i = 0; i < length; i++) {\n             char stripped = (char) (name.charAt(i) & 0x7F);\n             if (stripped != 0) { // would be read as Trailing null\n      */\n     private void writeEOFRecord() throws IOException {\n         Arrays.fill(recordBuf, (byte) 0);\n-        buffer.writeRecord(recordBuf);\n+        writeRecord(recordBuf);\n     }\n \n     @Override\n         out.flush();\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public ArchiveEntry createArchiveEntry(File inputFile, String entryName)\n             throws IOException {\n             throw new IOException(\"Stream has already been finished\");\n         }\n         return new TarArchiveEntry(inputFile, entryName);\n+    }\n+    \n+    /**\n+     * Write an archive record to the archive.\n+     *\n+     * @param record The record data to write to the archive.\n+     * @throws IOException on error\n+     */\n+    private void writeRecord(byte[] record) throws IOException {\n+        if (record.length != recordSize) {\n+            throw new IOException(\"record to write has length '\"\n+                                  + record.length\n+                                  + \"' which is not the record size of '\"\n+                                  + recordSize + \"'\");\n+        }\n+\n+        out.write(record);\n+        recordsWritten++;\n+    }\n+    \n+    /**\n+     * Write an archive record to the archive, where the record may be\n+     * inside of a larger array buffer. The buffer must be \"offset plus\n+     * record size\" long.\n+     *\n+     * @param buf The buffer containing the record data to write.\n+     * @param offset The offset of the record data within buf.\n+     * @throws IOException on error\n+     */\n+    private void writeRecord(byte[] buf, int offset) throws IOException {\n+ \n+        if ((offset + recordSize) > buf.length) {\n+            throw new IOException(\"record has length '\" + buf.length\n+                                  + \"' with offset '\" + offset\n+                                  + \"' which is less than the record size of '\"\n+                                  + recordSize + \"'\");\n+        }\n+\n+        out.write(buf, offset, recordSize);\n+        recordsWritten++;\n+    }\n+\n+    private void padAsNeeded() throws IOException {\n+        int start = recordsWritten % recordsPerBlock;\n+        if (start != 0) {\n+            for (int i = start; i < recordsPerBlock; i++) {\n+                writeEOFRecord();\n+            }\n+        }\n     }\n \n     private void addPaxHeadersForBigNumbers(Map<String, String> paxHeaders,\n                                        + maxValue + \" )\");\n         }\n     }\n+\n+    /**\n+     * Handles long file or link names according to the longFileMode setting.\n+     *\n+     * <p>I.e. if the given name is too long to be written to a plain\n+     * tar header then\n+     * <ul>\n+     *   <li>it creates a pax header who's name is given by the\n+     *   paxHeaderName parameter if longFileMode is POSIX</li>\n+     *   <li>it creates a GNU longlink entry who's type is given by\n+     *   the linkType parameter if longFileMode is GNU</li>\n+     *   <li>it throws an exception if longFileMode is ERROR</li>\n+     *   <li>it truncates the name if longFileMode is TRUNCATE</li>\n+     * </ul></p>\n+     *\n+     * @param name the name to write\n+     * @param paxHeaders current map of pax headers\n+     * @param paxHeaderName name of the pax header to write\n+     * @param linkType type of the GNU entry to write\n+     * @param fieldName the name of the field\n+     * @return whether a pax header has been written.\n+     */\n+    private boolean handleLongName(String name,\n+                                   Map<String, String> paxHeaders,\n+                                   String paxHeaderName, byte linkType, String fieldName)\n+        throws IOException {\n+        final ByteBuffer encodedName = encoding.encode(name);\n+        final int len = encodedName.limit() - encodedName.position();\n+        if (len >= TarConstants.NAMELEN) {\n+\n+            if (longFileMode == LONGFILE_POSIX) {\n+                paxHeaders.put(paxHeaderName, name);\n+                return true;\n+            } else if (longFileMode == LONGFILE_GNU) {\n+                // create a TarEntry for the LongLink, the contents\n+                // of which are the link's name\n+                TarArchiveEntry longLinkEntry = new TarArchiveEntry(TarConstants.GNU_LONGLINK, linkType);\n+\n+                longLinkEntry.setSize(len + 1); // +1 for NUL\n+                putArchiveEntry(longLinkEntry);\n+                write(encodedName.array(), encodedName.arrayOffset(), len);\n+                write(0); // NUL terminator\n+                closeArchiveEntry();\n+            } else if (longFileMode != LONGFILE_TRUNCATE) {\n+                throw new RuntimeException(fieldName + \" '\" + name\n+                                           + \"' is too long ( > \"\n+                                           + TarConstants.NAMELEN + \" bytes)\");\n+            }\n+        }\n+        return false;\n+    }\n }\n--- a/src/main/java/org/apache/commons/compress/archivers/tar/TarConstants.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarConstants.java\n // CheckStyle:InterfaceIsTypeCheck OFF (bc)\n public interface TarConstants {\n \n+    /** Default record size */\n+    int DEFAULT_RCDSIZE = (512);\n+\n+    /** Default block size */\n+    int DEFAULT_BLKSIZE = (DEFAULT_RCDSIZE * 20);\n+\n     /**\n      * GNU format as per before tar 1.12.\n      */\n--- a/src/main/java/org/apache/commons/compress/archivers/tar/TarUtils.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarUtils.java\n \n             public String decode(byte[] buffer) {\n                 final int length = buffer.length;\n-                StringBuffer result = new StringBuffer(length);\n+                StringBuilder result = new StringBuilder(length);\n \n                 for (int i = 0; i < length; ++i) {\n                     byte b = buffer[i];\n     // Helper method to generate the exception message\n     private static String exceptionMessage(byte[] buffer, final int offset,\n             final int length, int current, final byte currentByte) {\n-        String string = new String(buffer, offset, length); // TODO default charset?\n+        // default charset is good enough for an exception message,\n+        //\n+        // the alternative was to modify parseOctal and\n+        // parseOctalOrBinary to receive the ZipEncoding of the\n+        // archive (deprecating the existing public methods, of\n+        // course) and dealing with the fact that ZipEncoding#decode\n+        // can throw an IOException which parseOctal* doesn't declare\n+        String string = new String(buffer, offset, length);\n+\n         string=string.replaceAll(\"\\0\", \"{NUL}\"); // Replace NULs to allow string to be printed\n         final String s = \"Invalid byte \"+currentByte+\" at offset \"+(current-offset)+\" in '\"+string+\"' len=\"+length;\n         return s;\n--- a/src/main/java/org/apache/commons/compress/archivers/zip/AbstractUnicodeExtraField.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/AbstractUnicodeExtraField.java\n         data = null;\n     }\n \n-    /** {@inheritDoc} */\n     public byte[] getCentralDirectoryData() {\n         if (data == null) {\n             this.assembleData();\n         return b;\n     }\n \n-    /** {@inheritDoc} */\n     public ZipShort getCentralDirectoryLength() {\n         if (data == null) {\n             assembleData();\n         return new ZipShort(data.length);\n     }\n \n-    /** {@inheritDoc} */\n     public byte[] getLocalFileDataData() {\n         return getCentralDirectoryData();\n     }\n \n-    /** {@inheritDoc} */\n     public ZipShort getLocalFileDataLength() {\n         return getCentralDirectoryLength();\n     }\n \n-    /** {@inheritDoc} */\n     public void parseFromLocalFileData(byte[] buffer, int offset, int length)\n         throws ZipException {\n \n--- a/src/main/java/org/apache/commons/compress/archivers/zip/UnicodeCommentExtraField.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/UnicodeCommentExtraField.java\n         super(comment, bytes);\n     }\n \n-    /** {@inheritDoc} */\n     public ZipShort getHeaderId() {\n         return UCOM_ID;\n     }\n--- a/src/main/java/org/apache/commons/compress/archivers/zip/UnicodePathExtraField.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/UnicodePathExtraField.java\n         super(name, bytes);\n     }\n \n-    /** {@inheritDoc} */\n     public ZipShort getHeaderId() {\n         return UPATH_ID;\n     }\n--- a/src/main/java/org/apache/commons/compress/archivers/zip/Zip64ExtendedInformationExtraField.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/Zip64ExtendedInformationExtraField.java\n         this.diskStart = diskStart;\n     }\n \n-    /** {@inheritDoc} */\n     public ZipShort getHeaderId() {\n         return HEADER_ID;\n     }\n \n-    /** {@inheritDoc} */\n     public ZipShort getLocalFileDataLength() {\n         return new ZipShort(size != null ? 2 * DWORD : 0);\n     }\n \n-    /** {@inheritDoc} */\n     public ZipShort getCentralDirectoryLength() {\n         return new ZipShort((size != null ? DWORD : 0)\n                             + (compressedSize != null ? DWORD : 0)\n                             + (diskStart != null ? WORD : 0));\n     }\n \n-    /** {@inheritDoc} */\n     public byte[] getLocalFileDataData() {\n         if (size != null || compressedSize != null) {\n             if (size == null || compressedSize == null) {\n         return EMPTY;\n     }\n \n-    /** {@inheritDoc} */\n     public byte[] getCentralDirectoryData() {\n         byte[] data = new byte[getCentralDirectoryLength().getValue()];\n         int off = addSizes(data);\n         return data;\n     }\n \n-    /** {@inheritDoc} */\n     public void parseFromLocalFileData(byte[] buffer, int offset, int length)\n         throws ZipException {\n         if (length == 0) {\n         }\n     }\n \n-    /** {@inheritDoc} */\n     public void parseFromCentralDirectoryData(byte[] buffer, int offset,\n                                               int length)\n         throws ZipException {\n--- a/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveEntry.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveEntry.java\n         }\n     }\n \n-    /** {@inheritDoc} */\n     public Date getLastModifiedDate() {\n         return new Date(getTime());\n     }\n--- a/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveInputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveInputStream.java\n         }\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public ArchiveEntry getNextEntry() throws IOException {\n         return getNextZipEntry();\n--- a/src/main/java/org/apache/commons/compress/compressors/FileNameUtil.java\n+++ b/src/main/java/org/apache/commons/compress/compressors/FileNameUtil.java\n \n     /**\n      * Maps the given filename to the name that the file should have after\n-     * compressio. Common file types with custom suffixes for\n+     * compression. Common file types with custom suffixes for\n      * compressed versions are automatically detected and correctly mapped.\n      * For example the name \"package.tar\" is mapped to \"package.tgz\". If no\n      * custom mapping is applicable, then the default \".gz\" suffix is appended\n--- a/src/main/java/org/apache/commons/compress/compressors/bzip2/BZip2CompressorInputStream.java\n+++ b/src/main/java/org/apache/commons/compress/compressors/bzip2/BZip2CompressorInputStream.java\n      * @throws NullPointerException\n      *             if <tt>in == null</tt>\n      */\n-    public BZip2CompressorInputStream(final InputStream in,\n-                                      final boolean decompressConcatenated)\n-            throws IOException {\n-        super();\n-\n+    public BZip2CompressorInputStream(final InputStream in, final boolean decompressConcatenated) throws IOException {\n         this.in = in;\n         this.decompressConcatenated = decompressConcatenated;\n \n         setupBlock();\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public int read() throws IOException {\n         if (this.in != null) {\n         // ===============\n \n         Data(int blockSize100k) {\n-            super();\n-\n             this.ll8 = new byte[blockSize100k * BZip2Constants.BASEBLOCKSIZE];\n         }\n \n--- a/src/main/java/org/apache/commons/compress/compressors/bzip2/BZip2CompressorOutputStream.java\n+++ b/src/main/java/org/apache/commons/compress/compressors/bzip2/BZip2CompressorOutputStream.java\n      * @see #MIN_BLOCKSIZE\n      * @see #MAX_BLOCKSIZE\n      */\n-    public BZip2CompressorOutputStream(final OutputStream out,\n-                                       final int blockSize)\n-        throws IOException {\n-        super();\n-\n+    public BZip2CompressorOutputStream(final OutputStream out, final int blockSize) throws IOException {\n         if (blockSize < 1) {\n-            throw new IllegalArgumentException(\"blockSize(\" + blockSize\n-                                               + \") < 1\");\n+            throw new IllegalArgumentException(\"blockSize(\" + blockSize + \") < 1\");\n         }\n         if (blockSize > 9) {\n-            throw new IllegalArgumentException(\"blockSize(\" + blockSize\n-                                               + \") > 9\");\n+            throw new IllegalArgumentException(\"blockSize(\" + blockSize + \") > 9\");\n         }\n \n         this.blockSize100k = blockSize;\n         init();\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public void write(final int b) throws IOException {\n         if (this.out != null) {\n         int origPtr;\n \n         Data(int blockSize100k) {\n-            super();\n-\n             final int n = blockSize100k * BZip2Constants.BASEBLOCKSIZE;\n             this.block = new byte[(n + 1 + NUM_OVERSHOOT_BYTES)];\n             this.fmap = new int[n];\n--- a/src/main/java/org/apache/commons/compress/compressors/gzip/GzipCompressorInputStream.java\n+++ b/src/main/java/org/apache/commons/compress/compressors/gzip/GzipCompressorInputStream.java\n         while (inData.readUnsignedByte() != 0x00) {}\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public int read() throws IOException {\n         return read(oneByte, 0, 1) == -1 ? -1 : (oneByte[0] & 0xFF);\n--- a/src/main/java/org/apache/commons/compress/compressors/gzip/GzipCompressorOutputStream.java\n+++ b/src/main/java/org/apache/commons/compress/compressors/gzip/GzipCompressorOutputStream.java\n         out = new GZIPOutputStream(outputStream);\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public void write(int b) throws IOException {\n         out.write(b);\n--- a/src/main/java/org/apache/commons/compress/compressors/pack200/InMemoryCachingStreamBridge.java\n+++ b/src/main/java/org/apache/commons/compress/compressors/pack200/InMemoryCachingStreamBridge.java\n         super(new ByteArrayOutputStream());\n     }\n \n-    /**\n-     * {@inheritDoc}\n-     */\n     @Override\n     InputStream getInputView() throws IOException {\n         return new ByteArrayInputStream(((ByteArrayOutputStream) out)\n--- a/src/main/java/org/apache/commons/compress/compressors/pack200/Pack200CompressorInputStream.java\n+++ b/src/main/java/org/apache/commons/compress/compressors/pack200/Pack200CompressorInputStream.java\n         jarOut.close();\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public int read() throws IOException {\n         return streamBridge.getInput().read();\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public int read(byte[] b) throws IOException {\n         return streamBridge.getInput().read(b);\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public int read(byte[] b, int off, int count) throws IOException {\n         return streamBridge.getInput().read(b, off, count);\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public int available() throws IOException {\n         return streamBridge.getInput().available();\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public boolean markSupported() {\n         try {\n         }\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public void mark(int limit) {\n         try {\n         }\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public void reset() throws IOException {\n         streamBridge.getInput().reset();\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public long skip(long count) throws IOException {\n         return streamBridge.getInput().skip(count);\n--- a/src/main/java/org/apache/commons/compress/compressors/pack200/Pack200CompressorOutputStream.java\n+++ b/src/main/java/org/apache/commons/compress/compressors/pack200/Pack200CompressorOutputStream.java\n         properties = props;\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public void write(int b) throws IOException {\n         streamBridge.write(b);\n     }\n \n-    /**\n-     * {@inheritDoc}\n-     */\n     @Override\n     public void write(byte[] b) throws IOException {\n         streamBridge.write(b);\n     }\n \n-    /**\n-     * {@inheritDoc}\n-     */\n     @Override\n     public void write(byte[] b, int from, int length) throws IOException {\n         streamBridge.write(b, from, length);\n--- a/src/main/java/org/apache/commons/compress/compressors/pack200/TempFileCachingStreamBridge.java\n+++ b/src/main/java/org/apache/commons/compress/compressors/pack200/TempFileCachingStreamBridge.java\n         out = new FileOutputStream(f);\n     }\n \n-    /**\n-     * {@inheritDoc}\n-     */\n     @Override\n     InputStream getInputView() throws IOException {\n         out.close();\n--- a/src/main/java/org/apache/commons/compress/compressors/xz/XZCompressorInputStream.java\n+++ b/src/main/java/org/apache/commons/compress/compressors/xz/XZCompressorInputStream.java\n         }\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public int read() throws IOException {\n         int ret = in.read();\n         return ret;\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public int read(byte[] buf, int off, int len) throws IOException {\n         int ret = in.read(buf, off, len);\n         return ret;\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public long skip(long n) throws IOException {\n         return in.skip(n);\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public int available() throws IOException {\n         return in.available();\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public void close() throws IOException {\n         in.close();\n--- a/src/main/java/org/apache/commons/compress/compressors/xz/XZCompressorOutputStream.java\n+++ b/src/main/java/org/apache/commons/compress/compressors/xz/XZCompressorOutputStream.java\n         out = new XZOutputStream(outputStream, new LZMA2Options(preset));\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public void write(int b) throws IOException {\n         out.write(b);\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public void write(byte[] buf, int off, int len) throws IOException {\n         out.write(buf, off, len);\n         out.finish();\n     }\n \n-    /** {@inheritDoc} */\n     @Override\n     public void close() throws IOException {\n         out.close();\n--- a/src/main/java/org/apache/commons/compress/utils/ArchiveUtils.java\n+++ b/src/main/java/org/apache/commons/compress/utils/ArchiveUtils.java\n      * @return the representation of the entry\n      */\n     public static String toString(ArchiveEntry entry){\n-        StringBuffer sb = new StringBuffer();\n+        StringBuilder sb = new StringBuilder();\n         sb.append(entry.isDirectory()? 'd' : '-');// c.f. \"ls -l\" output\n         String size = Long.toString((entry.getSize()));\n         sb.append(' ');\n             String expected, byte[] buffer, int offset, int length){\n         byte[] buffer1;\n         try {\n-            buffer1 = expected.getBytes(\"ASCII\");\n+            buffer1 = expected.getBytes(CharsetNames.US_ASCII);\n         } catch (UnsupportedEncodingException e) {\n             throw new RuntimeException(e); // Should not happen\n         }\n      */\n     public static byte[] toAsciiBytes(String inputString){\n         try {\n-            return inputString.getBytes(\"ASCII\");\n+            return inputString.getBytes(CharsetNames.US_ASCII);\n         } catch (UnsupportedEncodingException e) {\n            throw new RuntimeException(e); // Should never happen\n         }\n      */\n     public static String toAsciiString(final byte[] inputBytes){\n         try {\n-            return new String(inputBytes, \"ASCII\");\n+            return new String(inputBytes, CharsetNames.US_ASCII);\n         } catch (UnsupportedEncodingException e) {\n             throw new RuntimeException(e); // Should never happen\n         }\n      */\n     public static String toAsciiString(final byte[] inputBytes, int offset, int length){\n         try {\n-            return new String(inputBytes, offset, length, \"ASCII\");\n+            return new String(inputBytes, offset, length, CharsetNames.US_ASCII);\n         } catch (UnsupportedEncodingException e) {\n             throw new RuntimeException(e); // Should never happen\n         }\n             final byte[] buffer2, final int offset2, final int length2){\n         return isEqual(buffer1, offset1, length1, buffer2, offset2, length2, true);\n     }\n-\n+    \n+    /**\n+     * Returns true if the first N bytes of an array are all zero\n+     * \n+     * @param a\n+     *            The array to check\n+     * @param size\n+     *            The number of characters to check (not the size of the array)\n+     * @return true if the first N bytes are zero\n+     */\n+    public static boolean isArrayZero(byte[] a, int size) {\n+        for (int i = 0; i < size; i++) {\n+            if (a[i] != 0) {\n+                return false;\n+            }\n+        }\n+        return true;\n+    }\n }\n--- a/src/main/java/org/apache/commons/compress/utils/IOUtils.java\n+++ b/src/main/java/org/apache/commons/compress/utils/IOUtils.java\n         }\n         return count;\n     }\n+    \n+    /**\n+     * Skips the given number of bytes by repeatedly invoking skip on\n+     * the given input stream if necessary.\n+     *\n+     * <p>This method will only skip less than the requested number of\n+     * bytes if the end of the input stream has been reached.</p>\n \n+     * @param input stream to skip bytes in\n+     * @param numToSkip the number of bytes to skip\n+     * @return the number of bytes actually skipped\n+     * @throws IOException\n+     */\n+    public static long skip(InputStream input, long numToSkip) throws IOException {\n+        long available = numToSkip;\n+        while (numToSkip > 0) {\n+            long skipped = input.skip(numToSkip);\n+            if (skipped == 0) {\n+                break;\n+            }\n+            numToSkip -= skipped;\n+        }\n+        return (available - numToSkip);\n+    }\n \n     // toByteArray(InputStream) copied from:\n     // commons/proper/io/trunk/src/main/java/org/apache/commons/io/IOUtils.java?revision=1428941\n--- a/src/test/java/org/apache/commons/compress/AbstractTestCase.java\n+++ b/src/test/java/org/apache/commons/compress/AbstractTestCase.java\n     protected ArchiveStreamFactory factory = new ArchiveStreamFactory();\n \n     public AbstractTestCase() {\n-        super();\n     }\n \n     public AbstractTestCase(String name) {\n--- a/src/test/java/org/apache/commons/compress/DetectArchiverTestCase.java\n+++ b/src/test/java/org/apache/commons/compress/DetectArchiverTestCase.java\n import org.apache.commons.compress.archivers.ArchiveException;\n import org.apache.commons.compress.archivers.ArchiveInputStream;\n import org.apache.commons.compress.archivers.ar.ArArchiveInputStream;\n+import org.apache.commons.compress.archivers.arj.ArjArchiveInputStream;\n import org.apache.commons.compress.archivers.cpio.CpioArchiveInputStream;\n import org.apache.commons.compress.archivers.tar.TarArchiveInputStream;\n import org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;\n         final ArchiveInputStream cpio = getStreamFor(\"bla.cpio\");\n         assertNotNull(cpio);\n         assertTrue(cpio instanceof CpioArchiveInputStream);\n+        \n+        final ArchiveInputStream arj = getStreamFor(\"bla.arj\");\n+        assertNotNull(arj);\n+        assertTrue(arj instanceof ArjArchiveInputStream);\n \n // Not yet implemented\n //        final ArchiveInputStream tgz = getStreamFor(\"bla.tgz\");\n--- a/src/test/java/org/apache/commons/compress/DetectCompressorTestCase.java\n+++ b/src/test/java/org/apache/commons/compress/DetectCompressorTestCase.java\n import static org.apache.commons.compress.AbstractTestCase.getFile;\n \n import java.io.BufferedInputStream;\n+import java.io.ByteArrayInputStream;\n import java.io.FileInputStream;\n import java.io.IOException;\n import junit.framework.TestCase;\n import org.apache.commons.compress.compressors.CompressorStreamFactory;\n import org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;\n import org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream;\n+import org.apache.commons.compress.compressors.pack200.Pack200CompressorInputStream;\n+import org.apache.commons.compress.compressors.xz.XZCompressorInputStream;\n \n public final class DetectCompressorTestCase extends TestCase {\n \n         super(name);\n     }\n \n-    final ClassLoader classLoader = getClass().getClassLoader();\n     final CompressorStreamFactory factory = new CompressorStreamFactory();\n \n     public void testDetection() throws Exception {\n-\n-        final CompressorInputStream bzip2 = getStreamFor(\"bla.txt.bz2\"); \n+        CompressorInputStream bzip2 = getStreamFor(\"bla.txt.bz2\"); \n         assertNotNull(bzip2);\n         assertTrue(bzip2 instanceof BZip2CompressorInputStream);\n \n-        final CompressorInputStream gzip = getStreamFor(\"bla.tgz\");\n+        CompressorInputStream gzip = getStreamFor(\"bla.tgz\");\n         assertNotNull(gzip);\n         assertTrue(gzip instanceof GzipCompressorInputStream);\n+        \n+        CompressorInputStream pack200 = getStreamFor(\"bla.pack\");\n+        assertNotNull(pack200);\n+        assertTrue(pack200 instanceof Pack200CompressorInputStream);\n \n+        CompressorInputStream xz = getStreamFor(\"bla.tar.xz\");\n+        assertNotNull(xz);\n+        assertTrue(xz instanceof XZCompressorInputStream);\n+\n+        try {\n+            factory.createCompressorInputStream(new ByteArrayInputStream(new byte[0]));\n+            fail(\"No exception thrown for an empty input stream\");\n+        } catch (CompressorException e) {\n+            // expected\n+        }\n     }\n \n     private CompressorInputStream getStreamFor(String resource)\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/compress/archivers/arj/ArjArchiveInputStreamTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.commons.compress.archivers.arj;\n+\n+import java.io.FileInputStream;\n+\n+import org.apache.commons.compress.AbstractTestCase;\n+\n+public class ArjArchiveInputStreamTest extends AbstractTestCase {\n+\n+    public void testArjUnarchive() throws Exception {\n+        StringBuilder expected = new StringBuilder();\n+        expected.append(\"test1.xml<?xml version=\\\"1.0\\\"?>\\n\");\n+        expected.append(\"<empty/>test2.xml<?xml version=\\\"1.0\\\"?>\\n\");\n+        expected.append(\"<empty/>\\n\");\n+\n+\n+        ArjArchiveInputStream in = new ArjArchiveInputStream(new FileInputStream(getFile(\"bla.arj\")));\n+        ArjArchiveEntry entry;\n+\n+        StringBuilder result = new StringBuilder();\n+        while ((entry = in.getNextEntry()) != null) {\n+            result.append(entry.getName());\n+            int tmp;\n+            while ((tmp = in.read()) != -1) {\n+                result.append((char) tmp);\n+            }\n+        }\n+        in.close();\n+        assertEquals(result.toString(), expected.toString());\n+    }\n+}\n--- a/src/test/java/org/apache/commons/compress/archivers/cpio/CpioArchiveInputStreamTest.java\n+++ b/src/test/java/org/apache/commons/compress/archivers/cpio/CpioArchiveInputStreamTest.java\n public class CpioArchiveInputStreamTest extends AbstractTestCase {\n \n     public void testCpioUnarchive() throws Exception {\n-        StringBuffer expected = new StringBuffer();\n+        StringBuilder expected = new StringBuilder();\n         expected.append(\"./test1.xml<?xml version=\\\"1.0\\\"?>\\n\");\n         expected.append(\"<empty/>./test2.xml<?xml version=\\\"1.0\\\"?>\\n\");\n         expected.append(\"<empty/>\\n\");\n \n \n-        CpioArchiveInputStream in = \n-                new CpioArchiveInputStream(new FileInputStream(getFile(\"bla.cpio\")));\n-        CpioArchiveEntry entry= null;\n+        CpioArchiveInputStream in = new CpioArchiveInputStream(new FileInputStream(getFile(\"bla.cpio\")));\n+        CpioArchiveEntry entry;\n \n-        StringBuffer result = new StringBuffer();\n-        while ((entry = (CpioArchiveEntry) in.getNextEntry()) != null) {\n+        StringBuilder result = new StringBuilder();\n+        while ((entry = in.getNextEntry()) != null) {\n             result.append(entry.getName());\n             int tmp;\n             while ((tmp = in.read()) != -1) {\n                 result.append((char) tmp);\n-             }\n-         }\n-         in.close();\n-         assertEquals(result.toString(), expected.toString());\n+            }\n+        }\n+        in.close();\n+        assertEquals(result.toString(), expected.toString());\n+    }\n+\n+    public void testCpioUnarchiveCreatedByRedlineRpm() throws Exception {\n+        CpioArchiveInputStream in =\n+            new CpioArchiveInputStream(new FileInputStream(getFile(\"redline.cpio\")));\n+        CpioArchiveEntry entry= null;\n+\n+        int count = 0;\n+        while ((entry = (CpioArchiveEntry) in.getNextEntry()) != null) {\n+            count++;\n+        }\n+        in.close();\n+\n+        assertEquals(count, 1);\n     }\n }\n--- a/src/test/java/org/apache/commons/compress/archivers/memory/MemoryArchiveEntry.java\n+++ b/src/test/java/org/apache/commons/compress/archivers/memory/MemoryArchiveEntry.java\n         return false;\n     }\n \n-    /** {@inheritDoc} */\n     public Date getLastModifiedDate() {\n         return new Date();\n     }\n--- a/src/test/java/org/apache/commons/compress/archivers/tar/BigFilesIT.java\n+++ b/src/test/java/org/apache/commons/compress/archivers/tar/BigFilesIT.java\n import static org.junit.Assert.assertNotNull;\n import static org.junit.Assert.assertNull;\n \n+import java.io.BufferedInputStream;\n+import java.io.InputStream;\n import java.util.Random;\n \n import org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream;\n         readFileBiggerThan8GByte(\"/8.posix.tar.gz\");\n     }\n \n-    private void readFileBiggerThan8GByte(String name) throws Exception {\n-        GzipCompressorInputStream in = null;\n+    @Test\n+    public void readFileHeadersOfArchiveBiggerThan8GByte() throws Exception {\n+        InputStream in = null;\n+        GzipCompressorInputStream gzin = null;\n         TarArchiveInputStream tin = null;\n         try {\n-            in =\n-                new GzipCompressorInputStream(BigFilesIT.class\n-                                              .getResourceAsStream(name));\n-            tin = new TarArchiveInputStream(in);\n+            in = new BufferedInputStream(BigFilesIT.class\n+                                         .getResourceAsStream(\"/8.posix.tar.gz\")\n+                                         );\n+            gzin = new GzipCompressorInputStream(in);\n+            tin = new TarArchiveInputStream(gzin);\n+            TarArchiveEntry e = tin.getNextTarEntry();\n+            assertNotNull(e);\n+            assertNull(tin.getNextTarEntry());\n+        } finally {\n+            if (tin != null) {\n+                tin.close();\n+            }\n+            if (gzin != null) {\n+                gzin.close();\n+            }\n+            if (in != null) {\n+                in.close();\n+            }\n+        }\n+    }\n+\n+    private void readFileBiggerThan8GByte(String name) throws Exception {\n+        InputStream in = null;\n+        GzipCompressorInputStream gzin = null;\n+        TarArchiveInputStream tin = null;\n+        try {\n+            in = new BufferedInputStream(BigFilesIT.class\n+                                         .getResourceAsStream(name));\n+            gzin = new GzipCompressorInputStream(in);\n+            tin = new TarArchiveInputStream(gzin);\n             TarArchiveEntry e = tin.getNextTarEntry();\n             assertNotNull(e);\n             assertEquals(8200l * 1024 * 1024, e.getSize());\n             if (tin != null) {\n                 tin.close();\n             }\n+            if (gzin != null) {\n+                gzin.close();\n+            }\n             if (in != null) {\n                 in.close();\n             }\n--- a/src/test/java/org/apache/commons/compress/archivers/tar/TarArchiveInputStreamTest.java\n+++ b/src/test/java/org/apache/commons/compress/archivers/tar/TarArchiveInputStreamTest.java\n import java.io.ByteArrayInputStream;\n import java.io.ByteArrayOutputStream;\n import java.io.FileInputStream;\n+import java.io.IOException;\n import java.io.InputStream;\n-import java.io.IOException;\n import java.util.Calendar;\n import java.util.Date;\n import java.util.Map;\n \n     @Test\n     public void readSimplePaxHeader() throws Exception {\n-        final TarArchiveInputStream tais = new TarArchiveInputStream(null);\n+        final InputStream is = new ByteArrayInputStream(new byte[1]);\n+        final TarArchiveInputStream tais = new TarArchiveInputStream(is);\n         Map<String, String> headers = tais\n             .parsePaxHeaders(new ByteArrayInputStream(\"30 atime=1321711775.972059463\\n\"\n                                                       .getBytes(CharsetNames.UTF_8)));\n \n     @Test\n     public void readPaxHeaderWithEmbeddedNewline() throws Exception {\n-        final TarArchiveInputStream tais = new TarArchiveInputStream(null);\n+        final InputStream is = new ByteArrayInputStream(new byte[1]);\n+        final TarArchiveInputStream tais = new TarArchiveInputStream(is);\n         Map<String, String> headers = tais\n             .parsePaxHeaders(new ByteArrayInputStream(\"28 comment=line1\\nline2\\nand3\\n\"\n                                                       .getBytes(CharsetNames.UTF_8)));\n         String ae = \"\\u00e4\";\n         String line = \"11 path=\"+ ae + \"\\n\";\n         assertEquals(11, line.getBytes(CharsetNames.UTF_8).length);\n-        final TarArchiveInputStream tais = new TarArchiveInputStream(null);\n+        final InputStream is = new ByteArrayInputStream(new byte[1]);\n+        final TarArchiveInputStream tais = new TarArchiveInputStream(is);\n         Map<String, String> headers = tais\n             .parsePaxHeaders(new ByteArrayInputStream(line.getBytes(CharsetNames.UTF_8)));\n         assertEquals(1, headers.size());\n--- a/src/test/java/org/apache/commons/compress/archivers/tar/TarArchiveOutputStreamTest.java\n+++ b/src/test/java/org/apache/commons/compress/archivers/tar/TarArchiveOutputStreamTest.java\n import org.apache.commons.compress.archivers.ArchiveOutputStream;\n import org.apache.commons.compress.archivers.ArchiveStreamFactory;\n import org.apache.commons.compress.utils.CharsetNames;\n+import org.apache.commons.compress.utils.IOUtils;\n \n public class TarArchiveOutputStreamTest extends AbstractTestCase {\n \n         tin.close();\n     }\n \n+    public void testWriteLongDirectoryNameErrorMode() throws Exception {\n+        String n = \"01234567890123456789012345678901234567890123456789\"\n+                + \"01234567890123456789012345678901234567890123456789\"\n+                + \"01234567890123456789012345678901234567890123456789/\";\n+\n+        try {\n+            TarArchiveEntry t = new TarArchiveEntry(n);\n+            ByteArrayOutputStream bos = new ByteArrayOutputStream();\n+            TarArchiveOutputStream tos = new TarArchiveOutputStream(bos, \"ASCII\");\n+            tos.setLongFileMode(TarArchiveOutputStream.LONGFILE_ERROR);\n+            tos.putArchiveEntry(t);\n+            tos.closeArchiveEntry();\n+            tos.close();\n+            \n+            fail(\"Truncated name didn't throw an exception\");\n+        } catch (RuntimeException e) {\n+            // expected\n+        }\n+    }\n+\n+    public void testWriteLongDirectoryNameTruncateMode() throws Exception {\n+        String n = \"01234567890123456789012345678901234567890123456789\"\n+            + \"01234567890123456789012345678901234567890123456789\"\n+            + \"01234567890123456789012345678901234567890123456789/\";\n+        TarArchiveEntry t = new TarArchiveEntry(n);\n+        ByteArrayOutputStream bos = new ByteArrayOutputStream();\n+        TarArchiveOutputStream tos = new TarArchiveOutputStream(bos, \"ASCII\");\n+        tos.setLongFileMode(TarArchiveOutputStream.LONGFILE_TRUNCATE);\n+        tos.putArchiveEntry(t);\n+        tos.closeArchiveEntry();\n+        tos.close();\n+        byte[] data = bos.toByteArray();\n+        TarArchiveInputStream tin =\n+            new TarArchiveInputStream(new ByteArrayInputStream(data));\n+        TarArchiveEntry e = tin.getNextTarEntry();\n+        assertEquals(\"Entry name\", n.substring(0, TarConstants.NAMELEN) + \"/\", e.getName());\n+        assertTrue(\"The entry is not a directory\", e.isDirectory());\n+        tin.close();\n+    }\n+\n     /**\n      * @see \"https://issues.apache.org/jira/browse/COMPRESS-203\"\n      */\n         tin.close();\n     }\n \n+    /**\n+     * @see \"https://issues.apache.org/jira/browse/COMPRESS-237\"\n+     */\n+    public void testWriteLongLinkNameErrorMode() throws Exception {\n+        String linkname = \"01234567890123456789012345678901234567890123456789\"\n+                + \"01234567890123456789012345678901234567890123456789\"\n+                + \"01234567890123456789012345678901234567890123456789/test\";\n+        TarArchiveEntry entry = new TarArchiveEntry(\"test\", TarArchiveEntry.LF_SYMLINK);\n+        entry.setLinkName(linkname);\n+        \n+        try {\n+            ByteArrayOutputStream bos = new ByteArrayOutputStream();\n+            TarArchiveOutputStream tos = new TarArchiveOutputStream(bos, \"ASCII\");\n+            tos.setLongFileMode(TarArchiveOutputStream.LONGFILE_ERROR);\n+            tos.putArchiveEntry(entry);\n+            tos.closeArchiveEntry();\n+            tos.close();\n+            \n+            fail(\"Truncated link name didn't throw an exception\");\n+        } catch (RuntimeException e) {\n+            // expected\n+        }\n+    }\n+\n+    public void testWriteLongLinkNameTruncateMode() throws Exception {\n+        String linkname = \"01234567890123456789012345678901234567890123456789\"\n+            + \"01234567890123456789012345678901234567890123456789\"\n+            + \"01234567890123456789012345678901234567890123456789/\";\n+        TarArchiveEntry entry = new TarArchiveEntry(\"test\" , TarArchiveEntry.LF_SYMLINK);\n+        entry.setLinkName(linkname);\n+        \n+        ByteArrayOutputStream bos = new ByteArrayOutputStream();\n+        TarArchiveOutputStream tos = new TarArchiveOutputStream(bos, \"ASCII\");\n+        tos.setLongFileMode(TarArchiveOutputStream.LONGFILE_TRUNCATE);\n+        tos.putArchiveEntry(entry);\n+        tos.closeArchiveEntry();\n+        tos.close();\n+        \n+        byte[] data = bos.toByteArray();\n+        TarArchiveInputStream tin = new TarArchiveInputStream(new ByteArrayInputStream(data));\n+        TarArchiveEntry e = tin.getNextTarEntry();\n+        assertEquals(\"Link name\", linkname.substring(0, TarConstants.NAMELEN), e.getLinkName());\n+        tin.close();\n+    }\n+\n+    /**\n+     * @see \"https://issues.apache.org/jira/browse/COMPRESS-237\"\n+     */\n+    public void testWriteLongLinkNameGnuMode() throws Exception {\n+        testWriteLongLinkName(TarArchiveOutputStream.LONGFILE_GNU);\n+    }\n+\n+    /**\n+     * @see \"https://issues.apache.org/jira/browse/COMPRESS-237\"\n+     */\n+    public void testWriteLongLinkNamePosixMode() throws Exception {\n+        testWriteLongLinkName(TarArchiveOutputStream.LONGFILE_POSIX);\n+    }\n+\n+    /**\n+     * @see \"https://issues.apache.org/jira/browse/COMPRESS-237\"\n+     */\n+    public void testWriteLongLinkName(int mode) throws Exception {\n+        String linkname = \"01234567890123456789012345678901234567890123456789\"\n+            + \"01234567890123456789012345678901234567890123456789\"\n+            + \"01234567890123456789012345678901234567890123456789/test\";\n+        TarArchiveEntry entry = new TarArchiveEntry(\"test\", TarArchiveEntry.LF_SYMLINK);\n+        entry.setLinkName(linkname);\n+        \n+        ByteArrayOutputStream bos = new ByteArrayOutputStream();\n+        TarArchiveOutputStream tos = new TarArchiveOutputStream(bos, \"ASCII\");\n+        tos.setLongFileMode(mode);\n+        tos.putArchiveEntry(entry);\n+        tos.closeArchiveEntry();\n+        tos.close();\n+        \n+        byte[] data = bos.toByteArray();\n+        TarArchiveInputStream tin = new TarArchiveInputStream(new ByteArrayInputStream(data));\n+        TarArchiveEntry e = tin.getNextTarEntry();\n+        assertEquals(\"Entry name\", \"test\", e.getName());\n+        assertEquals(\"Link name\", linkname, e.getLinkName());\n+        assertTrue(\"The entry is not a symbolic link\", e.isSymbolicLink());\n+        tin.close();\n+    }\n+\n+    public void testPadsOutputToFullBlockLength() throws Exception {\n+        File f = File.createTempFile(\"commons-compress-padding\", \".tar\");\n+        f.deleteOnExit();\n+        FileOutputStream fos = new FileOutputStream(f);\n+        TarArchiveOutputStream tos = new TarArchiveOutputStream(fos);\n+        File file1 = getFile(\"test1.xml\");\n+        TarArchiveEntry sEntry = new TarArchiveEntry(file1);\n+        tos.putArchiveEntry(sEntry);\n+        FileInputStream in = new FileInputStream(file1);\n+        IOUtils.copy(in, tos);\n+        in.close();\n+        tos.closeArchiveEntry();\n+        tos.close();\n+        // test1.xml is small enough to fit into the default blockv size\n+        assertEquals(TarConstants.DEFAULT_BLKSIZE, f.length());\n+    }\n+\n }", "timestamp": 1379855369, "metainfo": ""}