{"sha": "794c20fe50038a8fe88852e4ab95e6381ed8027b", "log": "a few 'extract method' refactorings to make code more readable, still won't win a beauty-contest  ", "commit": "\n--- a/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveInputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveInputStream.java\n \n /**\n  * Implements an input stream that can read Zip archives.\n- * <p>\n- * Note that {@link ZipArchiveEntry#getSize()} may return -1 if the DEFLATE algorithm is used, as the size information\n- * is not available from the header.\n- * <p>\n- * The {@link ZipFile} class is preferred when reading from files.\n- *  \n+ *\n+ * <p>Note that {@link ZipArchiveEntry#getSize()} may return -1 if the\n+ * DEFLATE algorithm is used, as the size information is not available\n+ * from the header.</p>\n+ *\n+ * <p>The {@link ZipFile} class is preferred when reading from files.</p>\n+ *\n+ * <p>As of Apache Commons Compress it transparently supports Zip64\n+ * extensions and thus individual entries and archives larger than 4\n+ * GB or with more than 65536 entries.</p>\n+ *\n  * @see ZipFile\n  * @NotThreadSafe\n  */\n                                                      null);\n         }\n \n-        Zip64ExtendedInformationExtraField z64 =  \n+        processZip64Extra(size, cSize);\n+        return current.entry;\n+    }\n+\n+    /**\n+     * Records whether a Zip64 extra is present and sets the size\n+     * information from it if sizes are 0xFFFFFFFF and the entry\n+     * doesn't use a data descriptor.\n+     */\n+    private void processZip64Extra(ZipLong size, ZipLong cSize) {\n+        Zip64ExtendedInformationExtraField z64 =\n             (Zip64ExtendedInformationExtraField)\n             current.entry.getExtraField(Zip64ExtendedInformationExtraField\n                                         .HEADER_ID);\n                 current.entry.setSize(size.getValue());\n             }\n         }\n-        return current.entry;\n     }\n \n     /** {@inheritDoc} */\n             }\n \n             if (current.entry.getMethod() == ZipArchiveOutputStream.STORED) {\n+                return readStored(buffer, start, length);\n+            }\n+            return readDeflated(buffer, start, length);\n+        }\n+        throw new ArrayIndexOutOfBoundsException();\n+    }\n+\n+    /**\n+     * Implementation of read for STORED entries.\n+     */\n+    private int readStored(byte[] buffer, int start, int length)\n+        throws IOException {\n                 if (current.hasDataDescriptor) {\n                     if (lastStoredEntry == null) {\n                         readStoredEntry();\n                 current.bytesRead += toRead;\n                 crc.update(buffer, start, toRead);\n                 return toRead;\n-            }\n-\n+    }\n+\n+    /**\n+     * Implementation of read for DEFLATED entries.\n+     */\n+    private int readDeflated(byte[] buffer, int start, int length)\n+        throws IOException {\n             if (inf.needsInput()) {\n                 fill();\n                 if (buf.lengthOfLastRead > 0) {\n             }\n             crc.update(buffer, start, read);\n             return read;\n-        }\n-        throw new ArrayIndexOutOfBoundsException();\n     }\n \n     @Override\n      * stream.\n      *\n      * <p>This implementation may end up skipping over some smaller\n-     * number of bytes, possibly 0, if an only if it reaches the end\n+     * number of bytes, possibly 0, if and only if it reaches the end\n      * of the underlying stream.</p>\n      *\n      * <p>The actual number of bytes skipped is returned.</p>\n                 return false;\n             }\n         }\n-        return true;        \n+        return true;\n     }\n \n     /**\n         // Ensure all entry bytes are read\n         if (current.bytesReadFromStream <= current.entry.getCompressedSize()\n                 && !current.hasDataDescriptor) {\n+            drainCurrentEntryData();\n+        } else {\n+            skip(Long.MAX_VALUE);\n+\n+            long inB = \n+                current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED\n+                ? getBytesInflated() : current.bytesRead;\n+\n+            // this is at most a single read() operation and can't\n+            // exceed the range of int\n+            int diff = (int) (current.bytesReadFromStream - inB);\n+\n+            // Pushback any required bytes\n+            if (diff > 0) {\n+                pushback(buf.buf, buf.lengthOfLastRead - diff, diff);\n+            }\n+        }\n+\n+        if (lastStoredEntry == null && current.hasDataDescriptor) {\n+            readDataDescriptor();\n+        }\n+\n+        inf.reset();\n+        buf.reset();\n+        crc.reset();\n+        current = null;\n+        lastStoredEntry = null;\n+    }\n+\n+    /**\n+     * Read all data of the current entry from the underlying stream\n+     * that hasn't been read, yet.\n+     */\n+    private void drainCurrentEntryData() throws IOException {\n             long remaining = current.entry.getCompressedSize()\n                 - current.bytesReadFromStream;\n             while (remaining > 0) {\n                     remaining -= n;\n                 }\n             }\n-        } else {\n-            skip(Long.MAX_VALUE);\n-\n-            long inB;\n-            if (current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED) {\n-                inB = inf.getBytesRead();\n-                /* for Java < Java7 the getBytes* methods in\n-                 * Inflater/Deflater seem to return unsigned ints\n-                 * rather than longs that start over with 0 at 2^32.\n-                 *\n-                 * The stream knows how many bytes it has read, but\n-                 * not how many the Inflater actually consumed - it\n-                 * should be between the total number of bytes read\n-                 * for the entry and the total number minus the last\n-                 * read operation.  Here we just try to make the value\n-                 * close enough to the bytes we've read by assuming\n-                 * the number of bytes consumed must be smaller than\n-                 * (or equal to) the number of bytes read but not\n-                 * smaller by more than 2^32.\n-                 */\n-                if (current.bytesReadFromStream >= TWO_EXP_32) {\n-                    while (inB + TWO_EXP_32 <= current.bytesReadFromStream) {\n-                        inB += TWO_EXP_32;\n-                    }\n-                }\n-            } else {\n-                inB = current.bytesRead;\n-            }\n-\n-            // this is at most a single read() operation and can't\n-            // exceed the range of int\n-            int diff = (int) (current.bytesReadFromStream - inB);\n-\n-            // Pushback any required bytes\n-            if (diff > 0) {\n-                pushback(buf.buf, buf.lengthOfLastRead - diff, diff);\n-            }\n-        }\n-\n-        if (lastStoredEntry == null && current.hasDataDescriptor) {\n-            readDataDescriptor();\n-        }\n-\n-        inf.reset();\n-        buf.reset();\n-        crc.reset();\n-        current = null;\n-        lastStoredEntry = null;\n+    }\n+\n+    /**\n+     * Get the number of bytes Inflater has actually processed.\n+     *\n+     * <p>for Java &lt; Java7 the getBytes* methods in\n+     * Inflater/Deflater seem to return unsigned ints rather than\n+     * longs that start over with 0 at 2^32.</p>\n+     *\n+     * <p>The stream knows how many bytes it has read, but not how\n+     * many the Inflater actually consumed - it should be between the\n+     * total number of bytes read for the entry and the total number\n+     * minus the last read operation.  Here we just try to make the\n+     * value close enough to the bytes we've read by assuming the\n+     * number of bytes consumed must be smaller than (or equal to) the\n+     * number of bytes read but not smaller by more than 2^32.</p>\n+     */\n+    private long getBytesInflated() {\n+        long inB = inf.getBytesRead();\n+        if (current.bytesReadFromStream >= TWO_EXP_32) {\n+            while (inB + TWO_EXP_32 <= current.bytesReadFromStream) {\n+                inB += TWO_EXP_32;\n+            }\n+        }\n+        return inB;\n     }\n \n     private void fill() throws IOException {\n      */\n     private void readStoredEntry() throws IOException {\n         ByteArrayOutputStream bos = new ByteArrayOutputStream();\n-        byte[] LFH = ZipLong.LFH_SIG.getBytes();\n-        byte[] CFH = ZipLong.CFH_SIG.getBytes();\n-        byte[] DD = ZipLong.DD_SIG.getBytes();\n         int off = 0;\n         boolean done = false;\n \n                 continue;\n             }\n \n+            done = bufferContainsSignature(bos, off, r, ddLen);\n+            if (!done) {\n+                off = cacheBytesRead(bos, off, r, ddLen);\n+            }\n+        }\n+\n+        byte[] b = bos.toByteArray();\n+        lastStoredEntry = new ByteArrayInputStream(b);\n+    }\n+\n+    private static final byte[] LFH = ZipLong.LFH_SIG.getBytes();\n+    private static final byte[] CFH = ZipLong.CFH_SIG.getBytes();\n+    private static final byte[] DD = ZipLong.DD_SIG.getBytes();\n+\n+    /**\n+     * Checks whether the current buffer contains the signature of a\n+     * &quot;data decsriptor&quot;, &quot;local file header&quot; or\n+     * &quot;central directory entry&quot;.\n+     *\n+     * <p>If it contains such a signature, reads the data descriptor\n+     * and positions the stream right after the data descriptor.</p>\n+     */\n+    private boolean bufferContainsSignature(ByteArrayOutputStream bos,\n+                                            int off, int r, int ddLen)\n+        throws IOException {\n+        boolean done = false;\n             int readTooMuch = 0;\n             for (int i = 0; !done && i < r - 4; i++) {\n                 if (buf.buf[i] == LFH[0] && buf.buf[i + 1] == LFH[1]) {\n                     }\n                 }\n             }\n-            if (!done) {\n-                // worst case we've read a data descriptor without a\n-                // signature (up to 20 bytes) plus the first three bytes of\n-                // a LFH or CFH signature\n-                // save the last ddLen + 3 bytes in the buffer, cache\n-                // anything in front of that, read on\n-                if (off + r > ddLen + 3) {\n-                    bos.write(buf.buf, 0, off + r - ddLen - 3);\n-                    System.arraycopy(buf.buf, off + r - ddLen - 3, buf.buf, 0,\n-                                     ddLen + 3);\n-                    off = ddLen + 3;\n-                } else {\n-                    off += r;\n-                }\n-            }\n-        }\n-\n-        byte[] b = bos.toByteArray();\n-        lastStoredEntry = new ByteArrayInputStream(b);\n+        return done;\n+    }\n+\n+    /**\n+     * If the last read bytes could hold a data descriptor and an\n+     * incomplete signature then save the last bytes to the front of\n+     * the buffer and cache everything in front of the potential data\n+     * descriptor into the given ByteArrayOutputStream.\n+     *\n+     * <p>Data descriptor plus incomplete signature (3 bytes in the\n+     * worst case) can be 20 bytes max.</p>\n+     */\n+    private int cacheBytesRead(ByteArrayOutputStream bos, int offset,\n+                               int lastRead, int expecteDDLen)\n+        throws IOException {\n+        final int cacheable = offset + lastRead - expecteDDLen - 3;\n+        if (cacheable > 0) {\n+            bos.write(buf.buf, 0, cacheable);\n+            System.arraycopy(buf.buf, cacheable, buf.buf, 0,\n+                             expecteDDLen + 3);\n+            offset = expecteDDLen + 3;\n+        } else {\n+            offset += lastRead;\n+        }\n+        return offset;\n     }\n \n     private void pushback(byte[] buf, int offset, int length)\n--- a/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveOutputStream.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveOutputStream.java\n  * the {@link #STORED STORED} method, here setting the CRC and\n  * uncompressed size information is required before {@link\n  * #putArchiveEntry(ArchiveEntry)} can be called.</p>\n+ *\n+ * <p>As of Apache Commons Compress it transparently supports Zip64\n+ * extensions and thus individual entries and archives larger than 4\n+ * GB or with more than 65536 entries in most cases but explicit\n+ * control is provided via {@link setUseZip64}.  If the stream can not\n+ * user RandomAccessFile and you try to write a ZipArchiveEntry of\n+ * unknown size then Zip64 extensions will be disabled by default.</p>\n+ *\n  * @NotThreadSafe\n  */\n public class ZipArchiveOutputStream extends ArchiveOutputStream {\n      * {@inheritDoc}\n      * @throws Zip64RequiredException if the archive's size exceeds 4\n      * GByte or there are more than 65535 entries inside the archive\n+     * and {@link Zip64Mode #setUseZip64} is {@link Zip64Mode#Never}.\n      */\n     @Override\n     public void finish() throws IOException {\n      * Writes all necessary data for this entry.\n      * @throws IOException on error\n      * @throws Zip64RequiredException if the entry's uncompressed or\n-     * compressed size exceeds 4 GByte\n+     * compressed size exceeds 4 GByte and {@link Zip64Mode\n+     * #setUseZip64} is {@link Zip64Mode#Never}.\n      */\n     @Override\n     public void closeArchiveEntry() throws IOException {\n             write(new byte[0], 0, 0);\n         }\n \n+        flushDeflater();\n+\n+        final Zip64Mode effectiveMode = getEffectiveZip64Mode(entry.entry);\n+        long bytesWritten = written - entry.dataStart;\n+        long realCrc = crc.getValue();\n+        crc.reset();\n+\n+        final boolean actuallyNeedsZip64 =\n+            handleSizesAndCrc(bytesWritten, realCrc, effectiveMode);\n+\n+        if (raf != null) {\n+            rewriteSizesAndCrc(actuallyNeedsZip64);\n+        }\n+\n+        writeDataDescriptor(entry.entry);\n+        entry = null;\n+    }\n+\n+    /**\n+     * Ensures all bytes sent to the deflater are written to the stream.\n+     */\n+    private void flushDeflater() throws IOException {\n         if (entry.entry.getMethod() == DEFLATED) {\n             def.finish();\n             while (!def.finished()) {\n                 deflate();\n             }\n         }\n-\n-        final Zip64Mode effectiveMode = getEffectiveZip64Mode(entry.entry);\n-        long bytesWritten = written - entry.dataStart;\n-        long realCrc = crc.getValue();\n-        crc.reset();\n-\n+    }\n+\n+    /**\n+     * Ensures the current entry's size and CRC information is set to\n+     * the values just written, verifies it isn't too big in the\n+     * Zip64Mode.Never case and returns whether the entry would\n+     * require a Zip64 extra field.\n+     */\n+    private boolean handleSizesAndCrc(long bytesWritten, long crc,\n+                                      Zip64Mode effectiveMode)\n+        throws ZipException {\n         if (entry.entry.getMethod() == DEFLATED) {\n             /* It turns out def.getBytesRead() returns wrong values if\n              * the size exceeds 4 GB on Java < Java7\n             */\n             entry.entry.setSize(entry.bytesRead);\n             entry.entry.setCompressedSize(bytesWritten);\n-            entry.entry.setCrc(realCrc);\n+            entry.entry.setCrc(crc);\n \n             def.reset();\n         } else if (raf == null) {\n-            if (entry.entry.getCrc() != realCrc) {\n+            if (entry.entry.getCrc() != crc) {\n                 throw new ZipException(\"bad CRC checksum for entry \"\n                                        + entry.entry.getName() + \": \"\n                                        + Long.toHexString(entry.entry.getCrc())\n                                        + \" instead of \"\n-                                       + Long.toHexString(realCrc));\n+                                       + Long.toHexString(crc));\n             }\n \n             if (entry.entry.getSize() != bytesWritten) {\n         } else { /* method is STORED and we used RandomAccessFile */\n             entry.entry.setSize(bytesWritten);\n             entry.entry.setCompressedSize(bytesWritten);\n-            entry.entry.setCrc(realCrc);\n+            entry.entry.setCrc(crc);\n         }\n \n         final boolean actuallyNeedsZip64 = effectiveMode == Zip64Mode.Always\n             throw new Zip64RequiredException(Zip64RequiredException\n                                              .getEntryTooBigMessage(entry.entry));\n         }\n-\n-        // If random access output, write the local file header containing\n-        // the correct CRC and compressed/uncompressed sizes\n-        if (raf != null) {\n+        return actuallyNeedsZip64;\n+    }\n+\n+    /**\n+     * When using random access output, write the local file header\n+     * and potentiall the ZIP64 extra containing the correct CRC and\n+     * compressed/uncompressed sizes.\n+     */\n+    private void rewriteSizesAndCrc(boolean actuallyNeedsZip64)\n+        throws IOException {\n             long save = raf.getFilePointer();\n \n             raf.seek(entry.localDataStart);\n                 }\n             }\n             raf.seek(save);\n-        }\n-\n-        writeDataDescriptor(entry.entry);\n-        entry = null;\n     }\n \n     /**\n      * {@inheritDoc} \n      * @throws ClassCastException if entry is not an instance of ZipArchiveEntry\n      * @throws Zip64RequiredException if the entry's uncompressed or\n-     * compressed size is known to exceed 4 GByte\n+     * compressed size is known to exceed 4 GByte and {@link Zip64Mode\n+     * #setUseZip64} is {@link Zip64Mode#Never}.\n      */\n     @Override\n     public void putArchiveEntry(ArchiveEntry archiveEntry) throws IOException {\n         entry = new CurrentEntry((ZipArchiveEntry) archiveEntry);\n         entries.add(entry.entry);\n \n-        if (entry.entry.getMethod() == -1) { // not specified\n-            entry.entry.setMethod(method);\n-        }\n-\n-        if (entry.entry.getTime() == -1) { // not specified\n-            entry.entry.setTime(System.currentTimeMillis());\n-        }\n-\n+        setDefaults(entry.entry);\n+\n+        final Zip64Mode effectiveMode = getEffectiveZip64Mode(entry.entry);\n+        validateSizeInformation(effectiveMode);\n+\n+        if (shouldAddZip64Extra(entry.entry, effectiveMode)) {\n+\n+            Zip64ExtendedInformationExtraField z64 = getZip64Extra(entry.entry);\n+\n+            // just a placeholder, real data will be in data\n+            // descriptor or inserted later via RandomAccessFile\n+            ZipEightByteInteger size = ZipEightByteInteger.ZERO;\n+            if (entry.entry.getMethod() == STORED\n+                && entry.entry.getSize() != ArchiveEntry.SIZE_UNKNOWN) {\n+                // actually, we already know the sizes\n+                size = new ZipEightByteInteger(entry.entry.getSize());\n+            }\n+                z64.setSize(size);\n+                z64.setCompressedSize(size);\n+            entry.entry.setExtra();\n+        }\n+\n+        if (entry.entry.getMethod() == DEFLATED && hasCompressionLevelChanged) {\n+            def.setLevel(level);\n+            hasCompressionLevelChanged = false;\n+        }\n+        writeLocalFileHeader(entry.entry);\n+    }\n+\n+    /**\n+     * Provides default values for compression method and last\n+     * modification time.\n+     */\n+    private void setDefaults(ZipArchiveEntry entry) {\n+        if (entry.getMethod() == -1) { // not specified\n+            entry.setMethod(method);\n+        }\n+\n+        if (entry.getTime() == -1) { // not specified\n+            entry.setTime(System.currentTimeMillis());\n+        }\n+    }\n+\n+    /**\n+     * Throws an exception if the size is unknown for a stored entry\n+     * that is written to a non-seekable output or the entry is too\n+     * big to be written without Zip64 extra but the mode has been set\n+     * to Never.\n+     */\n+    private void validateSizeInformation(Zip64Mode effectiveMode)\n+        throws ZipException {\n         // Size/CRC not required if RandomAccessFile is used\n         if (entry.entry.getMethod() == STORED && raf == null) {\n             if (entry.entry.getSize() == ArchiveEntry.SIZE_UNKNOWN) {\n             entry.entry.setCompressedSize(entry.entry.getSize());\n         }\n \n-        final Zip64Mode effectiveMode = getEffectiveZip64Mode(entry.entry);\n-\n         if ((entry.entry.getSize() >= ZIP64_MAGIC\n              || entry.entry.getCompressedSize() >= ZIP64_MAGIC)\n             && effectiveMode == Zip64Mode.Never) {\n             throw new Zip64RequiredException(Zip64RequiredException\n                                              .getEntryTooBigMessage(entry.entry));\n         }\n-\n-        // add a ZIP64 extended information extra field if\n-        // * mode is Always\n-        // * or we already know it is going to be needed\n-        // * or the size is unknown and we can ensure it won't hurt\n-        //   other implementations if we add it (i.e. we can erase its\n-        //   usage)\n-        if (effectiveMode == Zip64Mode.Always\n-            || entry.entry.getSize() >= ZIP64_MAGIC\n-            || entry.entry.getCompressedSize() >= ZIP64_MAGIC\n-            || (entry.entry.getSize() == ArchiveEntry.SIZE_UNKNOWN\n-                && raf != null\n-                && effectiveMode != Zip64Mode.Never)) {\n-\n-            Zip64ExtendedInformationExtraField z64 = getZip64Extra(entry.entry);\n-            if (entry.entry.getMethod() == STORED\n-                && entry.entry.getSize() != ArchiveEntry.SIZE_UNKNOWN) {\n-                ZipEightByteInteger size =\n-                    new ZipEightByteInteger(entry.entry.getSize());\n-                z64.setSize(size);\n-                z64.setCompressedSize(size);\n-            } else {\n-                // just a placeholder, real data will be in data\n-                // descriptor or inserted later via RandomAccessFile\n-                z64.setSize(ZipEightByteInteger.ZERO);\n-                z64.setCompressedSize(ZipEightByteInteger.ZERO);\n-            }\n-            entry.entry.setExtra();\n-        }\n-\n-        if (entry.entry.getMethod() == DEFLATED && hasCompressionLevelChanged) {\n-            def.setLevel(level);\n-            hasCompressionLevelChanged = false;\n-        }\n-        writeLocalFileHeader(entry.entry);\n+    }\n+\n+    /**\n+     * Whether to addd a Zip64 extended information extra field to the\n+     * local file header.\n+     *\n+     * <p>Returns true if</p>\n+     *\n+     * <ul>\n+     * <li>mode is Always</li>\n+     * <li>or we already know it is going to be needed</li>\n+     * <li>or the size is unknown and we can ensure it won't hurt\n+     * other implementations if we add it (i.e. we can erase its\n+     * usage</li>\n+     * </ul>\n+     */\n+    private boolean shouldAddZip64Extra(ZipArchiveEntry entry, Zip64Mode mode) {\n+        return mode == Zip64Mode.Always\n+            || entry.getSize() >= ZIP64_MAGIC\n+            || entry.getCompressedSize() >= ZIP64_MAGIC\n+            || (entry.getSize() == ArchiveEntry.SIZE_UNKNOWN\n+                && raf != null && mode != Zip64Mode.Never);\n     }\n \n     /**\n         ZipUtil.checkRequestedFeatures(entry.entry);\n         entry.hasWritten = true;\n         if (entry.entry.getMethod() == DEFLATED) {\n+            writeDeflated(b, offset, length);\n+        } else {\n+            writeOut(b, offset, length);\n+            written += length;\n+        }\n+        crc.update(b, offset, length);\n+        count(length);\n+    }\n+\n+    /**\n+     * write implementation for DEFLATED entries.\n+     */\n+    private void writeDeflated(byte[]b, int offset, int length)\n+        throws IOException {\n             if (length > 0 && !def.finished()) {\n                 entry.bytesRead += length;\n                 if (length <= DEFLATER_BLOCK_SIZE) {\n                     }\n                 }\n             }\n-        } else {\n-            writeOut(b, offset, length);\n-            written += length;\n-        }\n-        crc.update(b, offset, length);\n-        count(length);\n     }\n \n     /**\n      * @exception  IOException  if an I/O error occurs.\n      * @throws Zip64RequiredException if the archive's size exceeds 4\n      * GByte or there are more than 65535 entries inside the archive\n+     * and {@link Zip64Mode #setUseZip64} is {@link Zip64Mode#Never}.\n      */\n     @Override\n     public void close() throws IOException {\n         if (!finished) {\n             finish();\n         }\n-\n-        if (raf != null) {\n-            raf.close();\n-        }\n-        if (out != null) {\n-            out.close();\n-        }\n+        destroy();\n     }\n \n     /**\n         ByteBuffer name = getName(ze);\n \n         if (createUnicodeExtraFields != UnicodeExtraFieldPolicy.NEVER) {\n-\n-            if (createUnicodeExtraFields == UnicodeExtraFieldPolicy.ALWAYS\n-                || !encodable) {\n-                ze.addExtraField(new UnicodePathExtraField(ze.getName(),\n-                                                           name.array(),\n-                                                           name.arrayOffset(),\n-                                                           name.limit()));\n-            }\n-\n-            String comm = ze.getComment();\n-            if (comm != null && !\"\".equals(comm)) {\n-\n-                boolean commentEncodable = zipEncoding.canEncode(comm);\n-\n-                if (createUnicodeExtraFields == UnicodeExtraFieldPolicy.ALWAYS\n-                    || !commentEncodable) {\n-                    ByteBuffer commentB = getEntryEncoding(ze).encode(comm);\n-                    ze.addExtraField(new UnicodeCommentExtraField(comm,\n-                                                                  commentB.array(),\n-                                                                  commentB.arrayOffset(),\n-                                                                  commentB.limit())\n-                                     );\n-                }\n-            }\n+            addUnicodeExtraFields(ze, encodable, name);\n         }\n \n         offsets.put(ze, Long.valueOf(written));\n     }\n \n     /**\n+     * Adds UnicodeExtra fields for name and file comment if mode is\n+     * ALWAYS or the data cannot be encoded using the configured\n+     * encoding.\n+     */\n+    private void addUnicodeExtraFields(ZipArchiveEntry ze, boolean encodable,\n+                                       ByteBuffer name)\n+        throws IOException {\n+            if (createUnicodeExtraFields == UnicodeExtraFieldPolicy.ALWAYS\n+                || !encodable) {\n+                ze.addExtraField(new UnicodePathExtraField(ze.getName(),\n+                                                           name.array(),\n+                                                           name.arrayOffset(),\n+                                                           name.limit()));\n+            }\n+\n+            String comm = ze.getComment();\n+            if (comm != null && !\"\".equals(comm)) {\n+\n+                boolean commentEncodable = zipEncoding.canEncode(comm);\n+\n+                if (createUnicodeExtraFields == UnicodeExtraFieldPolicy.ALWAYS\n+                    || !commentEncodable) {\n+                    ByteBuffer commentB = getEntryEncoding(ze).encode(comm);\n+                    ze.addExtraField(new UnicodeCommentExtraField(comm,\n+                                                                  commentB.array(),\n+                                                                  commentB.arrayOffset(),\n+                                                                  commentB.limit())\n+                                     );\n+                }\n+            }\n+    }\n+\n+    /**\n      * Writes the data descriptor entry.\n      * @param ze the entry to write\n      * @throws IOException on error\n      * @param ze the entry to write\n      * @throws IOException on error\n      * @throws Zip64RequiredException if the archive's size exceeds 4\n-     * GByte\n+     * GByte and {@link Zip64Mode #setUseZip64} is {@link\n+     * Zip64Mode#Never}.\n      */\n     protected void writeCentralFileHeader(ZipArchiveEntry ze) throws IOException {\n         writeOut(CFH_SIG);\n                                              .ARCHIVE_TOO_BIG_MESSAGE);\n         }\n \n-        if (needsZip64Extra) {\n-            Zip64ExtendedInformationExtraField z64 = getZip64Extra(ze);\n-            if (ze.getCompressedSize() >= ZIP64_MAGIC\n-                || ze.getSize() >= ZIP64_MAGIC) {\n-                z64.setCompressedSize(new ZipEightByteInteger(ze.getCompressedSize()));\n-                z64.setSize(new ZipEightByteInteger(ze.getSize()));\n-            } else {\n-                // reset value that may have been set for LFH\n-                z64.setCompressedSize(null);\n-                z64.setSize(null);\n-            }\n-            if (lfhOffset >= ZIP64_MAGIC) {\n-                z64.setRelativeHeaderOffset(new ZipEightByteInteger(lfhOffset));\n-            }\n-            ze.setExtra();\n-        } else if (hasZip64Extra(ze)) {\n-            // added to LFH but not really needed, probably because of\n-            // Zip64Mode.Always\n-            ze.removeExtraField(Zip64ExtendedInformationExtraField.HEADER_ID);\n-            ze.setExtra();\n-        }\n+        handleZip64Extra(ze, lfhOffset, needsZip64Extra);\n \n         // version made by\n         // CheckStyle:MagicNumber OFF\n     }\n \n     /**\n+     * If the entry needs Zip64 extra information inside the central\n+     * director then configure its data, otherwise remove it if one is\n+     * present.\n+     */\n+    private void handleZip64Extra(ZipArchiveEntry ze, long lfhOffset,\n+                                  boolean needsZip64Extra) {\n+        if (needsZip64Extra) {\n+            Zip64ExtendedInformationExtraField z64 = getZip64Extra(ze);\n+            if (ze.getCompressedSize() >= ZIP64_MAGIC\n+                || ze.getSize() >= ZIP64_MAGIC) {\n+                z64.setCompressedSize(new ZipEightByteInteger(ze.getCompressedSize()));\n+                z64.setSize(new ZipEightByteInteger(ze.getSize()));\n+            } else {\n+                // reset value that may have been set for LFH\n+                z64.setCompressedSize(null);\n+                z64.setSize(null);\n+            }\n+            if (lfhOffset >= ZIP64_MAGIC) {\n+                z64.setRelativeHeaderOffset(new ZipEightByteInteger(lfhOffset));\n+            }\n+            ze.setExtra();\n+        } else if (hasZip64Extra(ze)) {\n+            // added to LFH but not really needed, probably because of\n+            // Zip64Mode.Always\n+            ze.removeExtraField(Zip64ExtendedInformationExtraField.HEADER_ID);\n+            ze.setExtra();\n+        }\n+    }\n+\n+    /**\n      * Writes the &quot;End of central dir record&quot;.\n      * @throws IOException on error\n      * @throws Zip64RequiredException if the archive's size exceeds 4\n      * GByte or there are more than 65535 entries inside the archive\n+     * and {@link Zip64Mode #setUseZip64} is {@link Zip64Mode#Never}.\n      */\n     protected void writeCentralDirectoryEnd() throws IOException {\n         writeOut(EOCD_SIG);\n--- a/src/main/java/org/apache/commons/compress/archivers/zip/ZipFile.java\n+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipFile.java\n  * <p>It doesn't extend <code>java.util.zip.ZipFile</code> as it would\n  * have to reimplement all methods anyway.  Like\n  * <code>java.util.ZipFile</code>, it uses RandomAccessFile under the\n- * covers and supports compressed and uncompressed entries.</p>\n+ * covers and supports compressed and uncompressed entries.  It also\n+ * transparently supports Zip64 extensions and thus individual entries\n+ * and archives larger than 4 GB or with more than 65536 entries.</p>\n  *\n  * <p>The method signatures mimic the ones of\n  * <code>java.util.zip.ZipFile</code>, with a couple of exceptions:\n         /* external file attributes        */ + WORD\n         /* relative offset of local header */ + WORD;\n \n+    private static final long CFH_SIG =\n+        ZipLong.getValue(ZipArchiveOutputStream.CFH_SIG);\n+\n     /**\n      * Reads the central directory of the given archive and populates\n      * the internal tables with ZipArchiveEntry instances.\n \n         positionAtCentralDirectory();\n \n-        byte[] cfh = new byte[CFH_LEN];\n-\n         byte[] signatureBytes = new byte[WORD];\n         archive.readFully(signatureBytes);\n         long sig = ZipLong.getValue(signatureBytes);\n-        final long cfhSig = ZipLong.getValue(ZipArchiveOutputStream.CFH_SIG);\n-        if (sig != cfhSig && startsWithLocalFileHeader()) {\n+\n+        if (sig != CFH_SIG && startsWithLocalFileHeader()) {\n             throw new IOException(\"central directory is empty, can't expand\"\n                                   + \" corrupt archive.\");\n         }\n-        while (sig == cfhSig) {\n+\n+        while (sig == CFH_SIG) {\n+            readCentralDirectoryEntry(noUTF8Flag);\n+            archive.readFully(signatureBytes);\n+            sig = ZipLong.getValue(signatureBytes);\n+        }\n+        return noUTF8Flag;\n+    }\n+\n+    /**\n+     * Reads an individual entry of the central directory, creats an\n+     * ZipArchiveEntry from it and adds it to the global maps.\n+     *\n+     * @param noUTF8Flag map used to collect entries that don't have\n+     * their UTF-8 flag set and whose name will be set by data read\n+     * from the local file header later.  The current entry may be\n+     * added to this map.\n+     */\n+    private void\n+        readCentralDirectoryEntry(Map<ZipArchiveEntry, NameAndComment> noUTF8Flag) throws IOException {\n+        byte[] cfh = new byte[CFH_LEN];\n+\n             archive.readFully(cfh);\n             int off = 0;\n             ZipArchiveEntry ze = new ZipArchiveEntry();\n             ze.setMethod(ZipShort.getValue(cfh, off));\n             off += SHORT;\n \n-            // FIXME this is actually not very cpu cycles friendly as we are converting from\n-            // dos to java while the underlying Sun implementation will convert\n-            // from java to dos time for internal storage...\n             long time = ZipUtil.dosToJavaTime(ZipLong.getValue(cfh, off));\n             ze.setTime(time);\n             off += WORD;\n             archive.readFully(cdExtraData);\n             ze.setCentralDirectoryExtra(cdExtraData);\n \n+            setSizesAndOffsetFromZip64Extra(ze, offset, diskStart);\n+\n+            byte[] comment = new byte[commentLen];\n+            archive.readFully(comment);\n+            ze.setComment(entryEncoding.decode(comment));\n+\n+            if (!hasUTF8Flag && useUnicodeExtraFields) {\n+                noUTF8Flag.put(ze, new NameAndComment(fileName, comment));\n+            }\n+    }\n+\n+    /**\n+     * If the entry holds a Zip64 extended information extra field,\n+     * read sizes from there if the entry's sizes are set to\n+     * 0xFFFFFFFFF, do the same for the offset of the local file\n+     * header.\n+     *\n+     * <p>Ensures the Zip64 extra either knows both compressed and\n+     * uncompressed size or neither of both as the internal logic in\n+     * ExtraFieldUtils forces the field to create local header data\n+     * even if they are never used - and here a field with only one\n+     * size would be invalid.</p>\n+     */\n+    private void setSizesAndOffsetFromZip64Extra(ZipArchiveEntry ze,\n+                                                 OffsetEntry offset,\n+                                                 int diskStart)\n+        throws IOException {\n             Zip64ExtendedInformationExtraField z64 =\n                 (Zip64ExtendedInformationExtraField)\n                 ze.getExtraField(Zip64ExtendedInformationExtraField\n                                                 hasRelativeHeaderOffset,\n                                                 diskStart == ZIP64_MAGIC_SHORT);\n \n-                // read ZIP64 values into entry.\n-                // ensure ZIP64 field either knows no or both size\n-                // values so it can create valid local header extra data\n-\n                 if (hasUncompressedSize) {\n                     ze.setSize(z64.getSize().getLongValue());\n                 } else if (hasCompressedSize) {\n                         z64.getRelativeHeaderOffset().getLongValue();\n                 }\n             }\n-\n-            byte[] comment = new byte[commentLen];\n-            archive.readFully(comment);\n-            ze.setComment(entryEncoding.decode(comment));\n-\n-            archive.readFully(signatureBytes);\n-            sig = ZipLong.getValue(signatureBytes);\n-\n-            if (!hasUTF8Flag && useUnicodeExtraFields) {\n-                noUTF8Flag.put(ze, new NameAndComment(fileName, comment));\n-            }\n-        }\n-        return noUTF8Flag;\n     }\n \n     /**\n             // not a ZIP64 archive\n             positionAtCentralDirectory32();\n         } else {\n+            positionAtCentralDirectory64();\n+        }\n+    }\n+\n+    /**\n+     * Parses the &quot;Zip64 end of central directory locator&quot;,\n+     * finds the &quot;Zip64 end of central directory record&quot; using the\n+     * parsed information, parses that and positions the stream at the\n+     * first central directory record.\n+     */\n+    private void positionAtCentralDirectory64()\n+        throws IOException {\n             archive.skipBytes(ZIP64_EOCDL_LOCATOR_OFFSET);\n             byte[] zip64EocdOffset = new byte[DWORD];\n             archive.readFully(zip64EocdOffset);\n             byte[] cfdOffset = new byte[DWORD];\n             archive.readFully(cfdOffset);\n             archive.seek(ZipEightByteInteger.getLongValue(cfdOffset));\n-        }\n     }\n \n     /**", "timestamp": 1313071734, "metainfo": ""}